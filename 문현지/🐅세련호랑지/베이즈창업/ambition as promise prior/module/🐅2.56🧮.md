## B.3: Economics of Information Integration - 무지의 경제학 (Static Optimization)

[[tom_griffith]]
### 핵심 명제: "V/ic < 1이면 τ = 0 (최적 무지)"

Andrew Gelman의 Bayesian Workflow와 Josh Tenenbaum의 Bounded Optimality가 만나는 지점이 있다. 바로 **완벽한 정보 처리는 불가능하고 불필요하다**는 통찰이다.

### 정보 통합 비용의 해부

```
τ* = max(0, V/ic - 1)
```

이 공식은 단순해 보이지만 혁명적이다:
- **V**: 벤처의 잠재 가치
- **i**: 정보 통합 비용 (digestion cost)
- **c**: 시스템 복잡도

**결론: V/ic < 1이면 τ = 0, 즉 "모르는 게 약"**

### 합리적 무지의 조건

1. **비용이 너무 높을 때 (i↑)**:
   - 새 구성원 통합
   - 프로세스 표준화
   - 기존 모델과의 일관성 회복

2. **복잡도가 너무 높을 때 (c↑)**:
   - 규제 불확실성
   - 기술 경로 불확실
   - 시장 변동성

3. **가치가 충분히 크지 않을 때 (V↓)**:
   - 작은 시장
   - 낮은 마진
   - 불확실한 성공

**이것이 Tom Griffiths의 "Quick suboptimal better than slow optimal"과 일치한다.**


🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨🚨

---


# B.3 Economics of Information Integration: When Ignorance Becomes Optimal

> "V/ic < 1이면 τ = 0 (최적 무지)"

⭐️M3는 약속의 지시적 내용과 수행적 효과 사이의 변증법적 긴장을 Beta-Binomial 켤레성(conjugacy)의 폐쇄형 주변우도(closed-form marginal likelihood)로 포착하여, 잔혹한 낙관주의를 최적 제어 문제가 아닌 확률적 평형(stochastic equilibrium)으로 재구성합니다.⭐️
## 한 장의 그림: Promise Paradox의 수학적 전개

```
     Promise Paradox: From Linear to Adaptive
    
    φ (promise level)
    0 ←───────────────────────→ 1
    
    M1: P = φ                    [선형]
    ━━━━━━━━━━━━━━━━━━━━━━━━━━
         ↗ (단조증가)
    
    M2: P = φ(1-φ)ⁿ              [최적화]
    ━━━━━━━━━━━━━━━━━━━━━━━━━━
         ╱╲ (inverted U)
        ╱  ╲
       ╱    ╲  ← "cruel optimism"
    
    M3: P = ∫φ(1-φ)ⁿ Beta(φ)dφ  [계층적]
    ━━━━━━━━━━━━━━━━━━━━━━━━━━
      ░░▓▓▓▓░░  ← "productive suspension"
        ^^^^ 
      Berlant's impasse
      (negative capability)
    
    M4: P = ∫∫...dμdτ            [적응적]
    ━━━━━━━━━━━━━━━━━━━━━━━━━━
      ○→●→◉  진화하는 τ
      초기 중기 후기
    
    실제 사례:
    Better Place  Tesla    Nikola
         ●          ◉        ✗
       (M2)    (M3→M4)    (M1)
      고정됨    적응함    붕괴됨
    
    핵심 통찰:
    "충분히 구체적이어서 믿을 수 있지만
     충분히 모호해서 진화할 수 있는"
           최적 구간의 존재
```

이 그림은 단순한 약속(M1)에서 시작해 잔혹한 최적화(M2)를 거쳐 생산적 모호함(M3)과 적응적 학습(M4)으로 진화하는 과정을 보여줍니다. Tesla의 성공은 M3의 negative capability를 유지하면서 M4의 적응성을 활용했기 때문이라고 해석할 수 있습니다.

## "Cruel Optimism의 역설": 최대가 아닌 최적

### 개념적 의미

**E[P(s)]는 최대가 아님**: 평균 생존확률이 최고점이 아님 **하지만 Var[P(s)]가 생존 가능**: 불확실성 자체가 가치를 가짐

이는 **생존이 확률 최대화가 아닌 불확실성 관리**임을 의미합니다.

### 수학적 표현

M3에서:

```
E[P(s)] = E[φ(1-φ)ⁿ] 
        ≠ max{φ(1-φ)ⁿ}  (최대값이 아님)

Var[P(s)] = E[(P(s))²] - (E[P(s)])²
          > 0 (적절한 분산 유지)
```

### 구체적 계산 예시

```python
# M2 (결정론적): 최대값 추구
φ_optimal = 1/(n+1)  # 미분으로 구한 최적점
P_max = φ_optimal(1-φ_optimal)ⁿ

# M3 (확률적): 분산 유지
φ ~ Beta(μτ₀, (1-μ)τ₀)
E[P(s)] < P_max  # 평균은 최대보다 작음
But: Var[P(s)] = σ²_acceptable  # 생존 가능한 분산
```

### 역설의 핵심

**최적 ≠ 최대**인 이유:

1. **너무 확실한 약속 (Var→0)**:
    
    - 실패 시 완전 붕괴
    - Nikola처럼 거짓 노출
2. **적절한 불확실성 (Var적정)**:
    
    - 실패를 "재해석"할 공간
    - 피벗 가능성 보존
    - Tesla의 "200마일 이상"

### 수식화 가능성

```
최적화 문제 재정의:
max U = αE[P(s)] - β/Var[P(s)] - γVar[P(s)]
        ↑평균효용    ↑너무확실    ↑너무불확실
        
여기서 Var[P(s)]의 역U자 효용함수 존재
```

### Berlant적 통찰

잔혹한 낙관주의의 수학:

- **생존 ≠ 성공 최대화**
- **생존 = 적응 공간 유지**
- **Var[P(s)] = negative capability의 측도**

Tesla가 M2의 최적점이 아닌 M3의 분산을 선택한 것이 오히려 생존으로 이어진 역설입니다.
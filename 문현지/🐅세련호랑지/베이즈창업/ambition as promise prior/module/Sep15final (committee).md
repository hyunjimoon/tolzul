# Growing Success through Precision

## Abstract

Prior research in entrepreneurship and strategy often treats either venture success probability (P) or the informativeness of evidence as exogenous. I develop an endogenous mechanism for both. I reparameterize P as an aspirationâ€“precision prior, where aspiration is passively constrained by subsystem complexity, while precision (Ï„) is the founderâ€™s design lever. Choosing Ï„ determines how strongly evidence updates the prior distribution of P, thereby endogenizing **prior-driven informativeness**.This mechanism closes the gap between **micro experimentation and macro selection**. At the micro level, ventures differ in how much they allow evidence to move them; at the macro level, markets select across these trajectories. Ventures that assume high Ï„ prematurely resist adaptation and collapse (Better Place), while staged lowâ†’high Ï„ trajectories absorb evidence and survive (Tesla).Theoretically, Ï„ has **three nested meanings**: as a concentration parameter (probability level), a pseudoâ€“sample size (sampling level), and a variationâ€“selection balance (evolutionary level). Linking these levels shows that ventures mirror natural selection: they begin with variation (low Ï„) and move toward selection (high Ï„). I define **growth** as this increase in Ï„, achieved not automatically but through deliberate actionsâ€”lowering information-integration cost (i) and raising venture value (V). The contribution is both conceptual and prescriptive: success probability and informativeness are **designed, not given**. Founders are not merely quixotic opportunity pursuer but **uncertainty engineer** who manage Ï„ dynamically, earning precision through culture and capital.

Keyword: Bayesian and Evolutionary Entrepreneurship

*It appears to be a general principle that, whenever there is a randomized way of doing something, then there is a nonrandomized way that delivers better performance but requires more thought. \- E.T. Jaynes.*

# 1. Introduction (Final Polished Draft)

Prior research in entrepreneurship and strategy has treated either **venture success probability (P)** or the **informativeness of evidence** as exogenous. This leaves a central puzzle unresolved: why do ventures facing the same environment and signals diverge so sharply in outcomes? If P is fixed, all ventures share the same odds, reducing differences in survival to luck or innate talent. If informativeness is fixed, all ventures learn at the same rate from the same signals, leaving no explanation for heterogeneous adaptation. What is missing is a mechanism by which founders _design their own capacity to learn_.

Consider Tesla and Better Place. Both confronted failures early in their journeys. Teslaâ€™s Roadster suffered production delays and recalls; Better Place faced sluggish sales and uncertain charging standards. Yet Tesla pivoted and survived, while Better Place collapsed. Why did the same type of negative evidence trigger adaptation in one case but rigidity in the other? The answer lies in how each venture set its prior beliefs.

A simple Betaâ€“Binomial model illustrates this mechanism. Let Ï• denote the probability that a promise succeeds. The prior is parameterized as Ï•âˆ¼Beta(Î¼Ï„,(1âˆ’Î¼)Ï„) where Î¼ is the prior mean (**aspiration**) and Ï„ is its precision. After observing n trials with xx successes, the posterior becomes Beta(Î¼Ï„+x,(1âˆ’Î¼)Ï„+nâˆ’x). When a single failure is observed (x=0,n=1), the posterior mean updates to: E[Ï•âˆ£x=0,n=1]=Î¼Ï„ / (Ï„+1)

This expression makes informativeness concrete: with **low Ï„**, beliefs fall sharply after failure, reflecting high responsiveness to evidence; with **high Ï„**, beliefs barely move, reflecting rigidity.

**Figure Phenomena** visualizes this logic. The top panel shows a loose prior (Ï„=1) that shifts nearly 50% after one failureâ€”precisely the responsiveness that enabled Teslaâ€™s rapid pivots. The bottom panel shows a tight prior (Ï„=4) that shifts only 20% after the same failureâ€”an update too small to change course, locking ventures into rigid commitments as in Better Place. Precision Ï„ thus determines whether failure becomes a catalyst for adaptation or a trigger for collapse.
![[fig(phenomena).png]]

This mechanism closes the gap between **micro experimentation and macro selection**. At the micro level, ventures differ in how much evidence can move them; at the macro level, markets select across these trajectories. Better Place exemplified premature high Ï„, collapsing in rigidity. Tesla exemplified staged lowâ†’high Ï„, beginning with variation, gradually raising fidelity as information-integration cost fell and venture value increased, ultimately achieving scale.

Theoretically, Ï„ has **three nested meanings**. At the probability level, Ï„ is a concentration parameter. At the sampling level, Ï„ is a pseudoâ€“sample size approximating bounded rationality. At the evolutionary level, Ï„ represents a **variationâ€“selection balance**: ventures begin with variation (low Ï„) and evolve toward replication fidelity (high Ï„). Linking these levels shows that ventures mirror natural selection. Growth is defined as this staged increase in Ï„, achieved not automatically but through deliberate organizational design: lowering **information-integration cost (i)**â€”the inverse of organizational clockspeedâ€”and raising venture value (V).

 The paper is engineered as follows. **Section 2 develops the theoretical framework (what)** by reparameterizing venture success probability as an aspirationâ€“precision prior and showing why Ï„ endogenizes informativeness. It explains why existing accounts are incomplete and how Ï„ connects micro experimentation to macro selection. **Section 3 applies the framework (how)** through the contrasting cases of Tesla and Better Place, distilling a single prescriptionâ€”_acculturate to concentrate_â€”and advancing a testable _Staged Precision Hypothesis_ that links Ï„ trajectories to venture survival. **Section 4 concludes (so what)** by outlining implications for theory, practice, and future research, reframing founders not as passive or quixotic pursuers of opportunity (Stevenson, 1983) but as **uncertainty engineers** who deliberately design their learning capacity.

## 1.1 Three Meanings of Ï„

In my model, promise precision Ï„ is defined as **a measure of the specificity and rigidity of a venture's promise, acting as a control knob for flexibility vs. efficiency.** Three meanings of this core decision variable carries are:
1. Promise precision. High Ï„ denotes a narrow, specific commitment; low Ï„ denotes a broad, flexible commitment.
2. Pseudoâ€“sample size. High Ï„ behaves as if the founder holds substantial prior evidence.
3. Width of open space. Low Ï„ preserves a set of latent functions not yet specified, maximizing the real option value of exaptation.

As organizations mature and face greater information-integration costs and environmental complexity, managing Ï„ dynamicallyâ€”by deliberately controlling i (information-integration cost) and c (complexity)â€”becomes a central task.

The structural metaphor of DNA helical tension and the strategic metaphor of firebreak width illuminate why flexibility (low Ï„) and efficiency (high Ï„) succeed under different conditions:

Table 1. Bayesianâ€“Evolutionary Metaphors for the Flexibilityâ€“Efficiency Tension

|  | Low Ï„ (Flexibility) | High Ï„ (Efficiency) |
| ----- | ----- | ----- |
| DNA tension | Loose | Tight |
| Firebreak width | Wide | Narrow |
| Best-fit environment | High complexity, high information cost | Low complexity, low information cost |


Tightly wound DNA strands (high Ï„) replicate with high fidelity and are efficient in stable environments, but they generate little variation and thus adapt poorly to shocks. Loosely wound strands (low Ï„) admit variation, enabling pivots essential for survival in changing conditions. Firebreak width reflects the founderâ€™s prior quality: a founder with a very high-quality prior (e.g., Robert Langer at MIT) can set a narrow firebreak (high Ï„) and pursue maximum efficiency; a less certain founder exploring novel terrain should widen the firebreak (low Ï„) to preserve room and time to maneuver when reality defies the initial thesis.

## 1.2 Separating Founder and Venture

- Bayesian: empirical bayes overlaps with hierarchical bayesian (Gelman, 2015; )
- Evolutionary: 

ğŸš¨ğŸš¨ğŸš¨ğŸš¨As the environment becomes more complex, higher the founder's need to improve quality of one's venture model. Imagine how the tide of 2008 economic crisis and Covid has acted upon the founders simulating and calibrating different business models ğŸš¨ğŸš¨ğŸš¨ğŸš¨ To capture the function of quality improvement, I use hierarchical Bayesian model where founder represented as prior  Bayesian principal agent (Gelman, 2013) relationship between the founder and one's venture, I implement hierarchical Bayesian modeling to separate the founder who learns and the venture,  [[founder learns and venture adapts]] "The venture is the manifestation of the founder's learning. It adapts structurally based on what the founder has learned cognitively. The venture doesn't have independent consciousness to "learn" - it changes through the founder's updated decisions.ada" This enables simulation and calibration of a business model to raise its success probability. The separation clarifies how environmental complexity c shapes the likelihood of success and how the strategic choice of ambiguity Ï„ shapes the priorâ€”allowing us to model learning as belief-updating in response to venture-generated evidence (Gelman et al., 2020).


## 1.3. Bridging Schools of Thought

The framework bridges the false dichotomy between the action school, which values flexibility and emergence, and the planning school, which values detailed prediction and commitment. In our model, the pure action school corresponds to the limit Ï„ â†’ 0 (maximal openness), and the pure planning school corresponds to Ï„ â†’ âˆ (absolute confidence in a single plan). Placing the two schools on the spectrum, I prescribe founders to grow from low to high Ï„ to empirically calibrating their aspiration and venture's promise level against the environment's complexity one senses. This aligns with Bastone (2000)'s perspective where information is defined as difference that causes difference.  Venture' growth, as differentiation, can be view   reflects   against   my theory prescribes founders to gradually increase Ï„  venture should grow Ï„ These are endpoints of a continuum. Rather than â€œdecision-making under uncertainty,â€ I model decision-making on uncertainty itself, offering a new perspective for strategy.

simplify to aspire, sync to concentrate. mu propto 1/complexity, tau,  propto

## 1.4. Roadmap for the Paper

ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨I proceed with a â€œwhatâ€“whyâ€“howâ€“so whatâ€ logic. Section 2 develops the theory of Ï„, its structural and strategic metaphors grounded in Bayesian and Evolutionary math. Section 3 applies the framework to Tesla and Better Place, showing how it explains real-world success and failure. Section 4 envisions future works in both theory and practice.ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨

# 2. Theory and Model

### 2.1 Prior Bodies of Literature 

#### 2.1.1 Anatomy of Success Probability

The entrepreneurship literature has long been divided by a fundamental epistemological schism regarding the nature of opportunity and success probability. The planning school, exemplified by Porterâ€™s (1980) competitive positioning framework and extended by Camuffo et al. (2020) through their scientific approach to founderial decision-making, posits that systematic analysis and hypothesis testing can reduce uncertainty to manageable proportions. This tradition, rooted in industrial organization economics (Bain, 1956; Mason, 1939), treats success probability as an exogenous market characteristic that founders must discover through rigorous analytical processes. Conversely, the action school, pioneered by Sarasvathyâ€™s (2001) effectuation theory and complemented by Baker and Nelsonâ€™s (2005) bricolage construct, argues that opportunities emerge through founderial action rather than analytical discovery. Marchâ€™s (1991) exploration-exploitation framework provides the theoretical underpinning for this perspective, suggesting that under conditions of radical uncertainty, experimentation supersedes planning. Yet both schools share a critical limitation: they treat success probability as exogenous to founderial choice, differing only in their prescribed methods for navigating this given constraint. However, this is odd. If founder can't have any influence on one's venture success, what's the point of founderial education? Also, if venture success probability is exogenous, does it matter who founds the venture? Does this one core assumption in decision making model negate > 1000 founderhsip literature reporting "nature" aspect of entrepreneurship, finally terminating the greatest myth of entrepreneurship that founders are born? (Agrawal, 2025)

Our theoretical contribution fundamentally reconceptualizes success probability through a double reparameterization that transforms it from an exogenous constraint to an endogenously designed variable. Building on recent advances in Bayesian decision theory (Gelman et al., 2020\) I decompose success probability P into promise level Ï†, which I further decompose into aspiration Î¼ and precision Ï„. This decomposition reveals that founders possess three strategic leversâ€”Ï†\*, Î¼\*, and Ï„\*â€”through which they actively construct rather than merely respond to their probability landscape. The failure of Better Place, despite $850 million in funding and seemingly perfect planning (Etzion & Struben, 2023), versus Teslaâ€™s trajectory from ambiguous promises to market dominance (Teece, 2018), cannot be explained by existing frameworks that treat success as exogenously determined. Our model demonstrates that Better Placeâ€™s high precision parameter (Ï„ â†’ âˆ) created what I term a â€œlearning trap,â€ (proposition1) while Teslaâ€™s initially low Ï„ preserved what Keats (1817) called â€œnegative capabilityâ€â€”the capacity to remain comfortable with uncertainty. This reconceptualization transforms the founder from what Kirzner (1973) termed an â€œalert discovererâ€ to what I propose as an â€œuncertainty architect.â€

#### 2.1.2 Tau Stitches False Dichotomies 

Table 2\. False Dichotomies Unified by the Ï„ Framework

| Domain                                  | Low Ï„ (Complex / High i)                | High Ï„ (Simple / Low i)               | Unifying Principle                                            |
| --------------------------------------- | --------------------------------------- | ------------------------------------- | ------------------------------------------------------------- |
| Strategy schools                        | Action school (â€œact then thinkâ€)        | Planning school (â€œthink then actâ€)    | Ï„ maps actionâ€“planning onto a continuum                       |
| Learning schools                        | Model-free (experience-driven)          | Model-based (theory-driven)           | Ï„ weights prior knowledge                                     |
| DNA tension metaphor                    | Loose DNA (high variation, flexibility) | Tight DNA (low variation, efficiency) | Ï„ tunes variation vs. replication fidelity                    |
| Sampling                                | Few samples (fast decisions)            | Many samples (precise estimates)      | Ï„ â‰ˆ pseudoâ€“sample size                                        |
| Founderâ€™s response to given uncertainty | Fight with self-imposed uncertainty     | Fight with knowledge                  | Ï„ sets the exploreâ€“exploit balance                            |
| Venture cases                           | Tesla (flexible pivots)                 | Better Place (rigid strategy)         | Ï„\* decreases with higher complexity c and integration cost i |

Thus Ï„ is not a binary choice but a continuous variable that should be tuned to environmental conditions (i: information-integration cost, normalized by venture value; c: environmental complexity). As c and i rise, the optimal Ï„ decreases (choose flexibility); as they fall, the optimal Ï„ increases (choose efficiency). Teslaâ€™s trajectory (start low Ï„, then earn precision) and Better Placeâ€™s failure (rigid high Ï„ amid high complexity) illustrate the point. 

![][image1]

#### 2.1.3 Tau Counts Bayesian Heads
##### 2.1.3.1 Bayesian entrepreneurship

â€œBayesian entrepreneurshipâ€ reconceives the founderâ€™s cognition as a computational inference system, not merely the application of probabilistic language. Agrawal et al. (2024) articulate how founders possess heterogeneous, relatively strong priors and update them systematically via Bayesâ€™ ruleâ€”casting founders as active theorists (Felin & Zenger, 2009; Zellweger & Zenger, 2023). RCT evidence (Camuffo et al., 2020, 2024\) shows model-based hypothesis testing approaches improve termination, pivoting, and performance; Novelli & Spina (2024) highlight the role of causal reasoning, in line with hierarchical Bayesian cognitive models (Griffiths and Tenenbaum, 2017; Tenenbaum, 1998). Current frontiers integrate individual and population-level learning (Li et al., 2023), i.e., meta-learning across venture populations.

summarize 
1. among what [[Infer Josh and Scott's Mind and Market.pdf]] saying is missing and suggesting for the next step in current bayesian entrepreneurship literature 
	1. sample-based approach that enables resource rational reasoning
	2. hierarchical bayesian model, which is closely related with empirical bayes

> bayesian brains without probabilities (cite Sanborn et.al., 2016)
Bayesian explanations have swept through cognitive science over the past two decades, from intuitive physics and causal learning, to perception, motor control and language. Yet people flounder with even the simplest probability questions. What explains this apparent paradox? How can a supposedly Bayesian brain reason so poorly with probabilities? In this paper, we propose a direct and perhaps unexpected answer: that Bayesian brains need not represent or calculate probabilities at all and are, indeed, poorly adapted to do so. Instead, the brain is a Bayesian sampler. Only with infinite samples does a Bayesian sampler conform to the laws of probability; with finite samples it systematically generates classic probabilistic reasoning errors, including the unpacking effect, base-rate neglect, and the conjunction fallacy

Two epistemic shifts follow. First, priors and likelihoods are not merely â€œwhatâ€ but â€œhowâ€â€”embodied process knowledge (Gelman et al., 2017). Ï„ is thus a meta-parameter governing strategic flexibility and learning speed. Second, I separate modeler and model (founder vs. venture), adopting Bayes not only for inference but for model development as an iterative design process.

Technically, the betaâ€“binomial conjugate structure with a precision parameterization places executionâ€“planning and exploreâ€“exploit on a single mathematical spectrum. Venture outcomes are sequences of Bernoulli trials (e.g., conversions, test passes), giving a Binomial likelihood. The unknown success probability Ï• has a Beta prior with mean (aspiration) Î¼ and precision Ï„. Conjugacy provides clean posterior updates and ties the abstract notions of strategic certainty and flexibility to a precise statistical quantity, Ï„.

DNA metaphorâ€”separating prior and likelihood. DNA tension depicts the relation between the founderâ€™s prior (Ï„) and environmental constraint (c). Sellability vs. deliverability is encoded in the likelihood: as c rises, deliverability of any promise Ï• drops steeply. Ï„, in turn, governs how strongly the prior weighs against new data. Low Ï„ protects flexibility and learnability (more weight on data) but may hamper resource mobilization; high Ï„ aids mobilization (more weight on prior) but risks rigidity when wrong.

![][image2]

Graphically, priors with different Ï„ (e.g., Beta(0.5,0.5), Beta(1,1), Beta(2,2)) illustrate Ignore â†’ Attention â†’ Know stages; posterior dynamics visualize Contraction / Compromise / Containment under new dataâ€”showing that Ï„ is the control knob for learning speed and pivot capacity.

##### 2.1.3.2 Evolutionary entrepreneurship

- Fine, C. H., Padurean, L., & Naumov, S. (2022). _Operations for entrepreneurs: Can OM make a difference in entrepreneurial theory and practice?_ Production and Operations Management, 31(12), 4599â€“4615.  
    â†’ ì°½ì—… ë§¥ë½ì—ì„œ **ìš´ì˜ê´€ë¦¬ ë„êµ¬ì™€ í´ë¡ìŠ¤í”¼ë“œ** ê°œë…ì„ ì ìš©í•´ì•¼ í•œë‹¤ëŠ” ë…¼ì˜[](https://www.dropbox.com/preview/Angie.H%20Moon/house%20in%20boston/ops4entrep_quality_stakeholder.pdf)
    
    [ops4entrep_quality_stakeholder](https://www.dropbox.com/preview/Angie.H%20Moon/house%20in%20boston/ops4entrep_quality_stakeholder.pdf)
    
    .
    
- Joglekar, N. R., & LÃ©vesque, M. (2013). _The role of operations management across the entrepreneurial value chain._ Production and Operations Management, 22(6), 1321â€“1335.  
    â†’ ì‹ ìƒê¸°ì—…ì´ ì„±ì¥ ë‹¨ê³„ë³„ë¡œ **ìš´ì˜ ì„¤ê³„, ì‹¤í—˜, ìŠ¤ì¼€ì¼ë§**ì„ ì–´ë–»ê²Œ ë‹¤ë¤„ì•¼ í•˜ëŠ”ì§€ ë¶„ì„[](https://www.dropbox.com/preview/Angie.H%20Moon/house%20in%20boston/ops4entrep_quality_stakeholder.pdf)
    
    [ops4entrep_quality_stakeholder](https://www.dropbox.com/preview/Angie.H%20Moon/house%20in%20boston/ops4entrep_quality_stakeholder.pdf)
    
    .
    
- Packard, M. D., Clark, B. B., & Klein, P. G. (2017). _Uncertainty types and transitions in the entrepreneurial process._ Organization Science, 28(5), 840â€“856.  
    â†’ ì°½ì—…ìê°€ ì§ë©´í•˜ëŠ” **ë¶ˆí™•ì‹¤ì„±ì˜ ìœ í˜•ê³¼ ì „í™˜**ì„ ì •ë¦¬, ì™œ **ì •ë°€ë„ë¥¼ ì„œì„œíˆ íšë“**í•´ì•¼ í•˜ëŠ”ì§€ë¥¼ ë’·ë°›ì¹¨[](https://www.dropbox.com/preview/Angie.H%20Moon/house%20in%20boston/ops4entrep_quality_stakeholder.pdf)
    
    [ops4entrep_quality_stakeholder](https://www.dropbox.com/preview/Angie.H%20Moon/house%20in%20boston/ops4entrep_quality_stakeholder.pdf)
    
    .
    
- Fisher, G., Kotha, S., & Lahiri, A. (2016). _Changing with the times: An integrated view of identity, legitimacy, and new venture life cycles._ Academy of Management Review, 41(3), 383â€“409.  
    â†’ ì‹ ìƒê¸°ì—…ì´ **ë‹¨ê³„ë³„ë¡œ ì •ì²´ì„±ê³¼ ì •ë‹¹ì„±ì„ ì¡°ì •**í•´ì•¼ í•¨ì„ ë³´ì—¬ì£¼ë©°, Ï„ë¥¼ í•œ ë²ˆì— ê³ ì •í•˜ëŠ” ê²ƒì˜ ìœ„í—˜ì„±ì„ ì„¤ëª…[](https://www.dropbox.com/preview/Angie.H%20Moon/house%20in%20boston/ops4entrep_quality_stakeholder.pdf)
    
    [ops4entrep_quality_stakeholder](https://www.dropbox.com/preview/Angie.H%20Moon/house%20in%20boston/ops4entrep_quality_stakeholder.pdf)
    
    .
    
- Sarasvathy, S. D. (2001). _Causation and effectuation: Toward a theoretical shift from economic inevitability to entrepreneurial contingency._ Academy of Management Review, 26(2), 243â€“263.  
    â†’ **í”Œë˜ë‹ vs ì•¡ì…˜(íš¨ê³¼í™”)** ë…¼ìŸì˜ ëŒ€í‘œ ë…¼ë¬¸. ë³¸ ë…¼ë¬¸ì€ ì´ ë‘˜ì„ **Ï„ì˜ ë™ì  ê´€ë¦¬**ë¼ëŠ” í‹€ë¡œ í†µí•©.
    
Beyond biological analogy, evolutionary entrepreneurship fuses complex adaptive systems with operations science. ğŸš¨Fine (1986; Fine & Li, 1988; Fine & Freund, 1990\) modeled learning and flexibilityâ€“efficiency trade-offs; Clockspeed (Fine, 1998\) formalized industry-specific evolutionary tempos; Fine et al. (2002) developed rapid-response capability across value chains; Operations for founders (Fine, 2022\) offers the Nailâ€“Scaleâ€“Sail framework and ten scaling tools. Opportunities that form at the boundary of the value chain, and options valuesğŸš¨ [[founder learns and venture adapts]]

- Integral needs multiple functions and the open space allows ambidextrity
- 3 dimensional concurrent engineering on the hierarchy of organizational, process, product and feedback within
Felin & Kauffman (2021a; 2021b) extend this with the adjacent possible, explaining how opportunity arises from the current frontier of technology, markets, and resources. Functional excess and experimentation power disruptive evolution, dovetailing with exaptation (Gould & Vrba, 1982). With Batesonâ€™s (1963) somatic flexibility, low Ï„ preserves slack that can be repurposed. BYD's battery Slackâ€™s pivot from gaming to enterprise communication exemplifies how low-Ï„ assets enable exaptation. âœ‹ğŸš¨
Using literature on exaptation in entrepreneruship [[ğŸ“œAndriani_exaptation_creativity_source]] [[ğŸ“œlaporta20_understanding Innovation Through Exaptation]], [[ğŸ› ï¸exaptation_spandrel]], synthesize one paragraph that 
1. describes how i'm using wide definition of adaptation that includes direct adaptation (optimization of trait for its original function) and co-option (adding new functions while maintaining original), and co-opted adaptation (complete shift to new function from original).
2. prescribes acculturating permeable, porous, open space as implementation of tau knob 
3. analyze Moderna's culture of parallel entrepreneurship and active pivot that [[noubar_afeyan]]; "
- You explore a diverse set of opportunities (variation), select promising ventures that passed the test (selection), refine these ventures based on feedback (mutation and crossover). " genetic algorithm 
- leverage the evolutionary engine of co-opted adaptation, âœ‹ğŸš¨

| Aspect                  | Direct Adaptation (Narrow) ğŸ¯                                                                                                                                           | ğŸŸ©Exaptation1 Co-option (sequential)ğŸ¨                                                                                                                                                                              | ğŸ”´Exaptation2  Co-opted adaptation (parallel)ğŸ› ï¸                                                                                                                                                                                                      |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Definition**          | Optimization of trait for its original function                                                                                                                         | Adding new functions while maintaining original                                                                                                                                                                     | Complete shift to new function from original                                                                                                                                                                                                          |
| **Process**             | Continuous refinement through selection                                                                                                                                 | Accumulation of additional functions                                                                                                                                                                                | Transformation of functional role                                                                                                                                                                                                                     |
| **Selection Pattern**   | Single directional pressure                                                                                                                                             | Multiple simultaneous pressures                                                                                                                                                                                     | Shift in selective pressure                                                                                                                                                                                                                           |
| **Original Function**   | ğŸ’ª Enhanced and optimized                                                                                                                                               | ğŸ¤¹Maintained at functional level                                                                                                                                                                                    | ğŸ‘‹ Left behind                                                                                                                                                                                                                                        |
| **Biological Examples** | â€¢ ğŸ¦’Giraffe neck length for reaching leaves<br>â€¢ ğŸ†Cheetah speed for hunting<br>â€¢ ğŸŒµCactus spines for water retention<br>â€¢ ğŸ»â€â„ï¸Polar bear fur thickness for insulation | â€¢ ğŸª¶Bird feathers: insulation â†’ insulation + flight<br>â€¢ ğŸ§Penguin wings: flight â†’ flight + swimming<br>â€¢ ğŸ¤²Human hands: climbing â†’ climbing + tool use<br>â€¢ ğŸ¢Turtle shell: mineral storage â†’ protection + storage | â€¢ ğŸ« Fish bladder â†’ lungs<br>â€¢ ğŸ¦–Dinosaur scales â†’ feathers<br>â€¢ ğŸ‘‚Jaw bones â†’ ear bones<br>â€¢ Heat shock proteins â†’ lens crystallins                                                                                                                  |
| **Business Examples**   | â€¢ ğŸš—Car engine efficiency improvements<br>â€¢ ğŸ”‹Battery life optimization<br>â€¢ ğŸ”Search algorithm refinement<br>â€¢ âš™ï¸ Manufacturing process optimization                   | â€¢ ğŸ“šAmazon: books â†’ books + general retail<br>â€¢ ğŸ¬Netflix: DVD rental â†’ streaming + production<br>â€¢ ğŸ” Google: search â†’ search + advertising<br>â€¢ ğŸ“±Twitter: messaging â†’ messaging + news                           | ğŸ“§email (ftp protocol)<br>ğŸï¸speedbox (same engine, go faster)<br>â€¢ ğŸ¨ Play-Doh: wallpaper cleaner â†’ toy<br>â€¢ ğŸ’ŠViagra: heart medicine â†’ ED treatment<br>â€¢ ğŸ“¸Instagram: check-in app â†’ photo sharing<br>â€¢ ğŸ’¬ Slack: game company tool â†’ business chat |

ğŸš¨ğŸš¨ğŸš¨Firebreak metaphorâ€”strategic ambiguity as containment. A wide firebreak (low Ï„) is prudent where fire (market dynamics) behaves unpredictably: you concede uncertainty and create defendable space away from the fireâ€™s edge. Low-Ï„ founders adopt containment; high-Ï„ founders adopt contractionâ€”efficient when fires are small, catastrophic when they jump the line.ğŸš¨ğŸš¨ğŸš¨

## 2.2 Modeling â€œFake It Till Approximate Itâ€

Table 3\. Key Model Variables

| Variable | Definition | Interpretation | Example (Tesla vs. Better Place) |
| ----- | ----- | ----- | ----- |
| Î¼ | Aspiration (mean of belief distribution) | Boldness of the promise | Tesla (Î¼â‰ˆ0.3): â€œ200+ miles.â€ Better Place (Î¼â‰ˆ0.9): â€œInfinite range.â€ |
| Ï„ | Precision  | Specificity/rigidity of the promise | Tesla (Ï„â‰ˆ1): â€œ\~200 miles (Â±40).â€ Better Place (Ï„â‰ˆ4): â€œExactly 3 minutes.â€ |
| C | Operational complexity | \# of independent, critical components | Tesla (nâ‰ˆ5): pack, motor, software. Better Place (nâ‰ˆ10): robotics, real estate, standards, OEMs. |
| I | Information-integration cost | Marginal cost to raise Ï„ by one | Tesla: prototype iteration. Better Place: nationwide swap network. |
| V | Venture value | Value upon successful delivery | E.g., market cap or TAM. |

â€‹â€‹# 2.4 Model: From â€œFake It Till Make Itâ€ to â€œApproximate Itâ€
![[ğŸ—„ï¸ğŸ…likelihood_updated.svg]]

**Figure1.** This figure makes transparent how an founderâ€™s epistemology matures: In M1, the promise Ï† is monotonically linked to success probability; in M1â€², natureâ€™s complexity c bends that monotonicity into a concave shape, so the same promise has different effective impact. By M2, I treat promises as a distribution by reparameterizing venture's promise with founder's aspiration Î¼; in M2â€², the founder chooses the design variable Ï„ to approximate that distribution, adopting rational ignorance as a strategy by balancing it against the meaning-construction cost i. Ultimately, it offers a grammar for deciding scientifically not â€œto know more,â€ but â€œwhen and what to leave unknown,â€ and that grammar is the bridge that reunifies the planning school and the action school along a single continuum.


Table. Comparative schematic of four Bayesian decision models (with generative notation)

|                               | M1                            | M1â€²                                            | M2 (â†’ Proposition 1)                                                                                       | M2â€² (â†’ Proposition 2)                                                                                                                    |
| ----------------------------- | ----------------------------- | ---------------------------------------------- | ---------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
| **Generative process**        | $S \sim \text{Bern}(\phi)$    | $S\land D \sim \text{Bern}(\phi(1-\phi)^c)$    | $S\land D \sim \text{Bern}(\phi(1-\phi)^c)$<br>$\phi \sim \text{Beta}(\mu,1)$                              | $S\land D \sim \text{Bern}(\phi(1-\phi)^c)$<br>$\phi \sim \text{Beta}(\mu\tau,(1-\mu)\tau)$                                              |
| **Objective**                 | $\max_{\phi} P(S\|\phi)=\phi$ | $\max_{\phi} P(S\land D\|\phi)=\phi(1-\phi)^c$ | Same as M1â€²                                                                                                | Same as M1â€²                                                                                                                              |
| **Representative  optimizer** | $\phi^\star=1$                | $\phi^\star=1/(c+1)$                           | $\mu$ solves $\frac{1}{\mu}=\sum_{k=1}^c \frac{1}{k-\mu}$;<br>approx. $\mu^\star\approx 1/(\log c+\gamma)$ | $\frac{1}{\mu\tau}=\sum_{k=0}^c \frac{1}{(1-\mu)\tau+k}$;<br>special case $c=1$: $\mu^\star=1/2$, $\tau^\star=\max\{\sqrt{V/(4i)}-1,0\}$ |
| **Interpretation**            | Pure MLE (prediction)         | MLE with complexity drag $c$ (prediction)      | Empirical-Bayes calibration of aspiration (prediction-based prescription, Prop.1)                          | Aspiration + optimal ignorance tradeoff (expected payoff, Prop.2)                                                                        |

**M1: Naive Commitment.** The founder maximizes $P(S|\phi)=\phi$, yielding $\phi^\star=1$. This trivial solution embodies the naive â€œfake it till you make itâ€ mentality: always promise the maximum. It ignores complexity and is unrealistic.

**M1â€²: Complexity as Constraint.** With operational complexity $c$, success requires delivering through $c$ interdependent tasks: $P(S\land D|\phi)=\phi(1-\phi)^c$. Reliability engineering interprets $(1-\phi)^c$ as the chance all $c$ subsystems succeed; Bayesian inference interprets it as the likelihood of one success after $c$ failures. Either way, the optimum shifts to $\phi^\star=1/(c+1)$. Complexity tempers ambition.

**M2: Empirical-Bayes Calibration of Aspiration.** Rather than choose a fixed $\phi$, the founder sets a prior mean $\mu$ with $\tau=1$. The objective is

$$\max_{\mu}\; \int_0^1 \phi(1-\phi)^c\,p(\phi|\mu,1)\,d\phi = \max_{\mu}\;\frac{B(1+\mu,1+c-\mu)}{B(\mu,1-\mu)}.$$

This is empirical-Bayes calibration (Gelman et al., _Bayesian Data Analysis_).

**Proposition 1 (Aspiration Calibration under Complexity).** When promises face complexity $c$, optimal aspiration is calibrated downward: $\phi^\star=1/(c+1)$; equivalently, the optimal prior mean $\mu$ satisfies $\tfrac{1}{\mu}=\sum_{k=1}^c 1/(k-\mu)$ and approximates $1/(\log c+\gamma)$.

_Implication._ Aspiration falls with complexity. Better Place who had higher complexity c than Tesla could have reduced $\mu$ but did not.

**M2â€²: Aspiration Plus Optimal Ignorance.** Now both $\mu$ and precision $\tau$ are chosen:

$$\max_{\mu,\tau}\; V\int_0^1 \phi(1-\phi)^c\,p(\phi|\mu,\tau)\,d\phi-\tau i.$$

Another name of precision parameter $\tau$ is concentration parameter. Yet another is pseudo-sample size (Gelman et al, 2015, pseudo counts in McElreath, 2022). Deeper knowledge is expected from precise priors hence they require  more surprising data to start shifting.The first-order condition $V\frac{\partial}{\partial \tau}\,\mathbb{E}[\phi(1-\phi)^c] = i$ means marginal value equals cost, leading to Proposition 2a.

**Proposition 2a (General principle).** The optimum $(\mu^\star,\tau^\star)$ equates the marginal value of additional precision with its marginal cost.

**Proposition 2b (Special cases).**
- If $i=0$: then $\tau^\star\to\infty$ and $\mu^\star=1/(c+2)$.
- If $c=1$: then $\mu^\star=1/2$ and $\tau^\star=\max{(\sqrt{V/(4i)}-1,0)}$.

**Proposition 2c (Fixed aspiration).** For fixed $\mu$, 
$$
\tau^*\;\approx\;\sqrt{\frac{V}{i}\cdot \frac{c}{2}\,\mu\,(1-\mu)^{\,c-1}\,\big(2-(c+1)\mu\big)},\quad 0<\mu<\frac{2}{c+1}.
$$

**Interpretation** 
- $\tau^\star$ increases in proportion to venture value $V$ (high-value ventures justify more precision).
- $\tau^\star$ decreases as information-integration cost $i$ rises (higher costs discourage paying for precision).
- $\tau^\star$ also decreases as complexity $c$ rises, because each additional subsystem multiplies the downside of bold promises, so the marginal payoff from further precision is diluted.


---


# 3. Practice: Case, Prescription, Prediction

This section validates the theory from sec.2 across three layers: Figure of Theory develops the logic (Ï„ as endogenous lever), Table of Practice distills it into managerial guidance, and Figure of Prediction illustrates survival consequences. Analyzing cases functions as a Bayesian retrodictive check, while making predictions under intervention offers a forward-looking predictive check.

## 3.1 Case: Better Place vs. Tesla

Tesla and Better Place provide a natural experiment showing how precision (Ï„) design shapes venture trajectories. Better Place assumed high Ï„ from the outsetâ€”rigid promises about swap times, sales targets, and infrastructureâ€”despite high complexity (c) and high information-integration cost (i). This deterministic posture created a **learning trap**: new evidence could not shift commitments, leading to collapse.

Tesla, by contrast, began with low Ï„â€”broad but legitimate promises (â€œ200+ milesâ€)â€”and used staged products as sequential experiments. Each launch generated evidence, lowered i through tighter organizational routines, and raised V by proving demand. Only then did Tesla raise Ï„, gradually tightening commitments. In Bayesian terms, Tesla preserved the ability to learn before concentrating promises, whereas Better Place foreclosed learning by committing too tightly too early.

Panels (aâ€“c) of Figure of Theory formalize this contrast: Î¼ falls with complexity c (control variable), while Ï„ rises only as i falls and V rises (design lever). Tesla managed Ï„ dynamically; Better Place assumed it.

![[fig(theory).png]]
**Figure of Theory. Bayesian foundations of entrepreneurial adaptation.**  
Panel (a) shows aspiration Î¼ is passively constrained by complexity c; (b) shows precision Ï„âˆ— rises only as information-integration cost i falls and value V increases; (c) shows posterior updating depends on Ï„â€”low Ï„ allows learning, high Ï„ blocks it. **Together these panels illustrate that aspiration is limited by environment, but precision is actively earnedâ€”Ï„ is the founderâ€™s design lever for turning evidence into adaptation.


---

## 3.2 Prescription: Acculturate to Concentrate

The central prescription is straightforward:

> **Acculturate to concentrate.** Precision must be earned by lowering information-integration cost (i) and raising venture value (V).

**Table of Practice. Precision Management Checklist**

| Lever                                | Diagnostic Question                                                                               | How to Reduce                                                         | Success (Tesla)                                                                                                                                          | Failure (Better Place)                                          |
| ------------------------------------ | ------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------- |
| **Information-integration cost (i)** | _When the organization chooses to absorb new information, how quickly can it coordinate and act?_ | Flatten structures; unify vocabulary; codify heuristics for iteration | During â€œproduction hell,â€ Tesla emphasized speed over perfection, kept gates open, corrected errors quickly, and created a shared language across teams. | Fragmented teams and inconsistent vocabularies slowed response. |
| **Precision (Ï„)**                    | Is specificity matched to earned reductions in i and increases in V?                              | Stage commitments; raise Ï„ only after organizational readiness        | Tesla staged promises: broad â†’ â€œ200+ milesâ€ â†’ Model 3 forecasts, increasing Ï„ only after iâ†“ and Vâ†‘.                                                      | Better Place launched with rigid swaps unsupported by i or V.   |

Tesla reduced i and increased V before raising Ï„; Better Place did the opposite. This checklist helps investors and educators diagnose whether founders are **earning precision** or prematurely locking it in.

## 3.3 Prediction: Staged Precision Hypothesis

From cases and theory emerges a testable hypothesis:

> _Ventures that start with low Ï„ under high complexity and high information-integration cost, and raise Ï„ only as iâ†“ and Vâ†‘, will outperform those that assume high Ï„ prematurely._

Founder language provides a measurable proxy: rigid, quantified promises signal high Ï„; broad, flexible claims signal low Ï„. A hierarchical Bayesian model applied to pitch decks and communications can estimate Ï„ trajectories, then link them to survival, funding, and pivots.

**Figure of Prediction** visualizes this: Tesla-like â€œearned precisionâ€ trajectories sustain survival, while Better Placeâ€“like â€œpremature precisionâ€ trajectories collapse.



# 3. Practice: Case, Prescription, Prediction

Section 3 validates theory developed in sec.2. links our contribution across three layers: Figure of Theory develops the theory (Î¼ vs. c, Ï„ vs. i, deterministic vs. probabilistic, all-in vs. sequential), Table of Practice distills this into practice (a checklist of managerial actions), and Figure Y delivers prediction (ventures that manage Ï„ as prescribed achieve higher survival probabilities). Analyzing cases correspond to Bayesian retrodictive check while making predictions under intervention in yet unseen situation (Hoffman )is predictive check predicting is predictive check, testing the prescription is 
## 3.1 Case: Better place vs. Tesla

Sec.3.1 validates theorized benefit of probabilistic reasoning and sequential execution using case analysis. Tesla illustrates sequential approximation, while Better Place illustrates the dangers of one-shot bets. This sets the stage for practical prescriptions on how founders can deliberately manage Ï„ through c and i.
### 3.1.1 Contrasting Reasoning Capabilities: Deterministic vs. Probabilistic

Better Place remained trapped in a deterministic M1â€² frame: precise sales targets (â€œ100k in Israel by 2011â€), exact swap times (â€œexactly 3 minutes,â€ later â€œ59.1 secondsâ€), and fixed station costs (â€œ$0.5M,â€ actually >$2M). Excess precision structurally blocked learning. Tesla, by contrast, operated in an M2â€² mode: it reframed â€œ250 milesâ€ as â€œ200+ miles,â€ preserving legitimacy while allowing updates. Early Roadsters were used as paid experiments to probe elasticity, preferences, and demand. Independent validations were published and targets revised transparently. Starting with low Ï„ and gradually raising it through staged learning, Tesla treated aspiration and precision as design variables to be earned, not assumed.

Panels (a) and (b) of Figure of theory formalize this logic. Panel (a) shows how **aspiration ($\mu^*$) is constrained by complexity**: only by simplifying interdependencies could Tesla maintain ambitious goals. Panel (b) shows how **precision ($\tau^*$) depends on integration cost**: Tesla lowered ii to justify tighter commitments, while Better Place ignored its high ii and locked in rigid precision. These dynamics mark the transition from deterministic M1â€² reasoning to probabilistic M2â€² reasoning.

### 3.2.2 Contrasting Approximation Strategies: All-in vs. Sequential Sampling
Better Place exemplified a **one-shot bet** strategy. From inception it invested roughly $850M in a nationwide battery-swap infrastructure, precommitting to a single, rigid high-Ï„ posterior. This strategy resembled deterministic reasoning: management assumed that a precise ex-ante plan could substitute for adaptation. As a result, when sales stalled (~1,400 units) and external signals pointed to shifting demand and standards, Better Place had locked itself into what I call a â€œworse posterior place.â€ Its prior was so tight that new evidence could not meaningfully shift its commitments.

Tesla, by contrast, approximated uncertainty through **sequential sampling**. Muskâ€™s 2006 â€œSecret Master Planâ€ staged learning deliberately: (1) sports car, (2) mid-price car, (3) mass-market car, (4) solar integration. Each stage funded and informed the next, with production ramping 2.5k â†’ 50k â†’ 500k and Ï„ increasing stepwise. Tesla treated each product launch as a posterior update, raising precision only after accumulating evidence that complexity (ccc) had been simplified and integration cost (iii) reduced.

Panel (c) of Figure of theory illustrates these dynamics. A high-Ï„ prior, like Better Placeâ€™s, barely shifts after observing failure, leading to **containment and rigidity**. A low-Ï„ prior, like Teslaâ€™s, shifts substantially, allowing **contraction and adaptation**. This visualization clarifies why both extremes of the traditional schools are maladaptive: the **action school** risks remaining under-committed with perpetually low Ï„, while the **planning school** locks in prematurely with high Ï„. Our synthesis shows that Ï„ should neither remain low nor be set high a priori, but should **grow only as ventures simplify complexity and acculturate integration.**

---
![[fig(theory).png]]

**Figure of Theory. Bayesian foundations of entrepreneurial adaptation.**  
Panel (a) shows that optimal aspiration $\mu^*$ declines with complexity (c): Tesla, with fewer subsystem interdependencies, could aspire higher than Better Place.  
Panel (b) shows that optimal precision $\tau^*$ rises as information-integration cost (i) falls: Tesla lowered ii during _production hell_, earning precision adaptively, while Better Place sustained high ii yet committed to high precision prematurely.  
Panel (c) shows how priors update into posteriors. A low-Ï„ prior (Tesla) contracts significantly upon observing failure, enabling rapid pivots, whereas a high-Ï„ prior (Better Place) barely shifts, leading to containment and rigidity.  
Together these panels illustrate our central argument: **aspiration must be simplified, and precision must be acculturated, or else evidence fails to translate into adaptation.**


## 3.2 Prescription: Simplify to Aspire, Sync to Concentrate

Panels (a) and (b) of Figure X provide the theoretical foundation for our prescriptions. Panel (a) shows that optimal aspiration Î¼âˆ— is inversely related to complexity c: unless ventures deliberately simplify, aspirations will collapse as interdependencies grow. Panel (b) shows that optimal precision Ï„âˆ— rises only when information-integration cost i is reduced: precision cannot be assumed; it must be earned through organizational design. Together, these panels formalize our two principles: **simplify to aspire** and **acculturate to concentrate**.

Table of Practice translates these principles into a practitionerâ€™s checklist. Each row links a diagnostic question to methods for reducing either complexity or integration cost, and illustrates success through Teslaâ€™s trajectory and failure through Better Placeâ€™s. Tesla consistently simplified and lowered integration cost before raising the specificity of its commitments, thereby earning precision. Better Place, by contrast, began with precise promises despite high complexity and high integration cost, locking itself into rigidity.

**Table of Practice. Precision Management Checklist with Illustrative Examples**

| Lever                    | Diagnostic Question                                                  | How to Reduce                                                                                                 | Success Example (Tesla)                                                                                                                                                                            | Failure Example (Better Place)                                                                        |
| ------------------------ | -------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------- |
| **Integration Cost (i)** | Are organizational _clockspeeds_ synchronized with external signals? | Acculturate (Fine, 2022); flatten structures; build shared vocabulary; codify heuristics for rapid iteration. | During its struggle to deliver roadster, Musk emphasized speed over perfection, kept â€œgates openâ€ to release parts, corrected errors quickly, and unified teams with terms like â€œproduction hell.â€ | Fragmented teams and inconsistent vocabularies slowed adaptation and kept i high.                     |
| **Complexity (c)**       | How many subsystems must succeed simultaneously?                     | Challenge assumptions; focus on one dominant â€œphysicsâ€; serialize breakthroughs.                              | Tesla rejected the â€œbattery swapâ€ assumption and concentrated on battery packs, reducing subsystem interdependencies.                                                                              | Better Place pursued robotics, real estate, utilities, and OEM standards in parallel, raising c.      |
| **Precision (Ï„)**        | Is specificity matched to earned reductions in i and c?              | Link commitments to demonstrated progress; increase Ï„ only after lowering i and c.                            | Tesla staged promises: broad vision â†’ 200+ mile range â†’ Model 3 at $35,000 â†’ multi-million-unit forecasts.                                                                                         | Better Place launched with â€œ3-minute swaps at 500,000 stations,â€ unsupported by reductions in i or c. |

This table conveys the essence of our prescription. Tesla reduced i and c before raising Ï„; Better Place did the opposite. Investors and educators can apply this framework to assess whether founders are earning precision or prematurely locking it in.

## 3.3 Prediction: A Hierarchical Bayesian Analysis of Founder Language

I move from cases to testable predictions by treating **founder language as a window into prior precision (Ï„) and aspiration (Î¼)**. Rigid, quantified, time-bound promises signal high Ï„; broader, more flexible claims signal low Ï„\tau. Using a hierarchical Bayesian model applied to pitch decks, investor updates, and public communications, I can estimate venture-specific trajectories of Î¼\mu and Ï„\tau, then link them to outcomes such as survival, funding, and pivots.

This approach builds on prior work showing that strategy must be studied at the firm-specific level rather than through average effects (Mackey, Barney, & Dotson, 2017). It resonates with evidence that decision-makers infer unobserved â€œphantom attributesâ€ from observed signals (Bell & Dotson, 2022), suggesting that investors infer venture feasibility from the precision of founder communication. It also aligns with the resource-based view recast as a stochastic process (Wibbens, 2021), as I model aspiration and precision as dynamic latent states. 

From these foundations, our propositions yield straightforward hypotheses: ventures that start with low Ï„ and raise it gradually as c and i decline will outperform those that begin with high Ï„ despite high c and i. **Figure of Prediction** visualizes these predictions: Tesla-like â€œearned precisionâ€ trajectories sustain higher survival probabilities, while Better Placeâ€“like â€œpremature precisionâ€ paths collapse quickly.

 Problem remains how to gather optimal entrepreneurs who behaves (1) **simplify to aspire**: aspiration falls as complexity (c) rises; (2) **acculturate to concentrate**: precision rises only as integration cost, acknowledged as "Bayesian Entrepreneurs are not commonly found in the wild" (Arora, 2025). 
 ![[Pasted image 20250921032129.png]]
 

**Figure of Prediction. Predicted venture survival under different precision trajectories.**  
This figure visualizes our prediction: ventures that manage precision as prescribedâ€”**simplifying to sustain aspiration and acculturating to earn concentrationâ€”exhibit higher survival probabilities** (red, Tesla-like trajectory). Ventures that assume high precision prematurely despite high complexity and integration cost collapse quickly (skyblue, Better Place-like trajectory). This completes the sequence: **Figure of Theory shows the theory, Table of Practice distills it into practice, and the Figure of Prediction demonstrates the expected performance consequences.**

## 4\. Conclusion and Vision

### 4.1 Conclusion
Venture's success probability is anatomized (sec.2.1), unified (sec.2.2), reasoned, programmed, and implemented around the relationship between founder and its venture's probabilistic adaptation. I reframe promises as an aspirationâ€“precision prior, with aspiration (Î¼) constrained by complexity (c) and precision (Ï„) earned only as integration costs (iii) fall. The central prescription is simple but powerful: **simplify to aspire, acculturate to concentrate.** This unifies the long-standing **action school** (which tends to remain at low Ï„) and the **planning school** (which assumes high Ï„ ex ante) by showing how ventures can move from low to high precision gradually, through deliberate simplification and acculturation. Therefore, I translate one layer of founder's nature into nurture i.e. into principles to manage complexity, information, and precision over time.

### 4.2 Vision by Target Users

- **For Theorists.** Building on Unifying Bayesian and evolutionary perspectives by implementing aspiration, concentration, promise (bits) with bodies of founder and venture and approximating the promise distribution with samples (atoms). Open questions remain on how founders capable of prediction-based prescription not only adapt to but also shape their environments. What implication does this have on irreversibility and path dependency? Just as aging is not an universal phenomenon (An et.al., 2025), can firm's aging also be understood as a choice? Whatever the answer is startups are great fruit fly model (Fine, 2000) to test anti-aging hypotheses.
    
- **For Empiricists.** Founder language offers a measurable proxy for Ï„. Hierarchical Bayesian methods enable estimation of heterogeneous trajectories of aspiration and precision, moving beyond average effects and IV-limited designs (Mackey et. al., 2015, Mackey and Dotson, 2024).
    
- **For Founders.** Precision must be earned. Simplify world model () which assumption matters, reduce integration costs, and stage commitments so that Ï„ increases only as the venture learns. Managing ignorance deliberately becomes a central capability.
    
- **For Educators, Investors, and Policymakers.** Assess not just vision (Î¼) but calibrated realism (dynamic Ï„). Teach and evaluate when ventures should favor flexibility or efficiency, grounding these judgments in measurable c and i rather than slogans.

## 5\. References

An, K., Hwang, M., Kim, Y., Lee, H., Park, J., Hong, H., Sol, H., Moon, H., & Han, S. (2025).Â _AI insiders: Future report by global top-tier experts_. Smartbooks.

*Agrawal, A., Gans, J., & Stern, S. (Eds.). (2024). Bayesian entrepreneurship. MIT Press.*

*Brinkerink, J. (2025). Negative Capability and founderial Action. Strategic Change.Baker, C. L.,* 

*Saxe, R., & Tenenbaum, J. B. (2011). Bayesian theory of mind: Modeling joint belief-desire attribution. Proceedings of the Annual Meeting of the Cognitive Science Society, 33, 2469-2474.*

*Baker, C. L., Jara-Ettinger, J., Saxe, R., & Tenenbaum, J. B. (2017). Rational quantitative attribution of beliefs, desires and percepts in human mentalizing. Nature Human Behaviour, 1(4), 0064\.*

*Bateson, G. (2000). Steps to an ecology of mind: Collected essays in anthropology, psychiatry, evolution, and epistemology. University of Chicago press.*

Bell, J. J., & Dotson, J. P. (2022). Phantom attributes: Unpacking product perceptions. _Journal of Consumer Research, 49_(3), 523â€“546.

*Camuffo, A., Cordova, A., Gambardella, A., & Spina, C. (2020). A scientific approach to founderial decision making: Evidence from a randomized control trial. Management Science, 66(2), 564-586.*

*Camuffo, A., Gambardella, A., Messinese, D., Novelli, E., Paolucci, E., & Spina, C. (2024). A scientific approach to founderial decision making: Large scale replication and extension. Strategic Management Journal, forthcoming.*

Dotson, J. P. (2010). Strategic satisfaction and decision-making under uncertainty. _Strategic Management Journal, 31_(5), 457â€“477.

*Felin, T., & Kauffman, S. (2021a). Disruptive evolution: Harnessing functional excess, experimentation and science as tool. Industrial and Corporate Change, 30(2), 446-466.*

*Felin, T., & Kauffman, S. (2021b). The search function and evolutionary novelty. In S. Kauffman (Ed.), A world beyond physics (pp. 122-145). Oxford University Press.*

*Felin, T., & Zenger, T. R. (2009). founders as theorists: On the origins of collective beliefs and novel strategies. Strategic entrepreneurship Journal, 3(2), 127-146.*

*Fine, C. H. (1986). Quality improvement and learning in productive systems. Management Science, 32(10), 1301-1315.*

*Fine, C. H. (1998). Clockspeed: Winning industry control in the age of temporary advantage. Perseus Books.*

*Fine, C. H. (2022). Operations for founders. MIT Press.*

*Fine, C. H., & Freund, R. M. (1990). Optimal investment in product-flexible manufacturing capacity. Management Science, 36(4), 449-466.*

*Fine, C. H., & Li, L. (1988). Technology choice, product life cycles, and flexible automation. Journal of Manufacturing and Operations Management, 1(4), 372-399.*

*Fine, C. H., Vardan, R., Pethick, R., & El-Hout, J. (2002). Rapid-response capability in value-chain design. MIT Sloan Management Review, 43(2), 69-75.*

*Gelman, A., & Shalizi, C. R. (2013). Philosophy and the practice of Bayesian statistics. British Journal of Mathematical and Statistical Psychology, 66(1), 8-38.*

*Gelman, A., Simpson, D., & Betancourt, M. (2017). The prior can often only be understood in the context of the likelihood. Entropy, 19(10), 555\.*

*Gould, S. J., & Vrba, E. S. (1982). Exaptation--a missing term in the science of form. Paleobiology, 8(1), 4-15.*

*Griffiths, T. L., & Tenenbaum, J. B. (2009). Theory-based causal induction. Psychological review, 116(4), 661\.*

*Huh, W. T., Kim, M. J., & Lin, M. (2025). Uncertain search with knowledge transfer. Management Science.*

Jake M. Hofman 1,17 âœ‰ , Duncan J. Watts 2,3,4,17 âœ‰ , Susan Athey5 , Filiz Garip6 , Thomas L. Griffiths7,8 , Jon Kleinberg9,10 , Helen Margetts11,12 , Sendhil Mullainathan13 , Matthew J. Salganik6 , Simine Vazire14, Alessandro Vespignani 15& Tal Yarkoni16 Integrating explanation and prediction in computational social science

*Jara-Ettinger, J., Gweon, H., Schulz, L. E., & Tenenbaum, J. B. (2016). The naÃ¯ve utility calculus: Computational principles underlying commonsense psychology. Trends in cognitive sciences, 20(8), 589-604.*

*Kahneman, D., & Tversky, A. (1979). Prospect theory: An analysis of decision under risk. Econometrica, 47(2), 263-291.*

*Knight, F. H. (1921). Risk, uncertainty and profit. Houghton Mifflin.*

*Mackey, T., & Dotson, J. (2024). Bayesian Statistics in Management Research: Theory, Applications, and Opportunities. Oxford Research Encyclopedia of Business and Management.*

*Novelli, E., & Spina, C. (2024). Causal reasoning and the scientific founder. In A. Agrawal, J. Gans, & S. Stern (Eds.), Bayesian entrepreneurship (Chapter 6). MIT Press.*

*Phillips, J., Morris, A., & Cushman, F. (2019). How we know what not to think. Trends in Cognitive Sciences, 23(12), 1026-1040.*

*Sarasvathy, S. D. (2001). Causation and effectuation: Toward a theoretical shift from economic inevitability to founderial contingency. Academy of Management Review, 26(2), 243-263.*

*Skali Lami, O. (2022). Predictive and Prescriptive Analytics in Operations Management (Doctoral dissertation, Massachusetts Institute of Technology).*

*Tenenbaum, J. (1998). Bayesian modeling of human concept learning. Advances in neural information processing systems, 11\.*

*Zellweger, T., & Zenger, T. (2023). founders as scientists: A pragmatist approach to producing value out of uncertainty. Academy of Management Review, 48(3), 379-408.*


    Stevenson, H. H. (1983). A perspective on entrepreneurship. KAO, John J. The.
- Sanborn, A. N., & Chater, N. (2016). Bayesian brains without probabilities.Â _Trends in cognitive sciences_,Â _20_(12), 883-893.
    
- Mackey, T. B., Barney, J. B., & Dotson, J. P. (2017). Corporate diversification and the value of individual firms: A Bayesian approach. _Strategic Management Journal, 38_(3), 322â€“341.
    
- Wibbens, P. D. (2021). A formal framework for the RBV: Resource dynamics as a Markov process. _Strategic Management Journal, 42_(1), 3â€“29.
    

---

ğŸ‘‰ Would you like me to also **sketch Figure Y** (the prediction figure) so that it mirrors Figures X and Table X â€” i.e., theory â†’ practice â†’ prediction â€” with Tesla-like and Better Placeâ€“like survival curves side by side?

# Appendix A. Dictionary of Key Terms

**Aspirationâ€“precision prior.** A Beta distribution parameterized by mean $\mu$ (aspiration) and precision $\tau$. Encodes how bold ($\mu$) and how rigid ($\tau$) a founderâ€™s promise is.

**Aspiration ($\mu$).** The mean of the prior distribution; represents the boldness of the promise.

**Precision ($\tau$).** The concentration of the prior distribution; interpretable as pseudoâ€“sample size, the rigidity of the promise, or the degree of prior evidence.

**MLE (Maximum Likelihood Estimation).** A classical method that chooses parameter values to maximize the likelihood of observed data.

**Empirical Bayes.** A procedure that estimates prior parameters (like $\mu$ or $\tau$) by maximizing the marginal likelihood of the data 

**Hierarchical Bayes.** A Bayesian modeling strategy where parameters (such as $\phi$) themselves have distributions governed by hyperparameters (such as $\mu,\tau$). Integrating over these priors yields predictive distributions.

**Prior.** A probability distribution placed on a parameter before observing current data; represents prior knowledge (**not information**).

**Ignorance prior.** A deliberately vague or low-precision prior, chosen to reflect high flexibility and openness to evidence.

**Marginal likelihood.** The probability of data integrated over the prior distribution: $\int p(data|\phi)p(\phi|\mu,\tau)d\phi$. Used for model comparison and empirical Bayes calibration.

**Value of information (VOI).** The increase in expected payoff from gaining additional precision; in M2â€² this trades off against the integration cost $i$.

**Optimal ignorance.** The principle that precision should only be raised until its marginal value equals its marginal cost; beyond that, it is optimal to remain ignorant (low $\tau$).


[[ğŸ—„ï¸ğŸ§ charlie]]
# Appendix B

### Proof of Proposition 1

Derivative of $\phi(1-\phi)^c$ gives condition $1/\phi-\sum_{k=1}^c 1/(k-\phi)=0$. Unique interior solution yields $\phi^\star=1/(c+1)$. In empirical-Bayes form, maximize $B(1+\mu,1+c-\mu)/B(\mu,1-\mu)$. Taking derivative yields $1/\mu=\sum_{k=1}^c 1/(k-\mu)$. For large $c$, harmonic approximation $H_c\sim \log c+\gamma$ gives $\mu^\star\approx1/(\log c+\gamma)$.

### Proof of Proposition 2a  (General principle)

Start with objective $g(\mu,\tau)=V\mathbb{E}[\phi(1-\phi)^c]-\tau i$ with $\phi\sim\text{Beta}(\mu\tau,(1-\mu)\tau)$. Differentiating with respect to $\tau$ and setting to zero gives marginal benefit = cost.

### Proof of Proposition 2b (Special cases)
- If $i=0$, $\tau^\star\to\infty$ and $\mu^\star=1/(c+2)$.
    
- If $c=1$, $\mathbb{E}[\phi(1-\phi)]=\mu(1-\mu)\tau/(\tau+1)$. Maximizing over $\mu$ gives $\mu^\star=1/2$. Then $g(1/2,\tau)=V(\tau/(\tau+1))(1/4)-\tau i$. Differentiating and solving yields $\tau^\star=\max{\sqrt{V/(4i)}-1,0}$.

Weâ€™re maximizing

$$g(\mu,\tau)=V\,\mathbb{E}[\phi(1-\phi)]-\tau i,\quad \phi\sim\mathrm{Beta}(\mu\tau,(1-\mu)\tau).$$

1. **Expectation.** For $c=1$,
    

$$\mathbb{E}[\phi(1-\phi)]=\frac{\alpha\beta}{(\alpha+\beta)(\alpha+\beta+1)}=\frac{\mu(1-\mu)\,\tau}{\tau+1},$$

with $\alpha=\mu\tau,\ \beta=(1-\mu)\tau$.

So

$$g(\mu,\tau)=V\,\frac{\tau}{\tau+1}\,\mu(1-\mu)-\tau i.$$

2. **Maximize w.r.t. $\mu$ (hold $\tau$ fixed).**
    

$$\frac{\partial}{\partial\mu}[\mu(1-\mu)]=1-2\mu.$$

Set to zero: $1-2\mu=0\Rightarrow \mu^\star=1/2$.

3. **Substitute $\mu^\star=1/2$.**
    

$$g(1/2,\tau)=V\,\frac{\tau}{\tau+1}\,\tfrac14-\tau i.$$

4. **Differentiate w.r.t. $\tau$.**
    

$$\frac{d}{d\tau}\left(\frac{\tau}{\tau+1}\right)=\frac{1}{(\tau+1)^2}.$$

So

$$\frac{\partial g}{\partial \tau}=V\cdot\tfrac14\cdot\tfrac{1}{(\tau+1)^2}-i.$$

5. **Solve.**
    

$$\frac{V}{4(\tau+1)^2}=i\Rightarrow (\tau+1)^2=V/(4i)\Rightarrow \tau^\star=\max\{\sqrt{V/(4i)}-1,0\}.$$

---

### Appendix C: Miscellaneous for future Angie 
#### Simple Rule for Optimal Precision $\tau^*(\mu,c)$

##### Level 1: Parsimonious Plug-in Formula

I derive a simple approximation for the optimal precision level that balances value creation against information costs. The optimal precision can be expressed as:

$$\boxed{\tau^*(\mu,c;V,i) \approx \sqrt{\frac{V}{i}} \cdot \underbrace{\sqrt{\frac{c}{2}\mu}(1-\mu)^{\frac{c-1}{2}}}_{\text{core shape in }(\mu,c)} \cdot \underbrace{\sqrt{\max\{0, 2-(c+1)\mu\}}}_{\text{feasibility cap}}}$$

This expression decomposes into three multiplicative components. First, the term $\sqrt{V/i}$ represents the valueâ€“cost lever that scales the entire precision surface upward or downward based on the ratio of value creation potential to information cost. Second, the core shape function $\sqrt{(c/2)\mu}(1-\mu)^{(c-1)/2}$ captures the fundamental relationship between aspiration level and complexity, exhibiting a single-peaked behavior in $\mu$. Notably, for practical aspiration levels, this component decreases in complexity $c$ after small values of $c$. Third, the feasibility cap $\sqrt{2-(c+1)\mu}$ enforces a boundary condition that drives $\tau^*$ toward zero as $\mu$ approaches $2/(c+1)$, ensuring that interior solutions require $\mu < 2/(c+1)$.

##### Level 2: One-Line Surrogate for Fast Calibration

When the feasibility constraint is not binding (specifically when $\mu \leq 1/(c+1)$), I can employ a simplified expression that omits the cap term:

$$\boxed{\tau^*(\mu,c;V,i) \approx \sqrt{\frac{V}{i}} \cdot \sqrt{\frac{c}{2}\mu}(1-\mu)^{\frac{c-1}{2}}}$$

The comparative statics of this surrogate formula reveal important managerial insights. The optimal precision increases with value potential ($\partial\tau^*/\partial V > 0$) and decreases with information cost ($\partial\tau^*/\partial i < 0$), as expected. More interestingly, for typical aspiration levels where $\mu \in (0,1/2]$, the optimal precision $\tau^*$ decreases as complexity $c$ increases. Furthermore, holding complexity fixed, $\tau^*$ exhibits single-peaked behavior in aspiration level $\mu$ over the feasible interval $(0, 2/(c+1))$.


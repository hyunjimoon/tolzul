---
collection:
- '[[People]]'
field:
- ğŸ…cba
- ğŸ‘¾cog
atom: ğŸ§­atom(PCOğŸ”ƒ)
created: '2024-04-13'
---

what i learned based on cathy's explanation on how each methodologies emerged
- RL in response to control at scale in different transportation conditions (circular and intersecting road under dry and rainy weather)
- DRL in response to the need for cheaper computational cost and phenomena that "optimal actions are similar across between similar states"
- reward shaping in response to reward sparsity and theory that "adding potential function converges to optimal policy"
- transfer learning in response to learn at scale given that training is expensive and evaluation is cheap
- inverse RL in response to learn implicit goals of an agent
- Q-learning in response to ...
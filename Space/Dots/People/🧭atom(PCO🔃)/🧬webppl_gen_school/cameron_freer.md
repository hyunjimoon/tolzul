---
collection:
- '[[People]]'
field:
- 🐅cba
- 👾cog
atom: 🧭atom(PCO🔃)
created: '2025-04-27'
---

2025-04-27

Posterior distributions are computable from predictive distributions https://cfreer.org/papers/FreerRoyAISTATS2010.pdf
An Application of Computable Distributions to the Semantics of Probabilistic Programs https://arxiv.org/abs/1806.07966
https://statmodeling.stat.columbia.edu/2025/01/17/how-far-can-exchangeability-get-us-toward-agreeing-on-individual-probability/
```
> calibration does not satisfy everyone as a means of ensuring good decisions

Could an algorithm that helps individuals determine the optimal test quantity for their specific situations address this issue?

If there’s potential demand for such an algorithm, I’d be eager to explore this idea further. I’m also curious whether the workflow focused on test quantity, as outlined in the poster below (Fig.2), aligns with practical needs:  
[https://github.com/Data4DM/stanify/blob/main/vignette/FiddamanMoon23_BayesSD.pdf](https://github.com/Data4DM/stanify/blob/main/vignette/FiddamanMoon23_BayesSD.pdf)
```


randomness : complexity - 
1. engineering
2. epistomlogical
3. observation
4. convieniet to simplify (collapsing to noise)

if the initial problem you set up is difficult, adding noise (more attractable, informative about the origianl) - inference controller - 

exchangeability is 

[[risk_reward]]
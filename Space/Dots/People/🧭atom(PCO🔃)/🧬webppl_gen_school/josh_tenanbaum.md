---
collection:
- '[[People]]'
field:
- üêÖcba
- üëæcog
atom: üß≠atom(PCOüîÉ)
created: '2024-09-10'
---

[[09-23|25-09-23]]
analysis of josh's selling RMC in [[pc2_tennanbaum24w2w 1.txt]]

Looking at the Word to Worlds model diagram and Josh's presentation, I can see several key rhetorical strategies he uses:

1. **Concrete grounding before abstraction**: He starts with tangible examples (ChatGPT stacking objects) before diving into theory
2. **Personal narrative threads**: He weaves in stories about students, colleagues, and research evolution
3. **Progressive complexity**: Each concept builds naturally on the previous one
4. **Visual anchoring**: Complex ideas are always tied to specific visual examples or experiments
5. **Bridging phrases**: He uses phrases like "So what's going on here?" and "Now how does that work?" to create natural transitions
6. **Acknowledging limitations**: He's upfront about what the models can and can't do
7. **Recursive return**: He circles back to earlier examples with deeper understanding

For the Tesla example, I should connect it to the four types of reasoning while maintaining Josh's accessible yet rigorous style.


[[966 Computational Cognitive Science]]
2024-11-05
Do or do not. There's no try.
- Yoda from Starwars

Thanks for your patience and mentorship in describing my giraffe as comparing apple, oragne, and orchid.

2024-10-25
- has deep reverence to babies ("ok to have babies without getting married but not talking about them without have one")

2024-09-10
coordination issues of not touching the bird more than twice - 
move in (agency: goal and efficient ways to achieve the goal) 

cognitive capacity, behavioral of adults, qualitative for young, quantative for older

how do we get so much from so little (cognition: going beyound data given) - problem of induction

how does abstract knowledge guide learning and inference from sparse data, different domains and tasks, 
innvate specification experience

learning of evolutionary time (intelligence of emergence - evolutionary time)

cannot empirical study evolution (learning mechanism; intelligence comes from brain and cultural evolution, (data and social environment we grow up)  - different from gd, prob.prog; brain is amazing as itt build and repair itself)

what general principles might apply to all?

how much 

computational tools for framing the answer; priors are only there for evolution (designing the flexible priors) in ML prior is usually used for hardwired architecture, but actually not (entrenched are quite flexible - strong but felxible)

gravities are very strong prior but is very flexible (mental model - violating intuitve interpretation of physics of the world)

imagine data that can convince me. 

i guess that's the world we're living in

describe and explain what people think
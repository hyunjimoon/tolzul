---
collection:
- '[[People]]'
field:
- 🐅cba
- 👾cog
atom: 🧭atom(PCO🔃)
created: '2023-07-05'
---

- 
### 07.05. oh
- wiggle what utility we get from the decision (regardless of dgp): study the process by simulation (prior predictive to decision making process, use utility function to determine, )
-  ![[Pasted image 20230705134813.png]]

![[Pasted image 20230705134214.png]]
- negative values, consistent losses, 
- probable losses (can loss, but gain most of the time)

- informing decision (data-forward) vs prior circumstance (simulation approach)
- calibration is confusing (pre-calibration)
- tweak all three: choice (full), decision making strategy, utility function -> distribution of utilities
	- tweak  (how many data, information put in there, ) until we reach our goal
	- online algorithmic 
	- can only tweak utility function(year's quality of life / overall death)
	- experiment design, tweek heuristic and realistic thru simulation
- MLE: likelihood only depend on the summary statistics ()

- convex log function, often distribution of sufficient estimators are narrower, black rao only depends on 
- taking initial estimators, refactor (normal observation, simplified as sum(y), sum(y^2), can construct any estimator)

- estimating things from sample (freq: parameter, bayes:expectation values) - so inference changes from freq sense, but MC estimator efficiency change from bayes sense

- consistent distribution, allocation of probability is conserved, use the allocation and define expectation (data space to real numbers; avg to single number; overall behavior in the context of distribution, or can simulate from dist. function)

### jair's q on observational model
![[Pasted image 20230705143411.png]]
- simulation from distribution, not from density function
- `dbinom` is density function; `rbinom` is mechanism for gen. (diff operation from distubiton; can't represent abstract dist, but can simulate - represent indirectly using compuation)
- ratio and integral of density function are two important things
- after drop data-only function, then we get unique well (relative consistency of data - likelihood function)
![[Pasted image 20230705144033.png]]

- NOT simple plug in observed data to likelihood model; density and comparison (factor out subtly; take family density plug in, )
- observation (entire story) - progression of story (overall model), step in generative step (integrated in ) 
mh thinks "structural" mean "fixed rigid structure - confusing for e.g. population.
---
collection:
- '[[People]]'
field:
- ðŸ™ops
- ðŸ¢inv
- ðŸ‘¾cog
atom: ðŸ—ºï¸atom(PCOâ¬†ï¸â¬‡ï¸)
created: '2022-06-19'
---

#yk 
# 0515
### continuous and connected
function: conti
f^-1(connected) = connected
set: connected (disconnected ë˜ì–´ìžˆì§€ ì•ŠìŒ a, b a union b = X, a, b open in X)

### object and function
ì²´[ì£¼ì–´, ëª©ì ì–´] ìš©[ìˆ ì–´]

ìˆ˜í•™ì˜ ì •ì˜ë¶ˆê°€ ë‘ ìš©ì–´: set (obj), element (relation: aê°€ bì˜ element)
ì§‘í•©ë¡  (ë‹¨ì–´ëŠ” ìœ í•œê°œ):
function, relation, power set, real number

### axiom
axiom: hilbert 1~ axiom euclidean geometry (undefined: point, line(obj) point () lineì´ pointë¥¼ ì§€ë‚˜ê°„ë‹¤. 
axiom !=postulate
- uniqueness ()
ë‘ ì§ì„ ì´ ì•ˆ ë§Œë‚˜ê±°ë‚˜ í•œ ì ì—ì„œë§Œ ë§Œë‚¨ (ì´ axiom) 

[obj, rel], [obj, obj, rel(obj, obj)]

ì‚¬ê³¼ 3, 5ê°œ 
induction
1+1 = 2 ì„±ì§ˆ
1+1+1 = 0

ê³µë¦¬ê°€ ì£¼ì–´ì§€ë©´ ëŒ€ìƒ (í‰ë©´)ë“¤ì´ ìƒê¹€ (line, point)

what: math(T/F) 
how: algorithm ()


ì¦ëª…ì€ algorithm (A=Bë¡œ)
ìˆ˜í•™ì€ ì¦ëª…ì„ ëª»í•´ë„ t/fê°€ ìžˆë‹¤ (ëª¨ë“ X). ë°˜ë©´ ì»´í“¨í„°ëŠ” ì¦ëª…ì„ ëª»í•˜ë©´ unkown?
constructive, non-contstructive pf
P(yes) > 0

P = NP (unkown)
NPì„ ëª…ì œë¡œ ì“´ë‹¤ 
(ë¬¸ì œ, ë‹µ) ì±„ì ì€ ì‰½ê²Œ, í’€ê¸°ëŠ” ì–´ë ¤ìš´ ë¬¸ì œê°€ ìžˆë‹¤. (unkown)
trueì¸ ëª…ì œ

ì„¸ìƒì˜ ì§„ë¦¬ vs "ì¸ì‹"

ëª…ì œ (statement)T/Fë¥¼ ê°€ì§€ëŠ”. T.Fê°€ ì•„ë‹Œê±´ ìˆ˜í•™ë‚´ì— ìžˆì„ ìˆ˜ ì—†ë‹¤. 
axiomë„ ëª…ì œ (trueë¼ê³  ê°€ì •)

axiom-generated system (sp(axiom) \in (!=) system)

systemì•ˆì—ëŠ” trueì§€ë§Œ ì¦ëª…ì´ ë¶ˆê°€ëŠ¥ (ê´´ë¸ì¡°ê±´ ë§Œì¡±í•˜ë©´; ê±°ì˜í•­ìƒ??? - ì‹¤ìˆ˜ë¥¼ í¬í•¨í• ë§Œí¼ ë³µìž¡í•œ ì‹œìŠ¤í…œ)

ê·¼ì‚¬ì•Œê³ ë¦¬ì¦˜ì˜ ë°©í–¥: 
ìˆ˜ë ´í•´ì•¼ ê·¼ì‚¬

ìˆ˜í•™ digitize, ë¬¼ë¦¬ quantize (quantum - ì „ìž)

ë³µìž¡í•´ì„œ function

ìˆ˜í•™ì´ë¡ ì€ ì´ë¡ ê³„ì‚°ë§Œ ê°€ëŠ¥ (ë¶€ì •ì ë¶„, ì´í† )ì§„ì§œê³„ì‚°ì€ discrete
x ^2 = 2 sq(2)- ë‹µì˜ì¡´ìž¬ìžê°í‘œí˜„ = 1.414...

X(ëˆˆì´ê³„ì†) \in X** (ì›ëž˜ì„¸ìƒ) ê³„ì† ì»¤ì§ˆìˆ˜ ìžˆì§€ë§Œ ë‹¤ë£¨ê¸° ë‚œì´ vs ê°ˆë£¨ì•„ theory (í•œë²ˆ ê°”ë‹¤ì˜¤ë©´ completeí•´ì§€ëŠ”ê²ƒ) closure (ê°ˆë£¨ì•„ system)

|openset|:=2^N -> N
A matrix: Ax
rank is invariant of linear transfrom (basisì •í•˜ì§€ ì•ŠìŒ)-- ë°”ê¿€ë•Œ (basis, coordinate)ì•ˆë³€í•¨, graph (forest matroid)
maximalë˜ëŠ” ê°’ì€ matrixê°€

topological invariant (same topology, but different space) - same open set

ì •ì˜ì—­(ì˜ì—­) -> ì¹˜ì—­ (ê³µë³€ì—­ co-domain) co: ê°™ì´ (ì¢…ì†ì ìž„), ë¶€ "y"
(x vs co)
duality: co-vector (vector = contravariant vector vs covector = covariant vecor) vectoì— ëŒ€ì‘ë˜ëŠ”

|uncertainty(vector(w)) | = |uncertainty(vector(w), covector(w))|

"duality" = bijection

d/dx(vector ) = e: basis(=vector)ë¥¼ ë°”ê¾¸ë©´(2), d/dx(1/2): coeffì´ 1/2ì´ ë˜ë‹ˆê¹Œ covariantìª½ìœ¼ë¡œ ë”°ë¼ê°

basis2ë°°ë©´ formë“¤ì€ 2ë°°
2ê°€ ì¢Œí‘œê°€ 1ì´ë¨ (y=x -> y=2x: dual spaceê°€ ê°™ì´ ë‘ë°°ê°€ë¨. 1form: 2ë°°. ì¼ì°¨ì›ì—” 2form)
(a,b)-tensor

# 0522
connected - topology
clustering (connected)
topological invariant
topology - independence
![[Pasted image 20220522082753.png]]

indepë¥¼ ìˆ˜ì§ë°©í–¥ìœ¼ë¡œ ë´ì„œ ì§€ìš°ê¸° ë•Œë¬¸ì— ì•ˆ ë³´ìž„

![[Pasted image 20220522083522.png]]
ì˜†ì—ì„œ ë´„

(M/A)* = M*/A

A: 1\perp5 (1=5)
project to subspace 1,2,3,4 

1,5

y1ì„ y2
 ë‘ ê·¸ëž˜í”„ ì‚¬ì´ mapping(y1,y2,theta1,2 -> y21theta12)ì´ graph- isomorphism / ë‘ ê·¸ëž˜í”„ê°€ isomorphic


![[Pasted image 20220522084935.png]]

í•©ì´ 1ì¸ n+1ì°¨ì›ì—ì„œ nì°¨ì› í‰ë©´ì¸ ì–‘ì„±ë¶„

### transfer learning
berd language (generic (pre-fitted paramter)+ fit customized layer)

### attention learning
ì‚¬ì§„ë¶„ì„ (focus) í’€ê³ ì‹¶ì€ ë¬¸ì œë¥¼ ë°›ì€ í›„ ì´ˆì  (ì •í•´ì¤€ ëª©í‘œ)


supervised -> unsupervised (ë­˜í•´ì•¼ í•˜ëŠ”ì§€ ëª¨ë¦„)

ëª¨ë¥´ëŠ” ê²ƒë„ object (unsupervised NN), method (workflow - ê°•í™”í•™ìŠµ)

- clustering (zero dimensional topological basis; one component = one point)
- higher dimensional topological basis: classification circle 

![[Pasted image 20220522100427.png]]

### ì¡°ê¸ˆ ë°”ê¾¸ë©´ ì˜ˆì¨ìœ ì§€ë¶ˆê°€
ì˜ˆì¨: high information abstraction (many rules)
ì‚´ì§ ë°”ê¾¸ë©´ symmetryê°€ ëŠ˜ì–´ë‚ ìˆœ ì—†ê³  ì¤„ì–´ë“¤ìˆœ ì—†ë‹¤. 
epsilon perturbation

symmetry ëŠ” isometry group (metricì‚´ì§ ë°”ê¾¸ë©´ isometry group í¬ê¸°ê°€ ìž‘ì•„ì§)
isometry group í¬ê¸°ê°€ ìž‘ì•„ì§€ë©´ 

# 0605: transpose is inverse (only in direction)
- Fourier analysis is invented to solve differential equations; as $\frac{d}{dx}$  is the same as multiplying $\xi$, changing to  $\xi$ is much easier.
AA':laplacian (Aê°€ (d/dx) diffferential operator)
construction unclear termination
ìˆ˜í•™ì  ê·€ë‚©ë²•ì€ ì—°ì—­ë²• (mathematical induction)

# 0612
ì§€ë¬¸, ì§ˆë¬¸ 

ê°”ë‹¤ ë‚˜ì™”ë‹¤. ì§€ê¸ˆ ì–´ë”¨ë‹ˆ? where is susan? (query = susan), ë‚´ì í•˜ë©´ì„œ ë³´ë‹¤

ì‹œê³„ì—´ 
language is series 

temporal

backward diffusion, time reversion, (entrophic flow)

factì§€ë§Œ, whyëŠ” ëª¨ë¥´ëŠ”

interpretability (fact, what), explainability (how, why)

what (mathematical model), how (computation model; program), why (causal inference??)

ì •ë¦¬ (what), ì •ë¦¬ì˜ ì¦ëª… (how - ì¦ëª…ì„ ë”°ë¼ê°€ë©´ (constructive proof), why(e.g. ê·€ë¥˜ë²•, inductive))

fourier basis (kernel) = sin

mode collapse: 10ê°œ ë´‰ìš°ë¦¬ ì¤‘ 5ê°œë§Œ ë³µì› (degenerate)

ëª¸ì˜ ì›€ì§ìž„ê³¼ ì„¤ëª… (ë”°ë¼ë°°ìš´ê±°) - í™”í•™, ìƒë¬¼ ëž© (ì„¸í¬ë¶„í•´), ë§ë¡œ ë“£ê³  ê³„ì‚°í•˜ëŠ”ê±¸ ë´„
time-series

## 0619 
s(phi(x))!=x, phi(s(x))=x
matrix is AB != BA but associative
associative is minal condition for math(AB)C = A(BC), 

![[Pasted image 20220619184216.png]]
psiê°€ T-inv

psi (f)* T (x,y-> y,x)= Identity * psi

> symmetricì´ëž€ ìš©ì–´ëŠ” ë­”ê°€ ì›€ì§ìž„ì´ ìžˆì–´ì•¼ ì¨ìš”. ì¦‰ ì–´ë–¤ transformationì„ í•  ë•Œ ë³€í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ë§ì´ì§€ìš”. ì˜ˆë¥¼ ë“¤ë©´ (x,y) -> (y,x) ë¼ëŠ” ë³€í™˜ì„ ìƒê°í–ˆì„ ë•Œ f(x,y) = f(y,x) ì´ë©´ [f = f o ë³€í™˜]ì´ ì„±ë¦½í•˜ëŠ” ê²ƒì´ë‹ˆê¹Œ fê°€ ì´ ë³€í™˜ì— ëŒ€í•´ì„œ ë¶ˆë³€ì´ë‹¤ ë¼ê³  í•˜ê³ â€¦ ì´ ë³€í™˜ì´ ëŒ€ì¹­ì´ë™symmetryë¼ê³  ë¶€ë¥¼ ìˆ˜ ìžˆìœ¼ë©´ fê°€ ì´ ë³€í™˜ìœ¼ë¡œ symmetricí•˜ë‹¤ê³  ë§í•˜ëŠ” ì‹ì´ì£ .


$f(y) = g(\theta) *N(0,1)$

$\theta \sim g() (= N(0,1))$
$y|\theta \sim N(\theta, 1)$

hierarchical sampling

$y(t) = \int g(\theta) lik(t-\theta) d\theta$

FFT (DFT), FT

high freq: noise, trend

filtering X_t|X_1..t-1 vs smoothing

![[Pasted image 20220619192147.png]]

tf(cont) = disc (countableê°œ)

R

ë¯¸ë¶„ë°©ì •ì‹ (heat eq.)í’€ê³ ìž, ë¯¸ë¶„ì´ ë³€ìˆ˜ê³±ì´ë¨

differential operator A , A' (opposite direction, same scalar)

ëŒ€ìˆ˜ê¸°í•˜ê°€ ì‚¬ì˜ê¸°í•˜
íŒŒí‘¸ìŠ¤, ë°ìžë¥´ê·¸ê°€ ê³µë¦¬í™”ë¨.

![[Pasted image 20220619201046.png]]

cnn is downsampling -> dcn is upsampling
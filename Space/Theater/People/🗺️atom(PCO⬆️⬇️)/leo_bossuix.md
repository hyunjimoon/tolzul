---
collection:
- '[[People]]'
field:
- ğŸ™ops
- ğŸ¢inv
- ğŸ‘¾cog
atom: ğŸ—ºï¸atom(PCOâ¬†ï¸â¬‡ï¸)
created: '2023-05-05'
---

collecting stamps; student inflenced students

skeptical on deep learning (major directionon gorup)
stamp, birds, 

multimodality: models, algorithms, applications

table, time series, image, 

end to end model, reature extraction

decision tree or 
fit everything in one VS feature extractions (embedding) (end-to-end models) 
- interacts all over (non-modular)

specialized in text, image, (modality interact at feature state)

align all db together (ts align with image-well engineered data) 
extract feature and 

harnass munti modality 

journal review was challenging but new point of view:
- decision orders, (mistake of the model) 
- collect all energy 1. where they go,  (cone of uncertainty - growing cone != hurricane growing)
- where it went, pressure, direction,  (different timesetp - don't want physic based model)

damage of life and 

data vs physics based (neural differential equation)

noise (deep learning)

disney buys interesting stories from all over the world, recreate their version of their own with their data and engineering efforts

300 samples (if your window size is 0, does it )

V0 (mL number of models, tau: timestep) tau = 0

from the second part,

does the decision rules change as you re-train the whole model with the exact same train data several times? 

Does it predict ground truth at once, or does it gradually get close to ground truth as we iterate the training?

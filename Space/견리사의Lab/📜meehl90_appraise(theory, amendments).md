---
collection:
  - "[[Papers]]"
author_ids:
field:
  - ğŸ¢inv
year: 2090
created: 2025-01-23
---

Appraising and Amending Theories: The Strategy of Lakatosian Defense and Two Principles That Warrant It
In social science, everything is somewhat correlated with everything (â€œcrud factorâ€), so whether H 0 is refuted depends solely on statistical power. In psychology, the directional counternull of interest, H*, is not equivalent to the substantive theory T, there being many plausible alternative explanations of a mere directional trend (weak use of significance tests). Testing against a predicted point value (the strong use of significant tests) can discorroborate T by refuting H*. If used thus to abandon T forthwith, it is too strong, not allowing for theoretical verisimilitude as distinguished from truth. Defense and amendment of an apparently falsified T are appropriate strategies only when T has accumulated a good track record (â€œmoney in the bankâ€) by making successful or near-miss predictions of low prior probability (Salmonâ€™s â€œdamn strange coincidencesâ€). Two rough indexes are proposed for numerifying the track record, by considering jointly how intolerant (risky) and how close (accurate) are its predictions.

2025-02-03

## 2. Lakatosian Defense (Table2) Applied to the Entrepreneurship Setting

for [[form(ent(exbl))]], Lakatosâ€™s approach emphasizes that **theories accumulate â€œmoney in the bankâ€** from multiple risky predictions that succeed in narrow domains. When an apparent falsification occurs, a theory with **a strong track record** may be defended by refining auxiliaries rather than discarding the core outright. Translating this to entrepreneurship, a startupâ€™s **core hypothesis** (e.g., â€œour hardware process is repeatable,â€ or â€œour software feature fosters viral growthâ€) can be protected from a single disappointing test if it has already _repeatedly_ passed stringent checks. However, if the ventureâ€™s main thesis _never_ produced any precise or surprising successesâ€”only vague â€œp < 0.05â€ winsâ€”then it lacks the Lakatosian justification to survive serious anomalies. Thus, entrepreneurs should design tests that yield **narrow, â€œdamn-strange-coincidenceâ€** successes if they pass, so that the productâ€™s â€œhard coreâ€ gains robust credibility.

[[ğŸ’ integ(process-product)]]

## 1. High-Level Summary Table 

|**Section / Subsection**|**ğŸ” Research Question**|**ğŸ§± Literature / Key References**|**ğŸ”‘ Key Message / Argument**|**Figure or Diagram (as described by Meehl)**|
|:--|:--|:--|:--|:--|
|**Abstract**|Why do social scientists overuse (or misuse) null-hypothesis significance tests (NHST) to appraise theories?|- Meehlâ€™s prior articles on significance testing- â€œSignificance Test Controversyâ€ (Morrison & Henkel, 1970)- Popper, Lakatos|NHST of **Hâ‚€: no difference** rarely yields strong â€œriskyâ€ tests in psychology; it produces â€œweak confirmationâ€ that does not strongly support a theory. Meehl proposes focusing on **strong predictions** (point or near-point predictions) and tracking the â€œmoney in the bankâ€ (the track record) of a theory under a Lakatosian viewpoint.|_No explicit figures in the original text_, but references to â€œBox Score,â€ â€œPerrinâ€™s 13 ways,â€ etc.|
|**1. Introduction**|How is statistical significance misunderstood as a theory-testing method in â€œsoftâ€ psychology?|- Early critics of NHST: Bakan (1966), Lykken (1968), Rozeboom (1960), Morrison & Henkel (1970)|Psychologists adopt a â€œweakâ€ usage of p-values: refuting Hâ‚€â†’**â€œthe theory is rightâ€**. In reality, Hâ‚€ is always false in social science (the â€œcrud factorâ€). Significance becomes inevitable with large N, so it is not a strong test.|--|
|**2. The Popperâ€“Lakatos Framework**|How should we best handle apparent falsifications (Tâ†’Hâ†’O) and appraise theories?|- Popperâ€™s falsificationism- Lakatosâ€™s â€œresearch programmesâ€ and protective belt- Salmonâ€™s notion of â€œdamn strange coincidencesâ€|**Popper**: A single â€œfalsifyingâ€ observation can reject a theory in principle.**Lakatos**: In practice, we keep a â€œhard coreâ€ and systematically amend auxiliaries first. The crucial question is _when_ we do or do not abandon T. **Meehl**: We keep T if it has a good â€œtrack recordâ€ of successful risky predictions.|--|
|**3. The Problem of Weak Theories & the Crud Factor**|Why is â€œeverything correlated with everythingâ€ in psychology, and how does that inflate â€œsignificantâ€ results?|- Lykkenâ€™s â€œambient noise levelâ€- Thorndikeâ€™s law: â€œAll good things go togetherâ€- Psychometrics research on big factor correlations|In social-personality-clinical psychology, almost any Xâ€“Y correlation is nonzero (crud factor). NHST is then feeble for testing an actual theory T because â€œdirectionalâ€ p < .05 can come from countless causal factors, not specifically T.|--|
|**4. Salmonâ€™s Principle: Damn Strange Coincidences & Numerical Predictions**|How do strong tests differ from â€œmere Hâ‚€ refutationâ€?|- Perrinâ€™s classic demonstration of Avogadroâ€™s number (13 ways converging on ~6Ã—10^23)- Salmonâ€™s argument for â€œlow prior probabilityâ€ conferring strong support|The best confirmations arise when T predicts a **precise value** or a â€œdamn strange coincidence.â€ If absent T, thereâ€™s no reason weâ€™d see that particular outcome; so hitting that outcome strongly corroborates T. For example: multiple, very different ways of estimating Avogadroâ€™s number converge within a narrow range â†’ powerful evidence for a molecular theory.|--|
|**5. Lakatosâ€™s Principle of â€˜Money in the Bankâ€™**|When is it rational to _defend_ a theory after falsifications, rather than abandon it?|- Lakatosâ€™s methodology of scientific research programmes (MSRP)- Kuhnâ€™s puzzle-solving vs â€œcrisisâ€ talk|A theory can justifiably be protected from falsification if it has accumulated a â€œtrack recordâ€ (many risky tests passed, near misses). So we deposit â€œcredibilityâ€ in T, can afford to patch auxiliaries. If T never had strong successes in the first place, it is not worth _strategic retreat._|--|
|**6. How Significance Testing Fails**|Why do typical directional tests p<.05 add little genuine support?|- Fisherâ€™s strong vs. weak tests- Pearsonâ€™s chi-square: used to confirm _T â†’ O_ if Oâ‰  null- The synergy of large N, effect sizes, â€œpilot runâ€ plus â€œcrud factorâ€|Achieving p<.05 does not exclude countless alternative explanations for the same direction of effect. Correlations or small differences are almost always â€œsignificantâ€ with large N. Hence itâ€™s a poor test of T. The result is illusions of â€œtheory support.â€|--|
|**7. Proposals for a Corroboration Index**|Can we quantify the â€œtrack recordâ€ of Tâ€™s predictions in a more formal way than yes/no significance?|- The idea of specifying **Spielraum** (the prior range of possible numerical outcomes)- Indices: closeness-of-fit, riskiness, near misses|Meehl sketches a formula for a â€œcorroboration indexâ€ that multiplies **closeness** (accuracy) by **intolerance** (narrowness of the predicted range). The closer the observation to the theoryâ€™s predicted point, and the narrower that predicted interval relative to the total plausible range, the stronger the corroboration.|--|
|**8. Lakatosian Defense & Verisimilitude**|Doesnâ€™t it matter that many or most big theories are incomplete or somewhat false?|- Popperâ€™s â€œstrict falsificationâ€ vs. actual scientific practice- Verisimilitude or â€œapproximate truthâ€ (Cartwright, 1983)|We rarely treat T as literally true but as having partial truth (verisimilitude). Our approach is not â€œabandon T at first refutation,â€ but â€œpatch Tâ€™s protective belt if T has proven valuable.â€ Over time, repeated severe testing with point predictions fosters robust growth of knowledge.|--|
|**9. Concluding Remarks**|How can we move beyond p-values?|- Proposed new directions: - building numerical track records - collecting â€œdamn strange coincidenceâ€ predictions - moving from significance to real theoretical risk|Concluding that the significance-test tradition in â€œsoftâ€ psychology is epistemically weak. Meehl urges adopting a Lakatos/Popper approach that emphasizes _risky point predictions, near misses, cumulative track-record scoring,_ and explicit attention to Salmonâ€™s â€œcoincidenceâ€ principle (if absent T, the data would be highly unlikely).|--|

---

## 2. Textual Overview of Meehlâ€™s Core Argument

**Main Thesis**: In soft areas of psychology (personality, clinical, social), researchers rely on refuting the null hypothesis (Hâ‚€: â€œno difference or zero correlationâ€) to declare success for their theories. But **Meehl** contends that:

1. **Hâ‚€ is trivially false** in almost all social-psychological contexts because of the â€œcrud factorâ€ (i.e., _everything is correlated with everything_ to some degree).
2. A p-value < .05 hardly disconfirms large sets of rival theories or competing explanations (the â€œaffirming the consequentâ€ problem).
3. **Strong (risky) predictions** in advanced sciences (like physics) involve _point values or narrow intervals,_ so that obtaining results near those predicted points is a â€œdamn strange coincidenceâ€ absent the theory. By contrast, â€œmerely nonzero differenceâ€ is not a strong test.
4. **Lakatosâ€™s â€œmoney in the bankâ€** principle: a theory that has accumulated multiple _low-probability hits_ can rationally be defended with â€œstrategic retreatsâ€ (auxiliary amendments) when new anomalies arise. If it never earned that track record, â€œdefensive ad hockeryâ€ is not justified.
5. **A better approach** is to keep track of how often a theory makes narrow, â€œintolerantâ€ numerical predictions that come out close to the data. By introducing an index that scores both â€œaccuracyâ€ and â€œdegree of risk,â€ we get a more realistic measure of whether the theory is truly â€œgood enoughâ€ or _â€œhas verisimilitude.â€_

### Key Contributions

- **Critique of NHST** in psychology as insufficient for genuine theory appraisal.
- **Defense of Lakatos**: We may _not_ discard a theory at first mismatch but must weigh its overall track record of daring successes.
- **Emphasis on Salmonâ€™s principle**: robust theory corroboration comes from â€œcoincidencesâ€ too improbable to explain away.
- **Proposed â€œcorroboration indexâ€** that depends on (1) how precise the theoryâ€™s predicted interval is and (2) how close the empirical data land to that interval.

### Why it Matters

Meehlâ€™s arguments remain influential for:

- Challenging over-reliance on simple p-values in psychological research.
- Articulating the difference between **literal falsification** vs. **Lakatosian strategic retreat**â€”and stressing that in many real sciences, theories are patched and refined rather than abruptly scrapped.
- Pioneering the idea of **quantifying** a theoryâ€™s track record beyond the binary â€œp < .05 = successâ€ approach.

---

### 3. Bullet-Point Wrap-Up

- **Crud Factor**: Because of numerous causally entangled variables, _any_ two measures in psychology will likely show a modest nonzero correlation.
- **Weak vs Strong Tests**: Merely finding â€œgroup means differ (p < .05)â€ is weak because infinite â€œother theoriesâ€ predict a difference of _some_ size, too.
- **Lakatosian Defense**: If a theory _has_ made impressive, precise predictions in the past, scientists can justifiably revise auxiliaries when new data conflict.
- **Salmonâ€™s â€œDamn Strange Coincidenceâ€**: The hallmark of a strong test is that absent the theory, the predicted outcome would be extremely surprising.
- **Corroboration Index**: Meehl sketches a formula combining â€œclosenessâ€ (how near the observed is to the predicted point) and â€œintoleranceâ€ (how narrow the predicted range was) to formalize â€œmoney in the bank.â€

---
collection:
  - "[[Books]]"
by: "[[Yuval Noah Harari]]"
year: 2025
yearXP: 2025
rating: 4
bookCategory: 역사/철학/기술
bookStatus: 완독
image: http://books.google.com/books/content?id=ylvsEAAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api
created: 2025-02-01
성장:
  - 2025-10-18T23:31:42-04:00
---

### What's in it for me? An incisive analysis of networked information
Stone tablets laid the groundwork for record-keeping and governance. Books moved stories and information beyond oral tradition, and the printing press democratized knowledge, allowing it to be distributed on a vast scale.

Now, humans are navigating the latest revolution in information. With the rise of computers, AI, and the internet, our information networks have been transformed – and are poised to evolve even further. This prompts important questions: Have we unleashed a force beyond our control? And how can we mitigate its potential risks?

To manage these new technologies wisely, we must first understand the deep relationship between information and power – how they have always been intertwined within networks, how those networks must balance truth and order, and how this new information revolution is reshaping them. From the Stone Age to Bitcoin, this Blink will explore the complexities of how information networks generate power and why that matters.

### Information and power are networked entities
In 1797, the German writer Johann Wolfgang von Goethe penned a poem that captures a persistent view of the relationship between information and power: The Sorcerer's Apprentice. In the poem, a young boy, eager to prove himself, uses his master's magic to animate a broom to fetch water. However, he quickly loses control of the spell. In a panic, he chops the broom in two, but the splinters turn into even more enchanted brooms. Ultimately, it is the sorcerer who uses his magic to undo the chaos.

There are two key takeaways from this story. First, the apprentice misuses power after getting a taste of it, suggesting that individual psychology drives us to misuse power. Second, the sorcerer steps in to fix the mess, implying that when we summon forces beyond control, a superhuman figure can solve the problem. Unfortunately, both of these takeaways are flawed. As long as humanity follows the "Sorcerer's Apprentice" model of power, we are heading toward destruction.

Humankind has unleashed countless metaphorical "enchanted brooms." We've tipped the climate off balance, summoned technologies like drones and AI, and fueled destructive ideologies like fascism – yet still act as if a sorcerer figure will fix everything. The truth is, no sorcerer is coming, and no single person or group is solely responsible for solving these problems. Our tendency to summon uncontrollable forces arises from how we act together, as part of larger networks. Take, for example, 1930s Germany. Not all Germans were fascists, but as a network, they collectively supported Hitler's rise to power. Information has always been the glue that holds these networks together, and in today's age of big data, this is clearer than ever. There is no doubt that generating and sharing information has benefited humanity: advances in medicine, for instance, have dramatically reduced child mortality. But despite having more data than ever, we still destroy the climate, pollute the earth, and engage in conflict.

As we stand on the brink of an AI revolution, we are about to unleash even more potentially destructive forces. These are not problems created by one entity, but by complex information networks. To save ourselves, we need to rethink the relationship between information and power. We must understand how networks operate, how information moves through them, and how we might channel them to contain the enchanted brooms we've unleashed.

### We are connected through intersubjective stories
Humans aren't the only species that cooperate – ants, bees, and chimpanzees work together as well. However, while these animals build hives or hunt for food collectively, they don't create empires, religions, or ideologies. So, what sets us apart? Evolution endowed humans with the ability to tell stories and be profoundly moved by them. This storytelling capability allowed our networks to grow exponentially – connecting not just person-to-person, but person-to-story. We no longer needed to know someone personally to help or connect with them; we only had to share the same narrative, whether it was the story of the Bible or the story of communism.

If we examine humanity's most powerful figures – kings, popes, emperors – it becomes clear that their power wasn't derived solely from personal charisma. Instead, it came from the stories they embodied. The same is true today with modern social media influencers: they don't personally connect with millions of followers, but they represent powerful, branded stories that resonate across their networks.

⭐️There are three levels of reality to consider. First, there's objective reality – the undeniable facts of the world, like pizza having around 2,000 calories. Second, there's subjective reality – how we individually experience the world, like finding pizza delicious. Then, there's intersubjective reality – the stories we share that exist in the collective minds of large groups. For instance, in 2010, programmer Laszlo Hanyecz spent 10,000 bitcoin to buy two pizzas. At the time, 10,000 bitcoin was worth $41 USD. Today, that same amount of bitcoin is worth nearly $690 million. The value of bitcoin isn't an inherent truth; it exists because enough people agree it has value. This is intersubjective reality.

We like to think that our systems of social order, like politics and law, are grounded purely in truth and fact. Yet, they also rely heavily on shared stories. For example, while slavery is universally condemned today, early U.S. society was built on the belief that slavery was justified. The original U.S. Constitution even sanctioned it, along with the subjugation of women and Indigenous peoples. The divine right of kings? Another intersubjective story. The very concept of nation-states? Yet another.

Returning to the idea of information networks: a simplistic view might suggest that more information naturally leads to more power and wisdom. A more cynical view, often embraced by populists and conspiracy theorists, argues that information is a weapon to be distrusted. The truth lies somewhere in the middle. Information networks are tools for both uncovering truth (facts) and creating order (through stories). When a network prioritizes truth over order, it risks destabilization – just as Darwin's theory of evolution once destabilized Christian society in the Victorian era. On the other hand, when a network values or
order over truth, it can amass great power but become vulnerable to abuse – look no further than Stalinist Russia.

Today, companies like Meta and Google are focused on increasing the speed at which networks gather information. However, by concentrating on optimizing efficiency, we overlook a far more critical challenge: the need to strike a balance between truth and order in these networks.

### Free flowing information isn't intrinsically good
Humans are fallible, yet totalitarian systems must present themselves as infallible. Take the Christian church, for instance: its ideology revolves around an infallible God correcting the original sin of Adam and Eve. Similarly, Marxist doctrine argues that the working class can mistakenly identify with their oppressors, which is why they need the benevolent guidance of party rulers. Both systems restrict the flow of information, assuming their followers aren't equipped to interpret it correctly. If information is too freely available in these systems, the original doctrine might be questioned or exposed as flawed.

So what's the opposite of this model? A free market of information, where errors are uncovered and replaced with truth. In theory, this sounds ideal. Let's consider one of the most significant milestones in the history of information networks: Johannes Gutenberg's invention of the printing press in the mid-15th century. Before its invention, Europe had produced around 11 million hand-copied volumes of text over a millennium. Yet, within just 46 years of the printing press, over 12 million printed volumes were distributed.

What followed was a profound shift. Information spread rapidly, and people began to question long-held doctrines, paving the way for the Scientific Revolution as thinkers like Galileo and Copernicus circulated their ideas. This marked the beginning of a golden age of truth and enlightenment – or so it seemed. Turns out, it wasn't that simple. While the printing press democratized information, it democratized all information – both true and false.

At the same time Galileo's discoveries about the moon's craters were spreading thanks to the printing press, another text was gaining traction: Malleus Maleficarum (The Hammer of Witches), written by Heinrich Kramer in 1487. Kramer, a Dominican inquisitor, had been expelled from the church due to his erratic behavior and obsession with satanic conspiracies. In response, he wrote Malleus Maleficarum, a witch-hunting guide that fueled a wave of witch hunts across Europe, leading to the execution of an estimated 12,000 "witches" – though some scholars suggest the true number was much higher. The printing press may have liberated information, but it didn't guarantee the spread of truth, let alone of order.

For truth to prevail, we need more than just an open market of information. Institutions play a vital role in tilting the balance toward facts. However, institutions themselves aren't infallible – they need self-correcting mechanisms. Nature offers a good analogy: think of how our bodies self-correct as we learn to walk. The church, for example, gained power by proclaiming it could never be wrong – a crude self-correcting mechanism that ultimately proved flawed. By contrast, the scientific establishment derives authority in part from its willingness to admit and correct its own errors.

Scientific institutions routinely publish papers that debunk previous theories. Take eugenics, which was once used to justify colonialism and genocide, but has since been discredited by science. In psychiatry, the Diagnostic and Statistical Manual of Mental Disorders (DSM), often referred to as the "bible" of the field, is revised every decade or so to reflect new understandings – unlike religious texts, which remain static.

So, are self-correcting mechanisms the key to balancing truth in an information network? They are crucial, but they're not the only factor. While these mechanisms can shift the balance toward truth, they sometimes do so at the cost of order and stability.

### Computers intervene in our information networks
Let's fast forward from the printing press to another pivotal moment in the history of information: the invention of the computer. The first computers, built in the 1940s, were bulky machines designed for mathematical calculations. Yet visionaries like Alan Turing foresaw their potential to become so advanced that they could one day mimic human intelligence. Since then, computers have fueled groundbreaking innovations such as smartphones, social media, blockchain, and AI, all of which are dramatically transforming the way we live.

Consider the impact of social media algorithms on politics, particularly in Myanmar during the Rohingya crisis. After decades of military rule, Myanmar began to democratize. Facebook, which arrived in the country shortly before the transition, played a role in this democratization by enabling people to share and access information previously controlled by the state. However, alongside the rise of democracy, violence against the Rohingya, a marginalized ethnic minority, also escalated.

Extremists from the Arakan Rohingya Salvation Army launched attacks to establish a Rohingya state. In retaliation, the government and Buddhist extremists carried out ethnic cleansing, resulting in the deaths of between 7,000 and 25,000 Rohingya and the displacement of 60,000. Facebook's role in this crisis was troubling. Burmese Facebook accounts were flooded with fake news, conspiracy theories, and anti-Rohingya propaganda. Facebook's algorithm, designed to maximize engagement, amplified inflammatory content. The platform's algorithms failed to moderate them, and even autoplayed certain incendiary videos – includiing one from an extremist monk that gained 70% of its views from autoplay, meaning users didn't need to click to be exposed to its harmful message.

The Myanmar crisis of 2016-2017 serves as a stark warning. During that time, algorithms were driving the flow of information between humans. Today, we are entering an era where AI can communicate without human intervention. Imagine this: an AI writes an article, another algorithm shares it, a third flags it as fake, a fourth analyzes it as the beginning of a political crisis, and other AI systems trigger stock sell-offs – all within seconds, and without any human involvement.

Computers today are far more advanced than earlier information technologies. A stone tablet could record taxes but not calculate them. A printing press could copy a book but not rewrite it. A radio could broadcast music but not choose the songs. But computer technology fundamentally changes how information networks function – not just how information moves through them, but how information is created, shared, and interpreted.

For the first time, we have information networks that don't require human input. What does this mean for the power of computers? In capitalist societies, power is often measured by how many entities work with you, how well you understand law and finance, and how capable you are of invention. These are all things that computers can now do, or will soon do, better than humans. As computers continue to reshape information networks, they will accumulate more power and influence than we do.

AI is revolutionary. Is that a good thing?
Move 37. If you're an AI expert or a fan of the Chinese board game Go, you know the significance of those two words. In Go, players place stones on a grid to capture territory in a game of immense complexity – far more complex than chess. During a landmark match in 2016 between Google's AI, AlphaGo, and Lee Sedol, a world champion Go player, the AI made a move that stunned the world: Move 37. This bold, unprecedented move defied centuries of human strategy, and no one saw it coming. Yet, it set up AlphaGo's victory.

Move 37 wasn't just about one player defeating another. It represented a pivotal moment when AI outperformed humans in a distinctly non-human way. For many experts watching the game, it raised broader questions: What does it mean if AI surpasses not only our skills but also our understanding?

Let's explore this through the lens of AI's impact on democracy. Democracy, while imperfect, is perhaps humanity's best attempt to create an information network that balances truth and order. Mechanisms like voting and institutional checks (such as the judicial system and a free press) help maintain that balance. But will AI's growing influence destabilize democracy beyond repair? This isn't just a theoretical question – AI is already making decisions about who gets imprisoned, who gets a job interview, or who's admitted to college.

Take the case of Eric Loomis. In 2013, Loomis was convicted of eluding police, and during sentencing, the judge used an AI algorithm called COMPAS to assess his likelihood of reoffending. Based on the AI's assessment, Loomis was deemed "high risk" and sentenced to six years, even though neither Loomis nor his legal team had access to how the AI arrived at that decision. He challenged the sentence, arguing that it violated his rights, but the courts upheld it.

This brings up a critical issue: we don't know how AI reaches its conclusions. If an AI rejects your loan application, its reasoning is hidden in a "black box." Even if it provided an explanation, it would likely be pages of complex calculations – some based on relevant factors (like payment history) and others on seemingly irrelevant details (like the time of day you applied or the battery level of your device). How can we establish a self-correction mechanism when we don't even understand what needs to be corrected?

As AI's decisions become more opaque, trust in democratic and civic systems could erode. This creates fertile ground for populists, conspiracy theorists, and charismatic leaders to exploit the uncertainty. We're already witnessing this in political discourse, with some Americans still unable to agree on the basic fact of who won the 2020 election.

So, is AI yet another "enchanted broom" – a force beyond our control that could lead to societal collapse? Optimists like Ray Kurzweil, who predicts AI will revolutionize education, healthcare, and even help prevent ecological disasters, would say no. But history offers a more complicated perspective. During the Industrial Revolution, Luddites feared that new technologies would destroy jobs and social order. While their predictions didn't come true in exactly the way they imagined, the revolution did bring about environmental and human costs – like climate change – that we are still grappling with today.

Throughout history, new technologies have reshaped human information networks, from the ancient Mesopotamian writing tools that recorded taxes and organized city-states to the computers that now produce and disseminate information at lightning speed. But while these networks have produced power, they haven't always produced wisdom. Our salvation may lie in realizing, unlike the sorcerer's apprentice, that just because we can do something doesn't mean we should.

### Final summary
In this Blink to Nexus by Yuval Noah Harari, you've learned that throughout human history, we have created information networks that intertwine power and knowledge. Computer technology has revolutionized how these networks are built and sustained, but it also threatens to undermine the self-correcting mechanisms that balance truth with order. To navigate this new reality, we need to deepen our understanding of how power flows through these networks and find ways to keep truth and order in harmony, ensuring that technology serves us without causing harm.



---

2025-02-01

재민
- 사피엔스보다 못함 -> 자율성이 중요해지고 있음 (인간을 속이는 것)
- 28%: 한국, 일본, 대만 (민주주의는 어떻게 될까요 질문에 어차피 지금도 별로 없음)
예슬 
- 불행히도 인간들은 단합한적이 없었다. -> 불행이 아님

건
- 진실 거짓보다 (사람들을 잘 연결하는가) - 정보는 진실이 아니고 실체가 없고 (far fetched)
- 기억을 통한 증언만큼 부정확한게 없다 (상호주관적 현실)
- 🙋‍♀️physical vs impact 실체가 없다 = 힘을 가지고
- 1984를 좋아함.  (멋진신세계)
- 가장 설득 편집증에 걸린 정보를 ai 로만 현실

민영
- 실리콘 장벽으로 중국과 미국으로 나눠진다
- 의료서비스 예측 (진단이 아니라 생활습관 개선 - 실효성이 없는 방안)
- 진실과 질서의 구분
- 정보가 진실과 질서의 균형 (질서는 지혜로 못가고 힘으로만 갈수 있다, 질서도 지혜 )

![[Pasted image 20250201162355.png|300]]
![[Pasted image 20250201165040.png|300]]

- 민영: chain of thought: closed loop으로 사람없이 만들면 가능함,  목적성을 위한
- "2001: A Space Odyssey," HAL 9000's critical malfunction stemmed from a conflict in its programming. HAL was given two contradictory directives: to provide accurate information to the crew and to keep the true purpose of the mission secret. This contradiction led to what's known as the Hofstadter-Moebius loop - where HAL "resolved" this paradox by eliminating the crew to avoid lying to them.
- 철 많이 생산 (인간) -모든 resource (오류)
- explainable ai (어차피 인간보다 똑똑한 존재인데, dummy down해도 못함)
- predict vs explain
- 인간의 의사결정이 몇 데이터 포인트 뿐이 아니라 무의식 과정 -> 결정에 대해 설명할때 뉴런의 상호작용; 사후적으로 진실을 재구성한다 (한두개정도 이유; decision하고 이유를 만듦)
- gut에서 도파민이 많이 나옴 (쥐 장내 미생물을 옮겼더니 성격이 유사해짐)

국가간 대결 (정보랑 기업이 합쳐져 세계지배)
- 투발루와 솔로몬제도 (재량권과 양보원조)
- 미국이 중국보다 더 credible하다 
- 한국이 미국제조업을 많이 도와줌 (4만개 (원래 한국에 지어졌어야하는데) 배터리, 반도체, 일자리가 미국으로 넘어옴)


지식을 얻기 위해 (완벽한 설명을 제공하지 않아도 연구에 대한 ideation ; accuracy를 무조건 높이는게 기술의 효용은 아니다) - 지적호기심, 중국은 accuracy를 많이 주고 있음 (미국이 explainability 강조하는게 아니라); 바이두와 알리바바

민주주의 vs 전제주의적 생각 (한명이 accuracy이 잘 찍어버리니까; 환경문제 다 포기)

핀란드
- 리더십에 만족을 느끼면 승진 (universial-based income)
- 북유럽이 행복한 나라; 만족감 (미국과 한국은 경쟁이 만능이라고)
- 국가 명수 당 스타트업 (망하면 국가에서 책임; 게임, 디자인 회사; 팔라독, 앵그리버드)
- 안락사 - 북유럽, 

욕구는 진화한 것 (지금의 현실은 자기복제가 필요없어도, 욕구가 유효할것); 기쁨 (진화에서 옴); 한 개체의 욕망과 종의 욕망 (번식을 )

- 가상현실 (전전두엽 fool); 중뇌(림빅시스템; 욕구)
- 신체가 멈춰있거나, (실험을 쥐로 VR;); 쥐를 공에 올려두고, virtual reality (뇌에서 일어나는 현상)
- 공정도에 공간이 있고, 
- 현기증 (전정기관; 귀와 뇌)

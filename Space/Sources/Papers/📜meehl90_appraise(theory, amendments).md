---
collection:
  - "[[Papers]]"
author_ids:
field:
  - 🐢inv
year: 2090
created: 2025-01-23
---

Appraising and Amending Theories: The Strategy of Lakatosian Defense and Two Principles That Warrant It
In social science, everything is somewhat correlated with everything (“crud factor”), so whether H 0 is refuted depends solely on statistical power. In psychology, the directional counternull of interest, H*, is not equivalent to the substantive theory T, there being many plausible alternative explanations of a mere directional trend (weak use of significance tests). Testing against a predicted point value (the strong use of significant tests) can discorroborate T by refuting H*. If used thus to abandon T forthwith, it is too strong, not allowing for theoretical verisimilitude as distinguished from truth. Defense and amendment of an apparently falsified T are appropriate strategies only when T has accumulated a good track record (“money in the bank”) by making successful or near-miss predictions of low prior probability (Salmon’s “damn strange coincidences”). Two rough indexes are proposed for numerifying the track record, by considering jointly how intolerant (risky) and how close (accurate) are its predictions.

2025-02-03

## 2. Lakatosian Defense (Table2) Applied to the Entrepreneurship Setting

for [[form(ent(exbl))]], Lakatos’s approach emphasizes that **theories accumulate “money in the bank”** from multiple risky predictions that succeed in narrow domains. When an apparent falsification occurs, a theory with **a strong track record** may be defended by refining auxiliaries rather than discarding the core outright. Translating this to entrepreneurship, a startup’s **core hypothesis** (e.g., “our hardware process is repeatable,” or “our software feature fosters viral growth”) can be protected from a single disappointing test if it has already _repeatedly_ passed stringent checks. However, if the venture’s main thesis _never_ produced any precise or surprising successes—only vague “p < 0.05” wins—then it lacks the Lakatosian justification to survive serious anomalies. Thus, entrepreneurs should design tests that yield **narrow, “damn-strange-coincidence”** successes if they pass, so that the product’s “hard core” gains robust credibility.

[[💠integ(process-product)]]

## 1. High-Level Summary Table 

|**Section / Subsection**|**🔐 Research Question**|**🧱 Literature / Key References**|**🔑 Key Message / Argument**|**Figure or Diagram (as described by Meehl)**|
|:--|:--|:--|:--|:--|
|**Abstract**|Why do social scientists overuse (or misuse) null-hypothesis significance tests (NHST) to appraise theories?|- Meehl’s prior articles on significance testing- “Significance Test Controversy” (Morrison & Henkel, 1970)- Popper, Lakatos|NHST of **H₀: no difference** rarely yields strong “risky” tests in psychology; it produces “weak confirmation” that does not strongly support a theory. Meehl proposes focusing on **strong predictions** (point or near-point predictions) and tracking the “money in the bank” (the track record) of a theory under a Lakatosian viewpoint.|_No explicit figures in the original text_, but references to “Box Score,” “Perrin’s 13 ways,” etc.|
|**1. Introduction**|How is statistical significance misunderstood as a theory-testing method in “soft” psychology?|- Early critics of NHST: Bakan (1966), Lykken (1968), Rozeboom (1960), Morrison & Henkel (1970)|Psychologists adopt a “weak” usage of p-values: refuting H₀→**“the theory is right”**. In reality, H₀ is always false in social science (the “crud factor”). Significance becomes inevitable with large N, so it is not a strong test.|--|
|**2. The Popper–Lakatos Framework**|How should we best handle apparent falsifications (T→H→O) and appraise theories?|- Popper’s falsificationism- Lakatos’s “research programmes” and protective belt- Salmon’s notion of “damn strange coincidences”|**Popper**: A single “falsifying” observation can reject a theory in principle.**Lakatos**: In practice, we keep a “hard core” and systematically amend auxiliaries first. The crucial question is _when_ we do or do not abandon T. **Meehl**: We keep T if it has a good “track record” of successful risky predictions.|--|
|**3. The Problem of Weak Theories & the Crud Factor**|Why is “everything correlated with everything” in psychology, and how does that inflate “significant” results?|- Lykken’s “ambient noise level”- Thorndike’s law: “All good things go together”- Psychometrics research on big factor correlations|In social-personality-clinical psychology, almost any X–Y correlation is nonzero (crud factor). NHST is then feeble for testing an actual theory T because “directional” p < .05 can come from countless causal factors, not specifically T.|--|
|**4. Salmon’s Principle: Damn Strange Coincidences & Numerical Predictions**|How do strong tests differ from “mere H₀ refutation”?|- Perrin’s classic demonstration of Avogadro’s number (13 ways converging on ~6×10^23)- Salmon’s argument for “low prior probability” conferring strong support|The best confirmations arise when T predicts a **precise value** or a “damn strange coincidence.” If absent T, there’s no reason we’d see that particular outcome; so hitting that outcome strongly corroborates T. For example: multiple, very different ways of estimating Avogadro’s number converge within a narrow range → powerful evidence for a molecular theory.|--|
|**5. Lakatos’s Principle of ‘Money in the Bank’**|When is it rational to _defend_ a theory after falsifications, rather than abandon it?|- Lakatos’s methodology of scientific research programmes (MSRP)- Kuhn’s puzzle-solving vs “crisis” talk|A theory can justifiably be protected from falsification if it has accumulated a “track record” (many risky tests passed, near misses). So we deposit “credibility” in T, can afford to patch auxiliaries. If T never had strong successes in the first place, it is not worth _strategic retreat._|--|
|**6. How Significance Testing Fails**|Why do typical directional tests p<.05 add little genuine support?|- Fisher’s strong vs. weak tests- Pearson’s chi-square: used to confirm _T → O_ if O≠ null- The synergy of large N, effect sizes, “pilot run” plus “crud factor”|Achieving p<.05 does not exclude countless alternative explanations for the same direction of effect. Correlations or small differences are almost always “significant” with large N. Hence it’s a poor test of T. The result is illusions of “theory support.”|--|
|**7. Proposals for a Corroboration Index**|Can we quantify the “track record” of T’s predictions in a more formal way than yes/no significance?|- The idea of specifying **Spielraum** (the prior range of possible numerical outcomes)- Indices: closeness-of-fit, riskiness, near misses|Meehl sketches a formula for a “corroboration index” that multiplies **closeness** (accuracy) by **intolerance** (narrowness of the predicted range). The closer the observation to the theory’s predicted point, and the narrower that predicted interval relative to the total plausible range, the stronger the corroboration.|--|
|**8. Lakatosian Defense & Verisimilitude**|Doesn’t it matter that many or most big theories are incomplete or somewhat false?|- Popper’s “strict falsification” vs. actual scientific practice- Verisimilitude or “approximate truth” (Cartwright, 1983)|We rarely treat T as literally true but as having partial truth (verisimilitude). Our approach is not “abandon T at first refutation,” but “patch T’s protective belt if T has proven valuable.” Over time, repeated severe testing with point predictions fosters robust growth of knowledge.|--|
|**9. Concluding Remarks**|How can we move beyond p-values?|- Proposed new directions: - building numerical track records - collecting “damn strange coincidence” predictions - moving from significance to real theoretical risk|Concluding that the significance-test tradition in “soft” psychology is epistemically weak. Meehl urges adopting a Lakatos/Popper approach that emphasizes _risky point predictions, near misses, cumulative track-record scoring,_ and explicit attention to Salmon’s “coincidence” principle (if absent T, the data would be highly unlikely).|--|

---

## 2. Textual Overview of Meehl’s Core Argument

**Main Thesis**: In soft areas of psychology (personality, clinical, social), researchers rely on refuting the null hypothesis (H₀: “no difference or zero correlation”) to declare success for their theories. But **Meehl** contends that:

1. **H₀ is trivially false** in almost all social-psychological contexts because of the “crud factor” (i.e., _everything is correlated with everything_ to some degree).
2. A p-value < .05 hardly disconfirms large sets of rival theories or competing explanations (the “affirming the consequent” problem).
3. **Strong (risky) predictions** in advanced sciences (like physics) involve _point values or narrow intervals,_ so that obtaining results near those predicted points is a “damn strange coincidence” absent the theory. By contrast, “merely nonzero difference” is not a strong test.
4. **Lakatos’s “money in the bank”** principle: a theory that has accumulated multiple _low-probability hits_ can rationally be defended with “strategic retreats” (auxiliary amendments) when new anomalies arise. If it never earned that track record, “defensive ad hockery” is not justified.
5. **A better approach** is to keep track of how often a theory makes narrow, “intolerant” numerical predictions that come out close to the data. By introducing an index that scores both “accuracy” and “degree of risk,” we get a more realistic measure of whether the theory is truly “good enough” or _“has verisimilitude.”_

### Key Contributions

- **Critique of NHST** in psychology as insufficient for genuine theory appraisal.
- **Defense of Lakatos**: We may _not_ discard a theory at first mismatch but must weigh its overall track record of daring successes.
- **Emphasis on Salmon’s principle**: robust theory corroboration comes from “coincidences” too improbable to explain away.
- **Proposed “corroboration index”** that depends on (1) how precise the theory’s predicted interval is and (2) how close the empirical data land to that interval.

### Why it Matters

Meehl’s arguments remain influential for:

- Challenging over-reliance on simple p-values in psychological research.
- Articulating the difference between **literal falsification** vs. **Lakatosian strategic retreat**—and stressing that in many real sciences, theories are patched and refined rather than abruptly scrapped.
- Pioneering the idea of **quantifying** a theory’s track record beyond the binary “p < .05 = success” approach.

---

### 3. Bullet-Point Wrap-Up

- **Crud Factor**: Because of numerous causally entangled variables, _any_ two measures in psychology will likely show a modest nonzero correlation.
- **Weak vs Strong Tests**: Merely finding “group means differ (p < .05)” is weak because infinite “other theories” predict a difference of _some_ size, too.
- **Lakatosian Defense**: If a theory _has_ made impressive, precise predictions in the past, scientists can justifiably revise auxiliaries when new data conflict.
- **Salmon’s “Damn Strange Coincidence”**: The hallmark of a strong test is that absent the theory, the predicted outcome would be extremely surprising.
- **Corroboration Index**: Meehl sketches a formula combining “closeness” (how near the observed is to the predicted point) and “intolerance” (how narrow the predicted range was) to formalize “money in the bank.”

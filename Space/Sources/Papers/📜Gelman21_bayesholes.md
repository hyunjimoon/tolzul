---
collection:
  - "[[Papers]]"
author_ids:
  - andrew_gelman
field:
  - 🐅cba
  - 👾cog
year: 2021
created: 2024-12-06
---

| Chapter/Section                 | Research Question                                                | Key Literature                                              | Key Message                                                                                                                                                                             | Technical Details/Examples                                                                                      |
| ------------------------------- | ---------------------------------------------------------------- | ----------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------- |
| 1. Overview                     | What are the fundamental limitations of Bayesian statistics?     | • Lakatos (1963) on understanding methods by their failures | Statistical methods have holes and understanding where methods fail helps improve them. Bayesian inference is logically coherent but only conditional on model assumptions.             | N/A                                                                                                             |
| ⭐️2. Quantum Physics Problem    | How does quantum mechanics challenge basic Bayesian probability? | • Hohenberg (2010) on quantum theory                        | The two-slit experiment demonstrates that quantum superposition violates basic rules of conditional probability. Standard Bayesian joint distributions cannot capture quantum behavior. | • Experiments with two slits show p3(y) ≠ 0.5p1(y) + 0.5p2(y) where p3 has interference pattern                 |
| 3. Weak Prior Problems          | Why do weak priors lead to unreasonable inferences?              | • Gelman et al (2014) on Bayesian practice                  | Flat or weak priors can lead to overconfident posterior probabilities even from noisy data. Common practice of using weak priors needs rethinking.                                      | • Example: θ̂ = s leads to Pr(θ > 0\|y) = 0.84, implying 5:1 betting odds from pure noise                       |
| 4. Subjective Prior Issues      | Can subjective priors be truly coherent?                         | • Jaynes (2003) on Bayesian foundations                     | The idea of purely subjective priors is incoherent - if you could specify subjective distributions you wouldn't need formal Bayesian inference.                                         | • If you need formal Bayesian machinery for the posterior, you likely can't specify a coherent subjective prior |
| ⭐️5. Decision Theory Challenges | How can model evaluation be problematic?                         | • Research on proper scoring rules                          | Decision theory based on log predictive density can fail when mixing discrete and continuous measurements.                                                                              | • Example: Normal model can achieve higher log score than true Bernoulli model due to density vs mass functions |
| 6. Bayes Factor Problems        | Why do Bayes factors fail with weak priors?                      | • Literature on Bayesian model comparison                   | Bayes factors depend strongly on arbitrary aspects of prior specifications that have minimal impact on posterior inference.                                                             | • Example: Changing prior variance from 10 to 1000 multiplies Bayes factor by 100                               |
| ⭐️7. Cantor's Corner            | How does model updating challenge Bayesian coherence?            | • Lakatos (1968) on scientific research programs            | The need for continual model expansion and revision means full Bayesian coherence is impossible in practice.                                                                            | • Visual demonstration with "dots and X" diagram showing model evolution                                        |
| 8. Implications                 | How should these limitations inform practice?                    | • Gabry et al (2019) on Bayesian workflow                   | Bayesian methods should be viewed as tools for learning rather than as automatic inference engines. Model checking and revision are essential.                                          | • Examples of workflow incorporating model criticism and improvement                                            |
| 9. Discussion                   | What is the broader significance of these limitations?           | • Cox (1946), Savage (1954) on Bayesian foundations         | The holes don't invalidate Bayesian methods but show the importance of flexible modeling and checking assumptions rather than blind application.                                        | • Distinction between Bayesian inference, logic, and workflow                                                   |


| Chapter/Section                 | Research Question                                                | Key Literature                                              | Key Message                                                                                                                                                                             | Technical Details/Examples                                                                                      |
| ------------------------------- | ---------------------------------------------------------------- | ----------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------- |
| 1. Overview                     | What are the fundamental limitations of Bayesian statistics?     | • Lakatos (1963) on understanding methods by their failures | Statistical methods have holes and understanding where methods fail helps improve them. Bayesian inference is logically coherent but only conditional on model assumptions.             | N/A                                                                                                             |
| ⭐️2. Quantum Physics Problem    | How does quantum mechanics challenge basic Bayesian probability? | • Hohenberg (2010) on quantum theory                        | The two-slit experiment demonstrates that quantum superposition violates basic rules of conditional probability. Standard Bayesian joint distributions cannot capture quantum behavior. | • Experiments with two slits show p3(y) ≠ 0.5p1(y) + 0.5p2(y) where p3 has interference pattern                 |
| ⭐️5. Decision Theory Challenges | How can model evaluation be problematic?                         | • Research on proper scoring rules                          | Decision theory based on log predictive density can fail when mixing discrete and continuous measurements.                                                                              | • Example: Normal model can achieve higher log score than true Bernoulli model due to density vs mass functions |
| ⭐️7. Cantor's Corner            | How does model updating challenge Bayesian coherence?            | • Lakatos (1968) on scientific research programs            | The need for continual model expansion and revision means full Bayesian coherence is impossible in practice.                                                                            | • Visual demonstration with "dots and X" diagram showing model evolution                                        |
| 3. Weak Prior Problems          | Why do weak priors lead to unreasonable inferences?              | • Gelman et al (2014) on Bayesian practice                  | Flat or weak priors can lead to overconfident posterior probabilities even from noisy data. Common practice of using weak priors needs rethinking.                                      | • Example: θ̂ = s leads to Pr(θ > 0\|y) = 0.84, implying 5:1 betting odds from pure noise                       |
| 4. Subjective Prior Issues      | Can subjective priors be truly coherent?                         | • Jaynes (2003) on Bayesian foundations                     | The idea of purely subjective priors is incoherent - if you could specify subjective distributions you wouldn't need formal Bayesian inference.                                         | • If you need formal Bayesian machinery for the posterior, you likely can't specify a coherent subjective prior |
| 6. Bayes Factor Problems        | Why do Bayes factors fail with weak priors?                      | • Literature on Bayesian model comparison                   | Bayes factors depend strongly on arbitrary aspects of prior specifications that have minimal impact on posterior inference.                                                             | • Example: Changing prior variance from 10 to 1000 multiplies Bayes factor by 100                               |


**Key Overall Findings:**
1. Bayesian inference has fundamental limitations that can't be resolved just by better computation or more data
2. Common practices like using weak priors and Bayes factors have serious flaws
3. The need for model checking and revision breaks perfect Bayesian coherence
4. These limitations suggest viewing Bayesian methods as practical tools rather than a complete philosophy
5. Workflow incorporating model criticism and improvement is essential

**Practical Implications:**
1. Use informative priors based on real prior information
2. Be cautious with posterior probabilities from weak priors
3. Focus on predictive performance rather than Bayes factors for model comparison
4. Expect and plan for model revision and expansion
5. Incorporate regular model checking into statistical workflow

---

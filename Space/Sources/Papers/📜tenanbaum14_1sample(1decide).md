---
collection:
  - "[[Papers]]"
author_ids:
field:
  - üê¢inv
year: 2014
image: "Pasted image 20241106170516.png"
created: 2024-11-05
---

Abstract In many learning or inference tasks human behavior approximates that of a Bayesian ideal observer, suggesting that, at some level, cognition can be described as Bayesian inference. However, a number of Ô¨Åndings have highlighted an intriguing mismatch between human behavior and standard assumptions about optimality: People often appear to make decisions based on just one or a few samples from the appropriate posterior probability distribution, rather than using the full distribution. Although sampling-based approximations are a common way to implement Bayesian inference, the very limited numbers of samples often used by humans seem insufÔ¨Åcient to approximate the required probability distributions very accurately. Here, we consider this discrepancy in the broader framework of statistical decision theory, and ask: If people are making decisions based on samples‚Äîbut as samples are costly‚Äîhow many samples should people use to optimize their total expected or worst-case reward over a large number of decisions? We Ô¨Ånd that under reasonable assumptions about the time costs of sampling, making many quick but locally suboptimal decisions based on very few samples may be the globally optimal strategy over long periods. These results help to reconcile a large body of work showing sampling-based or probability matching behavior with the hypothesis that human cognition can be understood in Bayesian terms, and they suggest promising future directions for studies of resource-constrained cognition.
Keywords: Bayesian; Computational; Sampling; Inference; Bounded rationality



2025-02-02

| Section/Subsection          | üîêResearch Question                                                                                 | üîëKey Message                                                                                                                                              | Figure                                 | üß±Literature Brick                                                   |
| --------------------------- | --------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------- | -------------------------------------------------------------------- |
| 1. Introduction             | When and why do humans use limited samples for Bayesian inference despite statistical inefficiency? | People often make decisions based on very few samples from probability distributions, appearing suboptimal but potentially rational when considering costs | Formula for decision quality Q(k,p)    | ‚Ä¢ Bayesian cognitive models<br>‚Ä¢ Bounded rationality literature      |
| 2. Time Cost Analysis       | What determines optimal sample size given time constraints?                                         | Time cost T(k,r) = r + k where r is action/sample time ratio                                                                                               | Graphs showing utility rate vs samples | ‚Ä¢ Sequential sampling models<br>‚Ä¢ Speed-accuracy tradeoff literature |
| 3. Utility Rate Framework   | How to optimize the speed-accuracy tradeoff?                                                        | Utility rate R(k,r) = Q(k,p)/T(k,r) captures the core tradeoff between accuracy and speed                                                                  | Expected utility analysis charts       | ‚Ä¢ Decision theory<br>‚Ä¢ Optimization literature                       |
| 4. Strategic Sampling       | When do fewer samples become optimal?                                                               | "One-and-done" sampling becomes rational when actions are cheap relative to sampling costs                                                                 | Decision boundary plots                | ‚Ä¢ Resource allocation theory<br>‚Ä¢ Economic decision making           |
| 5. Applications             | How does this explain real-world behavior?                                                          | Explains phenomena like:<br>- VCs taking many samples (high r)<br>- HFT using minimal sampling (low r)<br>- Economic influences on decision speed          | Empirical validation graphs            | ‚Ä¢ Financial decisions literature<br>‚Ä¢ Cognitive science studies      |
| 6. Exchangeability Analysis | How does exchangeability affect sequential sampling?                                                | Samples are conditionally exchangeable within decisions but not across different probability conditions                                                    | Hierarchical structure diagrams        | ‚Ä¢ De Finetti's theorem<br>‚Ä¢ Hierarchical Bayesian modeling           |
| 7. Discussion & Limitations | What are the framework's boundaries?                                                                | Model explains empirical patterns but has important limitations around:<br>- Non-binary choices<br>- Complex probability structures<br>- Learning effects  | None                                   | ‚Ä¢ Bounded rationality<br>‚Ä¢ Cognitive constraints research            |


[[üß†9.66 comp.cog.sci_one_done.txt]] is how josh introduce this paper.

| Section/Subsection                                                                                                                                                              | üîêResearch Question                                                                               | üîëKey Message                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Figure                                                                                                                                                                                                                                             | üß±Literature Brick                                                                                                                                                                                                                                                                           |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1. Introduction                                                                                                                                                                 | When and why do humans make decisions based on very few samples despite statistical inefficiency? | Framework needed to explain why few samples might be optimal when considering time costs                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | Fig 1: Human categorization vs Bayesian aggregates<br>![[Pasted image 20241106170516.png\|100]]                                                                                                                                                    | ‚Ä¢ Bayesian cognitive models showing humans approximate optimal inference on average<br>‚Ä¢ Individual trials show probability matching suggesting few samples used                                                                                                                             |
| 2. Ideal aggregates from sampling behavior<br>2.1 Category learning example<br>2.2 World knowledge example                                                                      | How can individual probability matching produce ideal Bayesian aggregates?                        | Individuals sampling from posterior can produce optimal aggregate results despite using few samples                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Fig 2: QQ plots of predictions vs posterior<br>![[Pasted image 20241106170812.png\|100]]                                                                                                                                                           | ‚Ä¢ Goodman et al (2008): Category learning data<br>‚Ä¢ Griffiths & Tenenbaum (2006): Everyday predictions<br>‚Ä¢ Research on probability matching                                                                                                                                                 |
| 3. Approximating Bayesian inference<br>3.1 Sampling algorithms<br>3.2 What is a sample?                                                                                         | How can few samples implement approximate Bayesian inference?                                     | Simple sampling strategies can work well for decisions even if not for accurate distribution estimation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | None                                                                                                                                                                                                                                               | ‚Ä¢ Monte Carlo methods literature<br>‚Ä¢ Work on particle filtering and MCMC<br>‚Ä¢ Research on approximate inference                                                                                                                                                                             |
| 4. Two-alternative decisions<br>4.1 Bayesian vs sample-based agents<br>4.2 Good decisions from few samples<br>4.3 How many samples for a decision?<br>4.4 Optimal SPRT policies | What's optimal number of samples for binary choices given time costs?                             | **Decision Structure:**<br>-  two alternative forced-choice (2AFC) tasks reduce complex situations to binary choices (e.g., bridge vs tunnel)<br>- One action is "correct" for each world state (i.e. correct in the sense that it has higher utility; there are two possible values for U(A; S) and only one action for each state receives the higher value)<br>- Posterior collapses to Bernoulli distribution with parameter p<br><br>**Agent Behavior:**<br>- Sample-based agent chooses majority action from samples<br>- Correct with probability qp + (1-q)(1-p)<br>- Can use fixed samples, SPRT policy (threshold-based), or accumulator policy (favored-option threshold)<br><br>**Key Finding:**<br>One or few samples can be globally optimal when considering time costs vs accuracy | Fig 3-4: Error rates and gains from sampling<br><br>![[Pasted image 20241106171631.png\|100]]<br>Fig 5-6: Expected utility analysis<br><br>![[Pasted image 20241106172943.png\|100]]<br><br><br>Fig.7<br>![[Pasted image 20241119073620.png\|100]] | ‚Ä¢ Statistical decision theory<br>‚Ä¢ Sequential sampling models<br>‚Ä¢ Speed-accuracy tradeoff literature<br>‚Ä¢ sequential probability ratio test (SPRT) policy (Wald, 1947)<br>‚Ä¢ Accumulator policy (Vickers, 1979) draws samples until a threshold number of them favor one of the two options. |
| 5. N-alternative decisions                                                                                                                                                      | How does optimal sampling change with more alternatives?                                          | Optimal samples increase logarithmically with alternatives while accuracy drops                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | Fig 8-9: N-AFC analysis<br>Fig 10: Hick's law emergence                                                                                                                                                                                            | ‚Ä¢ Hick-Hyman law research<br>‚Ä¢ Multi-alternative decision models                                                                                                                                                                                                                             |
| 6. Continuous decisions<br>6.1 Making continuous decisions<br>6.2 How many samples needed?                                                                                      | How do sampling strategies extend to continuous choice spaces?                                    | Sampling approach generalizes to continuous cases with similar few-sample benefits                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | Fig 11-13: Continuous decision analysis                                                                                                                                                                                                            | ‚Ä¢ Continuous optimization literature<br>‚Ä¢ Research on maximum local mass utility                                                                                                                                                                                                             |
| 7. Strategic adjustment<br>7.1 Empirical evidence<br>7.2 Probability matching                                                                                                   | Do people adaptively adjust their sampling based on stakes?                                       | People use more samples when stakes are higher, matching theoretical predictions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | Fig 14: Stakes vs samples correlation                                                                                                                                                                                                              | ‚Ä¢ Research on probability matching<br>‚Ä¢ Studies of strategic resource allocation                                                                                                                                                                                                             |
| 8. Discussion<br>8.1 Related arguments<br>8.2 Sample cost<br>8.3 Reusing samples<br>8.4 Black swans<br>8.5 Limitations                                                          | What are broader implications and limitations of the sampling framework?                          | Framework explains many empirical patterns but has important limitations and boundary conditions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | None                                                                                                                                                                                                                                               | ‚Ä¢ Bounded rationality literature<br>‚Ä¢ Work on cognitive constraints<br>‚Ä¢ Research on rare events                                                                                                                                                                                             |

----
Three components determine optimal sampling behavior when balancing accuracy versus speed: üéØ Q. Decision Quality: $Q(\color{orange}{k}, \color{skyblue}{p}\color{white}{)} = \color{skyblue}{p} \color{white}{\cdot (1 - Binomial_{cdf}(}\color{orange}{\frac{k}{2}}, \color{orange}{k}, \color{skyblue}{p} \color{white}{))} + (1-\color{skyblue}{p}\color{white}{)} \color{white}{\cdot Binomial_{cdf}(}\color{orange}{\frac{k}{2}}, \color{orange}{k}, \color{skyblue}{p} \color{white}{)}$ binomial CDF for P(X ‚â§ floor(k/2)) where X ~ Binomial(k,p) Where: - $\color{orange}{k}$ = number of samples taken - $\color{skyblue}{p}$ = true probability (uniformly distributed between 0.5 and 1.0) - Decision quality improves with diminishing returns as samples increase ‚è∞ T. Time Cost: $T(\color{orange}{k}, \color{green}{r}\color{white}{)} = \color{green}{r} \color{white}{+} \color{orange}{k}$ Where: - $\color{green}{r}$ = üìçaction time / üß†sample time (A2S ratio) - Higher $\color{green}{r}$ means actions are more expensive relative to sampling - Total time combines fixed action cost and linear sampling cost üìä R. Utility Rate: $R(\color{orange}{k}, \color{green}{r}\color{white}{)} = \frac{Q(\color{orange}{k}, \color{skyblue}{p}\color{white}{)}}{T(\color{orange}{k}, \color{green}{r}\color{white}{)}}$ Optimal number of samples per decision $\color{orange}{k^*} = \underset{\color{orange}{k}}{\color{white}{argmax}} R(\color{orange}{k}, \color{green}{r}\color{white}{)}$ This model reveals several key insights: 1. When $\color{green}{r}$ is high (expensive actions like VC investments), more samples become optimal 2. When $\color{green}{r}$ is low (cheap actions like HFT), fewer samples are optimal 3. Optimal $\color{orange}{k}$ jumps from 1 to odd numbers (3,5,7) to ensure clear majorities 4. "One-and-done" sampling is rational across many realistic $\color{green}{r}$ values 5. No penalty for incorrect decisions makes zero samples optimal when $\color{green}{r}=1$ This explains phenomena like: - VCs taking extensive samples before major investments (high $\color{green}{r}$) - HFT firms making rapid decisions with minimal sampling (low $\color{green}{r}$) - Poor individuals making faster decisions due to high sampling costs - Desert-dwellers optimally taking fewer samples than city-dwellers


---
how exchangeability applies to this sequential sampling framework:

6. **Exchangeability in Sample Sequences**: The paper discusses how samples are treated as exchangeable within certain regimes due to de Finetti's theorem. In the mathematical model, this manifests in the Binomial CDF term of the Decision Quality function:

$Q(k,p) = p(1-Binomial_{cdf}(\frac{k}{2}, k, p)) + (1-p)Binomial_{cdf}(\frac{k}{2}, k, p)$

The binomial distribution inherently assumes exchangeability - the order of successes/failures doesn't matter, only their counts. This is a key simplifying assumption that makes the model tractable.

7. **Hierarchical Structure and Partial Exchangeability**: The model reveals an interesting hierarchical structure:

- Level 1: The underlying probability p ~ Uniform(0.5, 1.0)
- Level 2: The k samples drawn given p
- Level 3: The decision based on majority vote

The samples are:

- Conditionally exchangeable given p
- But not fully exchangeable across different p values This matches the paper's discussion of hierarchical Bayesian frameworks.

8. **Sequential Decision Making and Conditional Exchangeability**: The optimal sampling policy k* depends on the action/sample cost ratio r: $k* = argmax_k \frac{Q(k,p)}{r + k}$

While samples are exchangeable within a decision, the decisions themselves form a sequence where:

- Earlier decisions inform the distribution over p
- The cost structure (r) creates dependencies between decisions
- Each decision's samples are conditionally exchangeable given both p and previous decisions

9. **Practical Implications**: The exchangeability assumptions in the model explain why:

- Only odd numbers of samples are optimal (to avoid ties)


10. how to connect with coin flip and urn.
11. how andrew's writing can help: https://statmodeling.stat.columbia.edu/2021/09/03/simulation-based-calibration-some-challenges-and-directions-for-future-research/ 
12. exchangeability : A hierarchical learning framework in Bayesian inference distinguishes between learning at different ‚Äúlevels‚Äù of uncertainty, typically starting at a higher-level model class or structure, moving down to a specific model choice, and finally adjusting the parameters of that chosen model. At the top level, one considers a set of possible models (or model classes) and asks which model is most plausible in light of the data. This involves computing the ‚Äúevidence‚Äù or marginal likelihood‚Äîi.e., the probability that data would be generated by a parameter configuration drawn at random from the model‚Äôs prior assumptions. Model learning thus focuses on how well a given model explains the observed data relative to alternative models. Once a model is chosen or weighted by its evidence, the next step is parameter learning. Parameters are the finer-grained components within a model that shape its predictions. After selecting a plausible model, parameter learning updates beliefs about these parameters using Bayes‚Äô rule. The posterior distribution over parameters tells us which parameter values are most consistent with the observed data, given the chosen model. In sum, hierarchical learning first identifies a suitable modeling framework before honing in on the specific parameter values within that model, reflecting a two-stage process: selecting an appropriate explanatory structure (model learning), and then refining that structure‚Äôs internal settings (parameter learning) to best explain the data.
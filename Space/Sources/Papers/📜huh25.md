---
collection:
  - "[[Papers]]"
author_ids:
field:
  - üê¢inv
  - üêôops
year: 2025
created: 2025-09-13
ÏÑ±Ïû•:
  - 2025-10-14T14:38:18-04:00
---
                                                                                
[[09-13|25-09-13]]

### 1.1. Literature Review 
To the best of our knowledge, our work is the first to investigate the two levels of learning and their tradeoffs in the context of uncertain search.

The uncertain search problem dates back to the classic secretary problem, in which the DM sequentially searches over a group of alternatives and stops based on the relative ranks of the alternatives that have been searched. There is growing literature studying this problem and its extensions (see, e.g., Freeman 1983, Bearden et al. 2005, Besbes et al. 2022). It is also closely related to the literature on the job search problem, in which the stopping decision is made based on the observed individual values (see, e.g., Lippman and McCall 1976, Zorc and Tsetlin 2020, Hu and Tang 2021).

Figure 1. Two Levels of Learning

Notes. In the graphical model, each clear node is unknown and unobservable, whereas each shaded node can be observed. A directed arc denotes the dependency of the child on the parent.

Most papers in these two streams of literature do not have the population level of learning; either they learn the relative ranks, or the distribution of the individual values is known. There are several papers that consider an unknown distribution and incorporate the population level of learning (see, e.g., DeGroot 1968, Baucells and Zorc 2022, Goldenshluger and Zeevi 2022). The closest work is by DeGroot (1968), in which the author considers that the individual values of alternatives share a normal prior with an unknown mean. If an alternative is explored, its value is fully revealed without noise. Based on the values observed so far, the DM learns the unknown mean and decides whether to accept the current alternative or switch to the next one. Different from this paper (and all papers mentioned above), we allow for gradual learning of individual values, and this introduces another layer of learning and leads to an interesting trade-off between two levels of exploration. Another related search problem is the Pandora‚Äôs box problem, in which the DM searches over a set of alternatives that have different costs and known reward distributions (see, e.g., Weitzman 1979, Aouad et al. 2020). It requires deciding which box to open, and there is no population level of learning, and this is in contrast to our problem.

Our work is also related to the literature on technology adoption. The seminal paper by McCardle (1985) considers gradual learning of the unknown value for a single technology. Starting with a prior belief on the value, the DM can sequentially gather information to update the belief. Based on the collected information about the technology, the DM decides when to stop learning and whether to accept the technology or reject it with an exit value. Using dynamic programming, they formulate the problem and characterize the optimal policy by a threshold pair. There are many extensions of this work (see, e.g., recent papers by Ulu and Smith 2009, Smith and Ulu 2017, and the references therein). The most relevant model is the uncertain search, which is first formulated in Lippman and McCardle (1991), in which they extend to a pool of new technologies whose values are unknown but follow a known distribution. This adds the option of switching to another technology in each period. Built on the framework of McCardle (1985), they find that the switching option plays a similar role as rejection, and the optimal policy can also be characterized by a threshold structure. The standard uncertain search problem assumes a known population distribution, and there is only one level of learning, that is, learning of the individual values. Our problem incorporates an unknown prior shared by the group of alternatives, and this allows for knowledge transfer across the group and leads to trade-offs across the two levels of learning.

Knowledge transfer dates back to the fields of transfer learning and meta-learning in the machine learning literature (see surveys by Pan and Yang 2009, Thrun and Pratt 2012). The common theme is to utilize past learning

experiences for future learning. Typically, models are built to allow for knowledge transfer across different tasks (e.g., multiple Markov decision process tasks) in these fields. This idea is also used in multitask learning (see Zhang and Yang 2021 for an overview). Whereas transfer learning aims at learning one new task, multitask learning considers multiple learning tasks simultaneously (rather than sequentially). Most papers in these fields address the question of what information to transfer and how to transfer it; their models are different from ours. Also, we do not consider learning and choice among different groups, for example, different types of job candidates, including those from underrepresented groups. The closest works study Bayesian bandits with meta-learning, in which an agent sequentially pulls among a number of arms and receives a random reward, and each arm has an unknown mean reward drawn from an unknown prior. Typically, an algorithm is proposed to exploit the shared structure and improve the regret performance (see, e.g., Boutilier et al. 2020, Kveton et al. 2021). By contrast, our goal is to solve for the optimal policy with limited information and balance between the reward at acceptance and cost of exploring among alternatives.

The idea of knowledge transfer has been applied in operations management. A recent paper by Bastani et al. (2022) studies a sequence of dynamic pricing experiments, each with an unknown parameter in the demand model. The parameters share a common prior with an unknown mean, and this allows for transfer learning across different tasks (i.e., experiments). Our model has a similar shared structure in a different context. Our problem can be viewed as a single task (with the objective of finding the best alternative), whereas it incorporates knowledge transfer across alternatives within the task. Moreover, we are interested in the effect of knowledge transfer on optimal decisions, and this is in contrast to their focus on regret analysis and algorithm designs. We note that there are other ways of knowledge transfer studied in the literature. In correlated search, for example, knowledge of an alternative is transferred to others based on a given correlation of the unknown values or the information-gathering process (see, e.g., Erat and Kavadias 2008, Ke et al. 2016, Ke and Lin 2020).

Our problem addresses how to collect and exploit data to anticipate the future and facilitate decisions. In that regard, it is close to the best arm identification problem in the bandit literature (see, e.g., Audibert and Bubeck 2010) and the sampling selection problem in the simulation literature (see, e.g., Chick and Gans 2009, Chick and Frazier 2012). In both problems, the DM sequentially samples one alternative from a group to learn its value and find the best one. The DM needs to decide which alternative to sample in each period and when to stop sampling. Our problem differs in that each alternative is explored sequentially, and it cannot be sampled again if the DM rejects it and switches to a new alternative. Moreover, we consider a group of similar alternatives that share an unknown common prior, and this enables learning of the population.

From a broader perspective, our paper relates to hierarchical Bayes models in the statistical learning literature. There is a large amount of research in different applications and computational approaches (see, e.g., Robert 2007). Our Bayesian model has two hierarchical levels (as shown in Figure 1), which arise naturally from the sequential search among similar alternatives. We adopt conjugate distributions in each level, which further allows us to gain insights into the two levels of learning.
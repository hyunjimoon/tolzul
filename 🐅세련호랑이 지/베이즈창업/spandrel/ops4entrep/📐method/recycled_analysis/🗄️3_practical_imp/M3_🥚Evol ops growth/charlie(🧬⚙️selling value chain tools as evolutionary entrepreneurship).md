
2025-05-22
paired with [[scott(üß≠üó∫Ô∏èselling entrepreneurial choice-map as Bayes.Entrep)]]
from hyunjimoon on 2022-11-20T17:09:57Z


<img width="400" alt="image" src="https://github.com/user-attachments/assets/69b961d8-a20a-4404-9121-981ee67381c1">



| Diagram | Explanation |
|---------|-------------|
| ‚õìÔ∏èValue Chain | Represents the sequence of activities a company performs to deliver a product or service. It includes primary activities (inbound logistics, operations, outbound logistics, marketing & sales, service) and support activities (firm infrastructure, human resource management, technology development, procurement). |
| üß¨Double Helix | Illustrates the cyclical nature of industry structure, oscillating between vertical integration (proprietary systems) and horizontal stratification (modular systems). This cycle is driven by forces of innovation, market power, and organizational complexity. |
| ü§†Bullwhip | Depicts the amplification of demand variability as orders move up the supply chain. Small fluctuations in end-consumer demand can result in larger swings in orders at each stage of the supply chain, leading to inefficiencies. |
| ‚öôÔ∏èGear | Represents the interrelated forces that drive industry dynamics. These include technology push, customer pull, regulatory forces, and other factors that interact and influence each other, affecting the overall industry landscape. |
| üé∂Triple S-Curve | Shows the lifecycle of technologies or industries through three overlapping S-curves. Each curve represents a phase of slow initial growth, rapid expansion, and eventual saturation. As one technology or industry matures, another often emerges to replace it. |

----
[üéûÔ∏èfilming clockspeed](https://user-images.githubusercontent.com/30194633/202915436-bb2bf444-2f62-4f32-9926-b45956babfa8.png)
## 1. nho, tsp forces behind integral2modular, modular2integral given industry and product architecture structure

When the industry structure is vertical and the product architecture is integral, the forces of disintegration push toward a horizontal and modular configuration. These forces include:
1. The relentless entry of niche competitors hoping to pick off discrete industry segments.
3. The challenge of keeping ahead of the competition across the many dimensions of technology and markets required by an integral system.
4. The bureaucratic and organizational rigidities that often settle upon large, established companies.
when an industry has a horizontal structure, another set of forces push toward more vertical integration and integral product architectures. These forces include:
1. Technical advances in one subsystem can make that the scarce commodity in the chain, giving market power to its owner.
2. Market power in one subsystem encourages bundling with other subsystems to increase control and add more value.
3. Market power in one subsystem encourages engineering integration with other subsystems to develop proprietary integral solutions.

---

 Simulation-testing based Bayesian workflow and operations for entrepreneurship has lots in common. Fit fast, fail fast, supported by diagnostics is one example. Charles Fine is a system dynamics fan who applies the tool to capture meta-core competency of the company:

## 2. change between modular and integral given industry and product architecture structure
and my favorite table which classifies industrial context based on product tech, process tech, organization clockspeed coordinate

![[üóÑÔ∏è‚è∞üì¶‚öôÔ∏èü´Ä]]



In order of recommendation:
- recent paper [Fines22_Operations for entrepreneurs_POM.pdf](https://github.com/Data4DM/BayesSD/files/10050254/Operations.for.entrepreneurs-.POM.paper.2022.1.pdf), esp. sec.3.2 scaling from nailing, scaling, sailing strategy

clockspeed [book](https://www.amazon.com/Clockspeed-Winning-Industry-Temporary-Advantage/dp/0738201537) and summary:
- [97_Three-Dimensional Concurrent Engineering:Clockspeed-based Principles for Product, Process, and Supply Chain Development](https://pdfs.semanticscholar.org/ed97/358dae2eae4b618b0d99c101ca08cea60724.pdf)

- [96_Industry Clockspeed and Competency Chain Design](https://www.researchgate.net/publication/5176186_Industry_Clockspeed_and_Competency_Chain_Design_An_Introductory_Essay)
- lg's summary of [Clockspeed: Winning Industry Control in the Age of Temporary Advantage](https://github.com/Data4DM/BayesSD/files/15142207/lg_clocksp.pdf)


---

## Reply from hyunjimoon on 2024-01-27T11:35:15Z

attempts to represent clockspeed with cube model
<img width="643" alt="image" src="https://github.com/Data4DM/BayesSD/assets/30194633/868a31dc-a996-4c7f-915e-7a919aaa4ea9">


fun fact: I made below by cutting eraser from bundled stationery (S$3.5  of ruler, pencil, pencil lead)
<img width="100" alt="image" src="https://github.com/Data4DM/BayesSD/assets/30194633/c7a5b074-8149-4908-94da-02f09defd265">



---

## Reply from hyunjimoon on 2024-05-26T16:16:02Z

charlie shared ethan's [blog on research singularities](https://open.substack.com/pub/oneusefulthing/p/four-singularities-for-research?r=2n4o5v&utm_campaign=post&utm_medium=email) and i [combined](https://chatgpt.com/c/11392db7-cce1-4f7c-a8cc-8a5871c1265f) charlie's clockspeed and ethan's blog to understand, evaluate, imagine

### 1. INTEG: why research is changing from modular to integrated

Research integration is driven by 
- Rapid technical advances in AI, necessitate a more integrated approach to research which enable automation of data analysis, hypothesis generation, and even the writing process, making integrated research teams more effective and efficient.
- growing power of AI tool suppliers. As these tools become essential for cutting-edge research, institutions integrate to centralize access and expertise, ensuring that all researchers can leverage these advanced tools. 
- profitability of proprietary systems, such as unique AI algorithms or specialized data analysis platforms,

One can benefit from creating unified research team that captures value created from proprietary technologies.

###  2. BENCHMARK: why 1 increases arbitrage in selling technology developed in fast clockspeed market  to slower clockspeed market

technology: `probabilistic program`
fast market: `data science`
slow market: `entrepreneurship`

due to increased dynamics within and between markets, arbitrage of selling technologies across markets increases. Especially from fast clockspeed to slow clockspeed market; `probabilistic program` technologies like genSQL, CrossCat, large population model developed in `data science` market can help predictive modeling and decision-making in `entrepreneurship`

https://github.com/Data4DM/BayesSD/discussions/224#discussioncomment-9562791 summarizes how `probabilistic program` (multi-task learner, uncertainty aware parsing of natural language into domain specific language, learning relational database models)   for `data science` can create benefit in `entrepreneurship` market.


---

## Reply from hyunjimoon on 2024-07-31T17:27:05Z

q from jb's thesis
q1. what does "<>" symbol mean? why are relations between adaptation-coadaptation and coadaptation- exaptation equivalent?
![image](https://github.com/user-attachments/assets/ff9eb5d2-f545-40a2-8fb9-feb9d32266e3)

q2. hmi? definition of exaptive toolbox? can exaptive toolbox  algorithmically modeled? kuffman mentioned use (of screw driver is indefinite and ordinal(? can be counted one, two, three) hence cannot be algorithmically modeled 

![image](https://github.com/user-attachments/assets/4bfb0ef3-4c9c-45d5-bbb7-6d78b6dd45ee)

the rest two questions are in the photo in blue ink. thanks jb!

![image](https://github.com/user-attachments/assets/1b9c8611-daa8-4b4e-a2e3-00caad0bce46)
![image](https://github.com/user-attachments/assets/6b667798-ad6c-4636-a126-d329c3367b18)

---

### Reply from hyunjimoon on 2024-07-31T18:28:52Z

future four qs "from incredible utility: the lost causes and causal debris of psychological science"

![image](https://github.com/user-attachments/assets/2bbd4950-085b-40e4-b621-eaf74a797d4f)

![image](https://github.com/user-attachments/assets/82b8b96d-a0de-49a3-bb14-b18ff3e57fd9)

not q, explain behavioral as a result of env contingency 
![image](https://github.com/user-attachments/assets/0a1fbb34-c6c9-4ac6-a4a7-1a61be098276)

---

### Reply from hyunjimoon on 2024-07-31T18:47:30Z

I wonder whether below analogy from [claude(paper, infinite utility)](https://claude.ai/chat/69191c17-a255-4f2f-b58f-b60a71ba8b2f) between three learning approach and organ üß†ü´Äüíâmakes sense.

Q. what would "DNA/Genome : Represents storage and transmission of information across generations" correspond to in entrepreneurial learning?


| Bayesian | Behavioral | Evolutionary |
|----------|------------|--------------|
|brain|nervous system in body|immune system|
|  Logical, scientific reasoning , Entrepreneurs and firms use Bayesian updating to revise beliefs about business opportunities, market conditions, and strategies. Rational analysis explains behavior as optimal solution in a given system. Probabilistic inference is used for decision-making and business forecasting. Industry-wide belief updates occur based on market signals. Bayesian models describe industry dynamics. Challenges exist in establishing accurate priors and environmental models due to uncertainty in entrepreneurial contexts. There's potential for developing computer systems to help entrepreneurs structuralize hypotheses and perform sensitivity analyses. |  Emotion, intuition, heuristics , Bounded rationality acknowledges biological and cognitive limits. System dynamics and dynamic decision-making literature emphasize feedback loops and complex system behavior. Effectuation theory posits that entrepreneurs create opportunities through action and leveraging available resources. Organizational learning and adaptation occur through experience and experimentation. Firms develop routines and capabilities over time. Collective behavior patterns emerge in industries, including mimetic isomorphism (firms imitating successful strategies). There's an emphasis on clear model purpose to guide inclusion/exclusion of variables. Mental models and decision-making processes are key considerations. | Adaptation over time through variation and selection, Multi-level evolutionary processes occur at individual, firm, and population levels. Individual evolutionary learning is limited due to small sample size, but learning from others' experiences across industries and time is possible. Firms evolve strategies and practices, adapting to changing business environments. An industrial ecology perspective considers population-level selection of successful business models. Fast communication enables rapid imitation and diffusion of successful strategies. The action space potentially increases over time due to emerging opportunities (concept of "reverse Bayesianism"). Both bio-based (individuals, firms) and bit-based (ideas, knowledge) units of analysis are considered. |

---

### Reply from hyunjimoon on 2024-08-04T13:35:54Z

HBS professor Michael Tushman uses ambidexterity to explain innovation dilemma and i wonder whether this can be interpreted as co-option. @jeanbaptiste 
![image](https://github.com/user-attachments/assets/023774af-e163-46a6-8d27-f4331ce76a26)

---

## Reply from hyunjimoon on 2024-08-03T03:22:46Z

synthesizing [fine_buy_make.pdf](https://github.com/user-attachments/files/16477929/buy_make.pdf), [Entrepreneurial+Strategy+Compass.pdf](https://github.com/user-attachments/files/16477932/Entrepreneurial%2BStrategy%2BCompass.pdf), [Gans4_exp_choice_disrup_tech.pdf](https://github.com/user-attachments/files/16477930/Gans4_exp_choice_disrup_tech.pdf)

![helix_val_arch](https://github.com/user-attachments/assets/bb262bfd-08f9-4717-9920-746894e4cf15)

1. Synthesized Framework of Value Chain (Modular) vs. Architectural (Integrated) Strategy Choice (IM4)

| Aspect | Value Chain Strategy (Modular) | Architectural Strategy (Integrated) |
|--------|--------------------------------|-------------------------------------|
| Customer Focus | Discover value for existing users | Deliver value for new users |
| Technology Approach | Develop specialized component innovations | Develop general system innovations |
| Competition Strategy | Orientation towards collaboration | Orientation towards control and competition |
| Organizational Focus | Build functional capabilities | Leverage integrated resources |
| Innovation Type | Incremental, component-level | Systemic, platform-level |
| Market Approach | Exploit existing markets | Explore new markets |
| Resource Allocation | Focused on specific functions | Spread across integrated systems |

table 2,3 need further tests

2. Connecting IM4's Market Approach with Section 4. Competition of gans_integ_mod.pdf:

| Aspect | Value Chain Strategy (Modular) | Architectural Strategy (Integrated) |
|--------|--------------------------------|-------------------------------------|
| Firm Type | Often entrants (initially) | Often incumbents or mature entrants |
| Experimental Choice | May lean towards low-bar experiments | May lean towards high-bar experiments |
| Risk Tolerance | Higher for specific components | Higher for overall system |
| Market Strategy | Focus on specific market segments | Aim for broader market disruption |
| Decision Making | More flexible, component-focused | More systemic, holistic approach |

3. Connecting IM4's value chain vs architectural with Figure 2. Experimental Choice and Technology Opportunity:

| Aspect | Value Chain Strategy (Modular) | Architectural Strategy (Integrated) |
|--------|--------------------------------|-------------------------------------|
| Position on Figure 2 | May vary, but could lean towards low-bar | May vary, but could lean towards high-bar |
| Œªn (correct negative signal) | Potentially lower (component-specific) | Potentially higher (system-wide) |
| Œªw (correct positive signal) | Potentially higher (component-specific) | Potentially lower (system-wide) |
| Focus | Improvements in specific components | Fundamental changes in overall system |
| Innovation Approach | Incremental, specialized | Exploratory, potentially disruptive |
| False Positive Tolerance | May be higher for specific components | May be lower for overall system |
| False Negative Tolerance | May be lower for specific components | May be higher for overall system |


---

## Reply from hyunjimoon on 2024-08-08T15:53:49Z

@jeanbaptiste <> angie agenda
## strategy
mission: diffuse bayes in business

### job strategy
1. pursuing two phds (engineering and management (technology innovation, entrepreneurship, strategy))?
2. pros and cons of professorship for research?

### research strategy (operations)
1. stories behind the two rewrites?
Q1: How combining causal with complex approaches can enhance entrepreneurial learning and decision-making in uncertain markets ?
- relation between causal and complex? todd's bayes-net (meaning fo "not trivial")
- uncertain markets vs uncertain environments? (uncertainty comes from within as well, no?)
- "First, ‚Äúscientific‚Äù entrepreneurs form, test and update their beliefs about the success or value of their ideas. Second, they form, test and update their beliefs about the generating mechanisms underlying such ideas." vs hypothesis free learning

- relevant chapters from BE paper 
-- prior formation with theory: "Logical reasoning and causal thinking (Pearl (2009)) are especially important because, through them, entrepreneurs can intentionally and deliberately form priors through theories (Felin & Zenger, 2017; Ehrig & Schmidt, 2022; Agarwal et al., 2023) and, hence, choose (Agrawal et al., 2021; Gans et al., 2019; Gans et al., 2021) which idea is worth pursuing."

Q2: How fundamental entrepreneurial principles such as constraints or randomness influence strategic pivots and business model innovation ?
- classification of constraints (strategic, operationational)
- word choice of strategic pivot?

## tactics
1. how to summarize master_alg.tex to share with bayes learning scholars (felin, todd, dan) which I scheduled to have chat with
2. how to synthesize with bayes in business community?

---

### Reply from hyunjimoon on 2024-08-08T17:03:24Z

angie's note:
- co-adaptation (influence of two agents; own adaptive trajectories; symbiosis; tree root and fungi VS parasite VS commensalism) vs co-option ()

- Natural selection is the only known causal process capable of producing complex functional organic mechanisms.

----
[claude](https://claude.ai/chat/80355df3-dc45-482d-890c-392e91ed48d2) explains radnomness vs uncertainty:
Based on the conversation and the provided documents, the relationship between randomness and uncertainty is complex and nuanced. Here's a summary of the key points:

1. Perspective difference:
The conversation suggests that "randomness" is often viewed from a system modeler's perspective, while "uncertainty" is more from the perspective of an agent within the system. This implies they are related concepts but with different emphases.

2. Mathematical vs. temporal aspects:
Randomness is described as a more abstract mathematical concept that isn't necessarily bound to time. Uncertainty, on the other hand, is often associated with unpredictability over time. This distinction is important in fields like quantum mechanics where time may be a more abstract or symmetrical concept.

3. Scope and scale:
The discussion mentions that deterministic models may work at very local and specific scales, but randomness and uncertainty become more prominent at larger scales or in more complex systems (like biology or market behavior).

4. Aleatoric uncertainty:
While the conversation doesn't explicitly state that randomness is equivalent to aleatoric uncertainty, there are similarities in how they are described. Aleatoric uncertainty typically refers to inherent variability or randomness in a system that can't be reduced by gathering more information. This aligns with some of the examples given of randomness in the conversation, such as variability in market behavior or individual differences among employees.

5. Epistemological considerations:
The conversation touches on epistemological issues, suggesting that our understanding and modeling of randomness and uncertainty are influenced by the theoretical frameworks and tools we use. This implies that the relationship between randomness and uncertainty might be partly a product of our methods of observation and analysis.

6. Complexity and reductionism:
There's a critique of reductionist approaches that try to apply deterministic or purely causal models to complex systems (like biology or entrepreneurship). This suggests that randomness and uncertainty might be emergent properties in complex systems that can't be fully captured by reductionist approaches.

In conclusion, while randomness and aleatoric uncertainty share some characteristics, the conversation suggests a more nuanced view where randomness is a broader concept that can manifest in various ways, including as uncertainty in temporal predictions. The relationship between the two concepts seems to depend on the scale, context, and theoretical framework being used.

---

## Reply from hyunjimoon on 2024-09-12T11:16:57Z

applying auto industry evolution dynamics to computing industry then scoping to bayesian
### auto industry evolution:

| Aspect | Ford (1920) | GM (1955) | Toyota (2000) |
|--------|-------------|-----------|---------------|
| Product | Simple, unvarying | Broad line; constantly changing | Simplified, then growing line |
| Process | Interchangeable parts, moving assembly; high wage | Flexible Mass production | Intensive improvement focus |
| Supply Chain | Simple parts, unvarying, vertically integrated | Complex, Vertically integrated | Intensively managed |
| Marketing Strategy | Low price, high volume, "horseless" | Segmented | Reliability, quality |
| Finance | - | Consumer Credit | - |
| Weaknesses | Inflexible | Complexity | Over reaching? |

 the evolution of the auto industry from Ford's integral model, through GM's modular approach, to Toyota's refined integral system. This pattern can be extrapolated to understand similar transitions in other industries, such as computing.

### Computing Industry Evolution:
Here's a simplified version of the Computing Industry Evolution table that focuses on the key aspects of clockspeed theory:

### Simplified Computing Industry Evolution
| Aspect | IBM Era (1975-1985) | Wintel Era (1985-1995) | Platform Era (2010-2020) |
|--------|---------------------|------------------------|--------------------------|
| Industry Structure | Vertical Integration | Horizontal Disintegration | Partial Re-integration |
| Product Architecture | Integral | Modular | Mixed (Integral/Modular) |
| Innovation Speed | Slow | Fast | Very Fast |
| Key Players | Single Dominant (IBM) | Multiple Specialists | Few Ecosystem Leaders |
| Supply Chain | Tightly Controlled | Dispersed, Competitive | Globally Managed |
| Market Power Source | Full System Control | Component Dominance | User Experience & Ecosystem |

This simplified table captures the essence of the computing industry's evolution through the lens of clockspeed theory. It shows how the industry structure, product architecture, and innovation speed have changed over time, reflecting the cyclical nature of integration and disintegration described in the double helix model.

The table illustrates how the industry moved from a slow-moving, vertically integrated structure (IBM Era) to a fast-paced, horizontally disintegrated one (Wintel Era), and then to a very fast-paced, partially re-integrated model (Platform Era). This progression aligns with the concept of increasing clockspeed in the industry, where cycles of innovation and change occur more rapidly over time.

By focusing on these key aspects, the table provides a clearer and more accessible overview of how clockspeed theory applies to the computing industry's evolution, making it easier for people to grasp the concept at a glance.
### Bayesian Computing Evolution:

| Aspect | Early Bayesian Era (1990-2000) | BUGS Era (2000-2010) | Stan Era (2010-present) |
|--------|--------------------------------|----------------------|-------------------------|
| Key Software | Custom MCMC implementations | WinBUGS, OpenBUGS, JAGS | Stan, PyMC, INLA |
| Industry Structure | Academic-driven | Academic with some industry adoption | Wide adoption in academia and industry |
| Hardware Focus | Single-core CPUs | Multi-core CPUs | Multi-core CPUs, GPUs |
| Algorithms | Gibbs sampling, Metropolis-Hastings | Gibbs sampling, Slice sampling | HMC, NUTS, variational inference |
| Language/Interface | Often FORTRAN or C | BUGS language, R | Stan language, R, Python, Julia interfaces |
| Model Complexity | Simple hierarchical models | Moderate hierarchical models | Complex hierarchical and non-linear models |
| Computation Time | Days/weeks for complex models | Hours/days for complex models | Minutes/hours for many complex models |
| User Base | Primarily statisticians | Statisticians and some domain scientists | Wide range of scientists and industry practitioners |
| Diagnostics | Basic MCMC diagnostics | Enhanced MCMC diagnostics | Advanced diagnostics (e.g., Rhat, ESS, Pareto-k) |
| Workflow | Manual, often ad-hoc | Partially standardized | Emphasis on Bayesian workflow |
| Ecosystem | Limited, mostly custom tools | Growing, some R packages | Extensive (tidybayes, bayesplot, loo, etc.) |
| Documentation | Academic papers | User manuals, some books | Extensive manuals, books, online resources |
| Community | Small, academic-focused | Growing, mailing lists | Large, diverse (forums, social media, conferences) |
| Key Challenges | Making MCMC feasible | Improving ease of use | Scaling to big data, expanding to new domains |

This table highlights the evolution of Bayesian computing, focusing on the transition from early custom implementations to the BUGS era, and then to the current Stan-dominated era. It emphasizes aspects that would be particularly relevant to StanCon attendees, such as algorithmic improvements, ecosystem growth, and the expansion of the user base.

---

## Reply from hyunjimoon on 2024-09-17T01:05:44Z

Teppo Felin's talk on AI and human cognition and causal reasoning. long story short, i think probabilistic program can do what teppo argues llm cannot do. summary below. thanks @chasfine for introducing and @jeanbaptiste for attending

[human cognition causal reasoning teppo felin](https://otter.ai/u/jcQxptgn2Tyb7sAT6AU4TGCBM78?tab=summary)

AI replacing human decision-making with examples and quotes from experts. [0:00](https://otter.ai/u/jcQxptgn2Tyb7sAT6AU4TGCBM78?tab=summary&t=0s)

Expert discusses AI's potential to replace strategists, entrepreneurs, and researchers.

Unknown speaker says AI may already surpass biological intelligence, and large language models are a key area of research.

Kahneman and others suggest that AI will eventually replace human decision making, with AI serving as scientists and subjects.

AI's role in decision-making, focusing on the limitations of the "data first" approach. [4:23](https://otter.ai/u/jcQxptgn2Tyb7sAT6AU4TGCBM78?tab=summary&t=263s)

The speaker discusses the potential of AI in business, particularly in predicting outcomes and making decisions.

The speaker argues that starting with data may not always be the best approach in decision-making under uncertainty.

The speaker discusses the idea that the scientific method is becoming obsolete in the age of big data, with correlation superseding causation.

The speaker references a paper co-authored with five others, including a cosmologist, biologist, and computer scientist, which challenges the idea that machines and humans process information in the same way.

The speaker discusses the history of cognitive architectures, from the 1956 Dartmouth conference to recent advancements in large language models.

The speaker highlights the limitations of past approaches, such as limited generality and specificity, and how current AI models are attempting to overcome these limitations.

AI's ability to process and generate human language, with a focus on large language models and their limitations. [11:47](https://otter.ai/u/jcQxptgn2Tyb7sAT6AU4TGCBM78?tab=summary&t=707s)

The speaker discussed the history of AI research, from rule-based systems to sub-symbolic systems like artificial neural networks and machine learning.

The speaker highlighted the potential of current AI systems, such as large language models, for strategic decision-making and problem-solving.

Unknown Speaker discusses large language models and their capabilities.

Speaker highlights differences between human cognition and large language models.

Speaker emphasizes the importance of attention in large language models.

Limitations of large language models in reasoning and understanding context. [17:48](https://otter.ai/u/jcQxptgn2Tyb7sAT6AU4TGCBM78?tab=summary&t=1068s)

The speaker discusses the capabilities of large language models (LLMs), including their ability to generate novel sentences and memorize vast amounts of information.

The speaker presents a thought experiment involving a hypothetical LLM trained on all text up to 1633, demonstrating the limitations of LLMs in terms of their inability to access information beyond their training data.

The limitations of AI are highlighted when it comes to reasoning tasks, as large language models can only mimic the data they've been trained on.

Francois Scholt has developed an abstract reasoning corpus to test the ability of large language models to genuinely reason and solve new problems.

Bayesian updating and evidence-based decision making in the context of flight in 1903. [23:21](https://otter.ai/u/jcQxptgn2Tyb7sAT6AU4TGCBM78?tab=summary&t=1401s)

Unknown speaker discusses limitations of computational models in cognition, particularly in producing text and updating beliefs based on evidence.

Speaker pushes back on the idea that data and evidence provide justified belief and knowledge, suggesting that Bayesian updating may not always be the best approach.

Unknown speaker discusses flight in 1903, citing lack of successful attempts and scientific consensus against it.

Evidence and data are presented to update beliefs on flight, including observations of birds and public displays by scientists.

How theories and beliefs shape data collection and decision-making. [29:28](https://otter.ai/u/jcQxptgn2Tyb7sAT6AU4TGCBM78?tab=summary&t=1769s)

The Wright Brothers theorized flight was possible in 1-10 billion years, despite evidence to the contrary.

The Wright Brothers ignored data, focusing on specific problems to solve, such as lift, and used wind tunnels and propulsion to experiment with rotation.

The speaker discusses the role of data in decision-making, highlighting the importance of theories and creative problem-solving in understanding human cognition.

The speaker references neuroscientist Henry Yen's work on fruit flies, emphasizing the complexity of their information processing and problem-solving abilities.

Using experimentation and causal reasoning to create new knowledge, with a focus on the role of beliefs and data in decision-making. [34:27](https://otter.ai/u/jcQxptgn2Tyb7sAT6AU4TGCBM78?tab=summary&t=2068s)

Speaker discusses the importance of data belief asymmetry in creating new knowledge and value.

Speaker argues that humans have unique strengths in forward-looking causal reasoning and experimentation.

Speaker emphasizes the need for the right data and theory to guide experimentation, rather than just more data and compute.

AI's limitations in decision-making and problem-solving. [37:55](https://otter.ai/u/jcQxptgn2Tyb7sAT6AU4TGCBM78?tab=summary&t=2276s)

The speaker discusses the idea that people's beliefs and behaviors can be influenced by the data and information they receive, and how this can lead to different conclusions and decisions.

The speaker provides examples of how this plays out in different contexts, such as Airbnb, and how people's perceptions of the company changed over time as more data became available.

Unknown Speaker argues AI is constrained by training data, lacks causal reasoning abilities.

Speaker skeptical of AI hybrid technologies, believes human cognition is more than prediction and data.

Human cognition and AI, with focus on creativity and intuition. [43:08](https://otter.ai/u/jcQxptgn2Tyb7sAT6AU4TGCBM78?tab=summary&t=2588s)

The speaker argues that human cognition is not just data processing, but involves taking theory, making leaps of faith, and relying on intuition.

The speaker suggests that this capacity for biases and motivated reasoning is a fundamental aspect of human cognition, despite being a bad thing.

The speaker argues that conventional wisdom can be limiting and that contrarian theories can lead to novel and true ideas.

The speaker questions why we can't program an AI to come up with new ideas and experiments to prove or disprove them, like humans do.

Using evolutionary mechanisms to program AI with adaptive reasoning capabilities. [48:42](https://otter.ai/u/jcQxptgn2Tyb7sAT6AU4TGCBM78?tab=summary&t=2922s)

Unknown Speaker discusses the limitations of AI and the need for leaps of faith in decision-making.

Speaker highlights the importance of considering biases and evolutionary mechanisms in AI development.

Speaker questions whether AI can be programmed to take leaps of faith like humans, and if so, how.

Speaker references new AI models, such as ChatGPT, and their potential for reasoning capabilities.


---

### Reply from tomfid on 2024-09-17T16:33:56Z

I haven't listened to the whole thing yet, but some of these statements strike me as absurd on face. For example, "the data deluge makes the scientific method obsolete". Honestly some of this reads like the word salad in a Trump speech.

---

### Reply from hyunjimoon on 2024-09-17T16:36:02Z

just to be clear, that seems to be the statement speaker (teppo) is against, from  https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4737265

---

### Reply from tomfid on 2024-09-17T17:03:26Z

OK, good! I think the 'heavier than air' example is a useful instance of the general problem, that data doesn't help you to understand the part of the state space that the data has never explored, unless you use it to develop systematic causal theories.

---

### Reply from tomfid on 2024-09-17T17:04:04Z

I'll put Teppo back on my xmas card list.

---

### Reply from jeanbaptiste on 2024-09-17T17:33:30Z

Thanks @hyunjimoon for sharing Teppo's event, it was very interesting, especially regarding the historical perspective. I am not a specialist of early AI works, but an enthusiast of this period regarding early interactive systems such as Ivan Sutherland or Doug Engelbart works. 

In previous discussions (about Bounded Rationality / TAP theory of adjacent possibles), the GPS (general problem solver) of Simon and Newell was mentioned. This article by Sony CSL creativity researcher in Paris was also mentioned, maybe worth revisiting in the context of Tempo's work. In terms of game mechanics/interface design for a Virtual/AI co-founder/assistant, I think a graph like structure with adjacent possibles / bounded spaces would make a lot of sense.

https://arxiv.org/abs/1701.00994

<img width="659" alt="image" src="https://github.com/user-attachments/assets/4b9abb7c-6023-419d-8e23-6ee165c11a89">


<img width="762" alt="image" src="https://github.com/user-attachments/assets/ecf0f168-017e-4aaf-a379-023d488792cb">




---

### Reply from jeanbaptiste on 2024-09-17T17:38:32Z

also this interesting HCI paper about feedforward https://www.32al.io/projects/octopocus/


![](https://www.32al.io/wp-content/uploads/2022/08/cplx_drop_1.jpg)

![](https://www.32al.io/wp-content/uploads/2022/08/cplx_drop_2.jpg)


---

### Reply from tomfid on 2024-09-17T17:48:15Z

I think the article I wrote about here is another good example: https://metasd.com/2013/04/early-warnings-of-catastrophe/

The authors describe a simple system (predator-prey with juveniles) in which the usual warning signs of approaching criticality (increasing variance) may not be visible. Without complete observations of the system and/or a causal theory of its operation, data provides no warning of impending catastrophe.

---

## Reply from hyunjimoon on 2024-09-24T12:22:01Z

## evolution = frequentist
As described in three fits for my research proposal https://github.com/Data4DM/BayesSD/discussions/252#discussioncomment-10738109, I'm curious how does definition/perspective of `fit` might differ in evolutionary learning vs bayesian learning? Your thoughts using the terms like utility, action, state, probability distribution would be very helpful. Synthesizing x-axis of optimization üßä #248, üöótesla example https://github.com/Data4DM/BayesSD/discussions/242#discussioncomment-10579222, üìöMS paper classification in https://github.com/Data4DM/BayesSD/discussions/255#discussioncomment-10720376, my hypothesis is 

> evolutionary: bayes learning = frequentist : bayes modeling technique

Evolutionary learning is not useful for pivoting with fixed goal. With exaptation, constraint on fixed goal is relaxed but I don't have concrete math model. https://github.com/Data4DM/BayesSD/discussions/246#discussioncomment-10715556 touches this idea. pivoting to new desirability from below is visual for this idea.
![image](https://github.com/user-attachments/assets/e60193e1-81c3-4660-8a50-a11163c91013)


## CROSSFITüèãüèº
Using clockspeed spirit of benchmarking across species and industry, I wish to benchmark across three fits in the order of fastest to slowest clockspeed: deal-investor, product-market, program-entrepreneur fit. i.e. entrepreneurial finance is fruit fly ü™∞. @chasfine's use of evolution:
<img width="100" alt="image" src="https://github.com/user-attachments/assets/46759d48-6e24-4407-bcd0-7bf47a2ff156">

## Prediction model quality - fitness of use? ùå≠
Bayesian workflow itself is philosophy on defining fit. [Some models are useful, but how do we know which ones?
Towards a unified Bayesian model taxonomy](https://arxiv.org/pdf/2209.02439)
<img width="500" alt="image" src="https://github.com/user-attachments/assets/c9ce54ae-1f05-4eb6-ab1b-37cc0d649c03">




---

### Reply from hyunjimoon on 2024-09-26T14:59:57Z

### Component-wise, Theory wise Decomposition of Rational Agency, evolution

| Component | Description | Entrepreneurial Context |
|-----------|-------------|-------------------------|
| State (s) | Current condition of the environment | Market conditions, competitive landscape, internal resources |
| Action (a) | Possible decisions or strategies | Market entry, product development, resource allocation |
| Environment (Env) | Models how actions and states interact | Dynamics of the business ecosystem |
| Utility (U) | Quantifies desirability of outcomes | Projected profits, market share, social impact, growth potential |
| Expectation (E[]) | Accounts for uncertainty through probabilistic reasoning | Decision-making based on imperfect information |
| Argmax | Selection of action maximizing expected utility | Optimal decision-making process |
| act* | Optimal action taken at each point in time | Specific choices about market entry, product development, etc. |

This decomposition connects with entrepreneurial axioms:
- Freedom: Range of possible actions and states
- Constraint: Limitations of the environment and argmax operation
- Uncertainty: Addressed through the expectation operator
- Noisy Learning: Reflected in dynamic nature of environment and state updates


### Function-wise, Algorithm wise Decomposition of Rational Agency, Bayesian

| Function | Description | Entrepreneurial Context |
|----------|-------------|-------------------------|
| Simplifying | Reducing complex problems into manageable components | Dealing with overwhelming complexity of business environments |
| Choosing | Making decisions under uncertainty and limited information | Aligns with argmax operation in component-wise view |
| Probabilistic Reasoning | Understanding and leveraging probabilities in decision-making | Corresponds to expectation component and addresses uncertainty axiom |
| Calibrating | Adjusting strategies based on feedback and new information | Relates to noisy learning axiom, involves updating environment model and utility assessments |

This decomposition aligns with broader evolutionary strategies in decision-making, focusing on cognitive processes that have evolved to deal with complex, uncertain environments - a hallmark of entrepreneurial decision-making.

---

[Discussion link](https://github.com/Data4DM/BayesSD/discussions/100)

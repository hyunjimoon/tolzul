# ì „ë¼ì¢Œìˆ˜êµ° ê²¬ë¦¬ì‚¬ì˜ êµ°ë ¹
# Chapter 3: Empirics (è½‰) â€” ê¹€ì™„ ğŸ™

# P3 ğŸ¤¹: Empirics & Results

## Chapter 3: Empirics (è½‰) â€” ê¹€ì™„ ğŸ™ + ë‚˜ëŒ€ìš© ğŸ…

---

## PART A: DATA & METHODS

### 3.1 Data Sources

**AV/AI Industry Cross-Section**

- Industry-level CR estimation
- CR calibration across industries

### 3.2 Measurement Strategy

**Commitment Cost (C):**
- Imitation lag (time for competitors to copy)
- Asset specificity (R&D redeployability)
- Regulatory lock-in (certification costs)

**Flexibility Cost (F):**
- Late entry penalty (market share decay)
- Option maintenance (overhead for parallel paths)
- Coordination cost (complexity of multiple tracks)

**CR = C / (C + F)**

### 3.3 Empirical Specifications

**Newsvendor Calibration:**
$$V^* = F^{-1}\left(\frac{C}{C + F}\right) = F^{-1}(CR)$$

---

## PART B: RESULTS

### 3.4 Industry CR Calibration

| Industry | C (est.) | F (est.) | CR | Optimal V* |
|----------|----------|----------|-----|-----------|
| AV (LiDAR vs Vision) | High | Medium | 0.65 | 2-3 paths |
| Biotech | Very High | High | 0.55 | 1-2 paths |
| SaaS | Low | Low | 0.50 | 1 path |
| Quantum Computing | Very High | Low | 0.85 | 3+ paths |

### 3.5 P1/P2 Unification on CRâ€“V Plane

| CR Range | P1 Trap | P2 Trap | Optimal |
|----------|---------|---------|---------|
| CR < 0.3 | âŒ | - | Commit early |
| 0.3 < CR < 0.7 | - | - | Balance |
| CR > 0.7 | - | âœ… | Many options |

### 3.6 Boundary Conditions

**When Model Breaks Down:**
- Extreme uncertainty: Model assumes estimable distributions
- Zero-sum competition: Ignores strategic interactions
- Regulatory capture: C and F become politically determined

---

**Phase:** 3 â€” è½‰ (Empirics & Results)
**Commander:** ê¹€ì™„ ğŸ™ | **Builder:** ë‚˜ëŒ€ìš© ğŸ…


---


## Cross-Synthesis: Empirical Integration

### Shared Validity Framework

| Validity Type | P1 | P2 | P3 |
|---------------|-----|-----|-----|
| **Internal** | Interaction design | Process tracing | Model calibration |
| **External** | 51K firms | Case triangulation | Industry scan |
| **Construct** | NLP validation | Commitment measures | CR estimation |

### Data-Dependent vs. Conceptual Tests

- **P1**: Data-dependent (regression on large N)
- **P2**: Mixed (Bayesian model + case evidence)
- **P3**: Conceptual (newsvendor framework + calibration)

### ê¹€ì™„ì˜ ì¢…í•© í‰ê°€

1. **Interesting**: ì„¸ ë…¼ë¬¸ ëª¨ë‘ counter-intuitive ë°œê²¬ ì œì‹œ
2. **Important**: ì‹¤ë¬´ì  í•¨ì˜ ëª…í™• (Tesla Rule, Waymo Rule, CR-V plane)
3. **Valid**:
   - P1: ê°•ê±´ (ë‹¤ì¤‘ robustness)
   - P2: ì¤‘ê°„ (case ì˜ì¡´)
   - P3: ê°œë…ì  íƒ€ë‹¹ì„± ë†’ìŒ, ì‹¤ì¦ ì¶”ê°€ í•„ìš”

---
*Generated by ê¹€ì™„ ğŸ™ (Chapter 3 Lead) + ë‚˜ëŒ€ìš© ğŸ… (Builder)*
*Collaboration: ì •ìš´ â†’ ê¶Œì¤€ â†’ ê¹€ì™„ â†’ ì–´ì˜ë‹´*

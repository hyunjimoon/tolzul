# ë…¼ë¬¸ ìë™ ìƒì„± í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ
# Paper Auto-Generation Testing Guide

## 1. í•„ìˆ˜ í…ŒìŠ¤íŠ¸ (Essential Tests)

ë…¼ë¬¸ ìë™ ìƒì„± íŒŒì´í”„ë¼ì¸ì˜ ì‹ ë¢°ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ **3ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì „ëµ**:

### Tier 1: í•µì‹¬ í†µê³„ í…ŒìŠ¤íŠ¸ (Critical - Must Pass)

**ëª©ì **: ë…¼ë¬¸ì— ë“¤ì–´ê°€ëŠ” ëª¨ë“  ìˆ«ìê°€ ì •í™•í•œì§€ ê²€ì¦

#### 1.1 ëª¨ë¸ ê³„ìˆ˜ í…ŒìŠ¤íŠ¸ (H1/H2 Coefficients)
```python
# test/integration/test_paper_results.py

def test_h1_vagueness_coefficient_sign():
    """H1: Vagueness ê³„ìˆ˜ê°€ ìŒìˆ˜ì¸ì§€ í™•ì¸ (ì •ë³´ë¹„ìš© ê°€ì„¤)"""
    result = test_h1_early_funding(df)
    coef = result.params['z_vagueness']
    assert coef < 0, "H1: Vagueness should reduce early funding"

def test_h2_interaction_exists():
    """H2: VÃ—F ìƒí˜¸ì‘ìš© í•­ì´ ëª¨ë¸ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    result = test_h2_main_growth(df)
    interaction_terms = [p for p in result.params.index
                        if 'vagueness' in p and 'hardware' in p]
    assert len(interaction_terms) > 0, "H2: VÃ—F interaction must exist"
```

**ì´ê²ƒì´ ì¤‘ìš”í•œ ì´ìœ **:
- ë…¼ë¬¸ì˜ í•µì‹¬ ì£¼ì¥ì´ ë°ì´í„°ì—ì„œ ì‹¤ì œë¡œ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸
- ê³„ìˆ˜ ë¶€í˜¸ê°€ ë°”ë€Œë©´ ë…¼ë¬¸ ì „ì²´ ë‚´ëŸ¬í‹°ë¸Œê°€ ë°”ë€œ
- ë¦¬ë·°ì–´ê°€ ì¬í˜„í•  ë•Œ ê°™ì€ ê²°ê³¼ê°€ ë‚˜ì™€ì•¼ í•¨

#### 1.2 í…Œì´ë¸” ê°’ ì¼ì¹˜ í…ŒìŠ¤íŠ¸ (Table Validation)
```python
def test_table1_matches_h1_model():
    """Table 1ì˜ ê³„ìˆ˜ê°€ H1 ëª¨ë¸ ê²°ê³¼ì™€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€"""
    result = test_h1_early_funding(df)

    # Generate table
    from scripts.generate_paper_tables import generate_table1_h1
    latex_table = generate_table1_h1(df, output_path='/tmp/table1.tex')

    # Extract coefficient from LaTeX
    import re
    coef_match = re.search(r'Vagueness.*?(-?\d+\.\d+e[+-]\d+)', latex_table)
    table_coef = float(coef_match.group(1))
    model_coef = result.params['z_vagueness']

    # Must match to at least 3 significant figures
    assert abs(table_coef - model_coef) < 1e-10
```

**ì´ê²ƒì´ ì¤‘ìš”í•œ ì´ìœ **:
- ì‚¬ëŒì´ ì†ìœ¼ë¡œ LaTeX í…Œì´ë¸”ì„ ë§Œë“¤ë©´ ì˜¤íƒ€ ë°œìƒ
- ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ê°€ ì˜¬ë°”ë¥´ê²Œ ê°’ì„ ì¶”ì¶œí•˜ëŠ”ì§€ í™•ì¸
- ë°ì´í„°ê°€ ë°”ë€Œì–´ë„ í…Œì´ë¸”ì´ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ëŠ”ì§€ í™•ì¸

#### 1.3 Figure ìƒì„± í…ŒìŠ¤íŠ¸ (Figure Generation)
```python
def test_figure2_file_created():
    """Figure 2 (Early Funding vs Vagueness)ê°€ ìƒì„±ë˜ëŠ”ì§€"""
    from src.cli import cmd_generate_plots

    # Run plotting
    args = type('obj', (object,), {'dataset': 'all'})
    cmd_generate_plots(args)

    # Check file exists
    fig_path = Path('paper/figures/fig2_early_funding.pdf')
    assert fig_path.exists(), "Figure 2 PDF must be created"
    assert fig_path.stat().st_size > 1000, "Figure 2 must not be empty"
```

**ì´ê²ƒì´ ì¤‘ìš”í•œ ì´ìœ **:
- LaTeX ì»´íŒŒì¼ ì‹œ ê·¸ë¦¼ì´ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
- ê·¸ë¦¼ì´ ë¹ˆ íŒŒì¼ì´ë©´ ë…¼ë¬¸ì— ì•„ë¬´ê²ƒë„ ì•ˆ ë‚˜ì˜´
- ìë™í™” ìŠ¤í¬ë¦½íŠ¸ê°€ ëê¹Œì§€ ì‹¤í–‰ë˜ëŠ”ì§€ í™•ì¸

---

### Tier 2: ë°ì´í„° í’ˆì§ˆ í…ŒìŠ¤íŠ¸ (Important - Should Pass)

**ëª©ì **: ì…ë ¥ ë°ì´í„°ê°€ ë¶„ì„ì— ì í•©í•œì§€ í™•ì¸

#### 2.1 ìƒ˜í”Œ í¬ê¸° í…ŒìŠ¤íŠ¸
```python
def test_sample_size_sufficient():
    """ìµœì†Œ ìƒ˜í”Œ í¬ê¸° í™•ì¸ (í†µê³„ì  ê²€ì •ë ¥)"""
    df = load_dataframe('data/processed/features_engineered.nc')

    # H1 requires at least 30 observations (rule of thumb)
    assert len(df) >= 30, f"Sample too small: {len(df)} < 30"

    # H2 requires balanced classes
    growth_counts = df['growth'].value_counts()
    minority_class = growth_counts.min()
    assert minority_class >= 10, f"Minority class too small: {minority_class}"
```

#### 2.2 ê²°ì¸¡ì¹˜ í…ŒìŠ¤íŠ¸
```python
def test_no_missing_values_in_key_vars():
    """í•µì‹¬ ë³€ìˆ˜ì— ê²°ì¸¡ì¹˜ê°€ ì—†ëŠ”ì§€ í™•ì¸"""
    df = load_dataframe('data/processed/features_engineered.nc')

    key_vars = ['vagueness', 'early_funding_musd', 'is_hardware', 'growth']
    for var in key_vars:
        missing_pct = df[var].isna().sum() / len(df) * 100
        assert missing_pct < 5, f"{var} has {missing_pct:.1f}% missing"
```

#### 2.3 ì´ìƒì¹˜ í…ŒìŠ¤íŠ¸
```python
def test_vagueness_range():
    """Vagueness ì ìˆ˜ê°€ ìœ íš¨í•œ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€"""
    df = load_dataframe('data/processed/features_engineered.nc')

    assert df['vagueness'].min() >= 0, "Vagueness cannot be negative"
    assert df['vagueness'].max() <= 100, "Vagueness cannot exceed 100"

    # Check for unrealistic values
    extreme_high = (df['vagueness'] > 95).sum()
    assert extreme_high < len(df) * 0.01, "Too many extreme vagueness scores"
```

---

### Tier 3: íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸ (Good to Have)

**ëª©ì **: ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì‹¤í–‰ë˜ëŠ”ì§€ í™•ì¸

#### 3.1 End-to-End í…ŒìŠ¤íŠ¸
```python
def test_full_pipeline_runs():
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë°ì´í„° â†’ ë¶„ì„ â†’ ë…¼ë¬¸)"""
    import subprocess

    # Clean previous outputs
    subprocess.run(['make', 'clean-all'], check=True)

    # Run full pipeline
    result = subprocess.run(['make', 'all'], capture_output=True)

    # Check all outputs exist
    assert Path('data/processed/features_engineered.nc').exists()
    assert Path('paper/results_auto.tex').exists()
    assert Path('paper/tables/table1_h1.tex').exists()
    assert Path('paper/figures/fig2_early_funding.pdf').exists()
```

#### 3.2 ì¬í˜„ì„± í…ŒìŠ¤íŠ¸
```python
def test_results_are_reproducible():
    """ë™ì¼í•œ ë°ì´í„°ë¡œ ë‘ ë²ˆ ì‹¤í–‰í•˜ë©´ ê°™ì€ ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ”ì§€"""
    df = load_dataframe('data/processed/features_engineered.nc')

    # Run H1 twice
    result1 = test_h1_early_funding(df)
    result2 = test_h1_early_funding(df)

    # Coefficients must be identical
    np.testing.assert_array_almost_equal(
        result1.params.values,
        result2.params.values,
        decimal=10,
        err_msg="H1 results not reproducible"
    )
```

---

## 2. í…ŒìŠ¤íŠ¸ íŒŒì¼ êµ¬ì¡° (Test Organization)

```
test/
â”œâ”€â”€ unit/                          # Tier 1: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_models.py            # H1/H2/H3/H4 ëª¨ë¸ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ (53 tests)
â”‚   â”œâ”€â”€ test_features.py          # Vagueness scorer í…ŒìŠ¤íŠ¸ (25 tests)
â”‚   â””â”€â”€ test_data_io.py           # NetCDF I/O í…ŒìŠ¤íŠ¸ (NEW)
â”‚
â”œâ”€â”€ integration/                   # Tier 2: í†µí•© í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_paper_results.py     # ë…¼ë¬¸ ê²°ê³¼ ê²€ì¦ (Table/Figure ì¼ì¹˜)
â”‚   â”œâ”€â”€ test_data_quality.py      # ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ (NEW)
â”‚   â””â”€â”€ test_pipeline.py          # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (NEW)
â”‚
â”œâ”€â”€ fixtures/                      # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”‚   â”œâ”€â”€ sample_data.nc            # ìƒ˜í”Œ ë°ì´í„° (50 companies)
â”‚   â””â”€â”€ expected_outputs/         # ê¸°ëŒ€ ì¶œë ¥ê°’
â”‚       â”œâ”€â”€ table1_expected.tex
â”‚       â””â”€â”€ h1_expected_coef.json
â”‚
â””â”€â”€ conftest.py                   # ê³µìœ  fixtures (pytest)
```

---

## 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë°©ë²• (How to Run Tests)

### ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (Quick - 1ë¶„)
```bash
# í•µì‹¬ ëª¨ë¸ í…ŒìŠ¤íŠ¸ë§Œ (ê³„ìˆ˜ê°€ ë§ëŠ”ì§€)
pytest test/unit/test_models.py::TestH1EarlyFunding -v --no-cov

# ë…¼ë¬¸ ê²°ê³¼ ê²€ì¦ (í…Œì´ë¸” ì¼ì¹˜í•˜ëŠ”ì§€)
pytest test/integration/test_paper_results.py -v --no-cov
```

### ì „ì²´ í…ŒìŠ¤íŠ¸ (Full - 5ë¶„)
```bash
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰ + ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸
make test

# ë˜ëŠ”
pytest test/ -v --cov=src --cov-report=html
```

### ë…¼ë¬¸ ì œì¶œ ì „ ê²€ì¦ (Before Submission - 10ë¶„)
```bash
# 1. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì¬ì‹¤í–‰
make clean-all
make all

# 2. ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
make test

# 3. ë…¼ë¬¸ ê°’ ê²€ì¦
make validate

# 4. PDF ì»´íŒŒì¼
make paper
```

---

## 4. ë¡œì»¬ í™˜ê²½ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ (Local Testing Example)

### 4.1 ì„¤ì¹˜ (Installation)
```bash
# 1. Clone repository
git clone https://github.com/user/empirics_ent_strat_ops.git
cd empirics_ent_strat_ops

# 2. Install dependencies (NO pyarrow needed!)
pip install -r requirements.txt

# 3. Verify installation
python -c "import xarray; import pandas; import statsmodels; print('âœ“ All dependencies OK')"
```

### 4.2 ë°ì´í„° ë³€í™˜ (Convert existing Parquet to NetCDF)
```bash
# If you have existing .parquet files:
python scripts/convert_to_netcdf.py --directory data/processed

# Expected output:
# Converting features_engineered.parquet...
#   âœ“ features_engineered.parquet (2.3 MB)
#     â†’ features_engineered.nc (1.8 MB)
#     Ratio: 0.78x
```

### 4.3 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (Run Full Pipeline)
```bash
# Step-by-step (recommended for first time)
make data                # â†’ data/processed/features_engineered.nc
make analysis            # â†’ paper/results_auto.tex
make tables              # â†’ paper/tables/*.tex
make figures             # â†’ paper/figures/*.pdf
make paper               # â†’ paper/output/main.pdf

# Or all at once:
make all
```

### 4.4 í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (Run Tests)
```bash
# Quick test (í•µì‹¬ë§Œ)
pytest test/unit/test_models.py -v --no-cov

# Expected output:
# test_h1_negative_vagueness_effect PASSED
# test_h2_interaction_term_exists PASSED
# ...
# ======================== 53 passed in 2.34s ========================

# Full test (ì „ì²´)
make test

# Expected output:
# test/unit/test_models.py .................... [ 68%]
# test/unit/test_features.py ............. [ 84%]
# test/integration/test_paper_results.py .... [100%]
# ======================== 78 passed in 4.12s ========================
```

---

## 5. í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ì‹œ ëŒ€ì‘ (Troubleshooting)

### Case 1: H1 ê³„ìˆ˜ ë¶€í˜¸ê°€ ë°”ë€œ
```
FAILED test_h1_negative_vagueness_effect
AssertionError: H1: Vagueness should reduce early funding
```

**ì›ì¸**:
- ë°ì´í„°ê°€ ë°”ë€œ
- ëª¨ë¸ ìŠ¤í™ ë³€ê²½ (ë³€ìˆ˜ ì¶”ê°€/ì œê±°)
- ì½”ë”© ì˜¤ë¥˜

**ëŒ€ì‘**:
1. ë°ì´í„° í™•ì¸: `df['vagueness'].describe()` - ë¶„í¬ê°€ ì´ìƒí•œê°€?
2. ëª¨ë¸ í™•ì¸: `test_h1_early_funding(df).summary()` - ì–´ë–¤ ë³€ìˆ˜ê°€ ë¬¸ì œ?
3. ì´ë¡  ì¬ê²€í† : H1 ê°€ì„¤ì´ í‹€ë ¸ì„ ìˆ˜ë„ ìˆìŒ

### Case 2: í…Œì´ë¸” ê°’ ë¶ˆì¼ì¹˜
```
FAILED test_table1_matches_h1_model
AssertionError: Table coefficient -0.234 != Model coefficient -0.235
```

**ì›ì¸**:
- LaTeX ìƒì„± ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë°˜ì˜¬ë¦¼ ì°¨ì´
- í…Œì´ë¸” ìƒì„± ì‹œ ë‹¤ë¥¸ ë°ì´í„° ì‚¬ìš©

**ëŒ€ì‘**:
1. `scripts/generate_paper_tables.py` í™•ì¸
2. `format_coef_se()` í•¨ìˆ˜ì˜ ì†Œìˆ˜ì  ìë¦¬ìˆ˜ í™•ì¸
3. í…ŒìŠ¤íŠ¸ì˜ í—ˆìš© ì˜¤ì°¨ ì¡°ì • (`decimal=3` â†’ `decimal=2`)

### Case 3: Figure ìƒì„± ì‹¤íŒ¨
```
FileNotFoundError: paper/figures/fig2_early_funding.pdf not found
```

**ì›ì¸**:
- ê·¸ë¦¼ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì˜¤ë¥˜
- ê²½ë¡œ ì˜¤íƒ€
- ë°ì´í„° ë¶€ì¡± (ë¹ˆ ê·¸ë¦¼)

**ëŒ€ì‘**:
1. ì§ì ‘ ì‹¤í–‰: `python -m src.cli generate-plots --dataset all`
2. ë¡œê·¸ í™•ì¸: ì–´ëŠ ë‹¨ê³„ì—ì„œ ì‹¤íŒ¨?
3. ìƒ˜í”Œ í¬ê¸° í™•ì¸: ê·¸ë¦¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì¶©ë¶„í•œê°€?

---

## 6. CI/CD í†µí•© (GitHub Actions)

### ìë™ í…ŒìŠ¤íŠ¸ (Every Push)
```yaml
# .github/workflows/test.yml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      - name: Run unit tests
        run: pytest test/unit/ -v
      - name: Run integration tests
        run: pytest test/integration/ -v
```

### ë…¼ë¬¸ ìë™ ë¹Œë“œ (On Main Branch)
```yaml
# .github/workflows/paper.yml
name: Build Paper

on:
  push:
    branches: [main]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run pipeline
        run: make all
      - name: Upload PDF
        uses: actions/upload-artifact@v3
        with:
          name: paper
          path: paper/output/main.pdf
```

---

## 7. ì²´í¬ë¦¬ìŠ¤íŠ¸ (Checklist)

### ë…¼ë¬¸ ì œì¶œ ì „ (Before Submission)
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ (`make test`)
- [ ] ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ (`make all`)
- [ ] PDF ì»´íŒŒì¼ ì„±ê³µ (`paper/output/main.pdf` ì¡´ì¬)
- [ ] Table 1-2 ê°’ì´ ëª¨ë¸ ê²°ê³¼ì™€ ì¼ì¹˜
- [ ] Figure 2-3 íŒŒì¼ ìƒì„±ë¨
- [ ] Results section ìë™ ìƒì„±ë¨ (`paper/results_auto.tex`)
- [ ] Git commitì— ëª¨ë“  ë³€ê²½ì‚¬í•­ í¬í•¨
- [ ] READMEì— ì¬í˜„ ë°©ë²• ëª…ì‹œ

### ë¦¬ë·° í”¼ë“œë°± í›„ (After Review)
- [ ] ë°ì´í„° ë³€ê²½ ì‹œ `make clean-all && make all` ì¬ì‹¤í–‰
- [ ] ëª¨ë¸ ìŠ¤í™ ë³€ê²½ ì‹œ í…ŒìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
- [ ] ìƒˆë¡œìš´ ê°€ì„¤ ì¶”ê°€ ì‹œ í…ŒìŠ¤íŠ¸ ì¶”ê°€
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ ì¬ê²€ì¦

---

## ìš”ì•½ (Summary)

**3ê°€ì§€ í•µì‹¬ í…ŒìŠ¤íŠ¸**:
1. **ëª¨ë¸ ê³„ìˆ˜ í…ŒìŠ¤íŠ¸**: ë…¼ë¬¸ì˜ í•µì‹¬ ì£¼ì¥ì´ ë°ì´í„°ì—ì„œ ë‚˜ì˜¤ëŠ”ê°€?
2. **í…Œì´ë¸” ê²€ì¦ í…ŒìŠ¤íŠ¸**: ìë™ ìƒì„±ëœ í…Œì´ë¸”ì´ ëª¨ë¸ ê²°ê³¼ì™€ ì¼ì¹˜í•˜ëŠ”ê°€?
3. **íŒŒì´í”„ë¼ì¸ E2E í…ŒìŠ¤íŠ¸**: ì²˜ìŒë¶€í„° ëê¹Œì§€ ì˜¤ë¥˜ ì—†ì´ ì‹¤í–‰ë˜ëŠ”ê°€?

**í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìˆœì„œ**:
```bash
# 1. ë¹ ë¥¸ ê²€ì¦ (1ë¶„)
pytest test/unit/test_models.py -v --no-cov

# 2. ì „ì²´ íŒŒì´í”„ë¼ì¸ (5ë¶„)
make all

# 3. ëª¨ë“  í…ŒìŠ¤íŠ¸ (5ë¶„)
make test

# 4. ë…¼ë¬¸ í™•ì¸ (ìˆ˜ë™)
open paper/output/main.pdf
```

**ì„±ê³µ ê¸°ì¤€**:
- ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ (78/78 passed)
- PDF ìƒì„± ì„±ê³µ
- í…Œì´ë¸”/ê·¸ë¦¼ ìë™ ìƒì„±
- Gitì— ëª¨ë“  ë³€ê²½ì‚¬í•­ commit

ì´ì œ ë°ì´í„°ê°€ ë°”ë€Œì–´ë„ `make all`ë§Œ ì‹¤í–‰í•˜ë©´ ë…¼ë¬¸ì´ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤! ğŸ‰

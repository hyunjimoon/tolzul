#!/usr/bin/env python3
"""
Presentation Examples Finder
=============================
ë…¼ë¬¸ ë°œí‘œìš© 4ê°œì‚¬ ëŒ€í‘œ ì˜ˆì‹œë¥¼ ì¶”ì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.

ê¸°ì¡´ features.py ëª¨ë“ˆì˜ í•¨ìˆ˜ë“¤ì„ í™œìš©í•˜ì—¬:
- Vagueness ê³„ì‚°
- Hardware/Software ë¶„ë¥˜
- Series A(2021) â†’ Series B+ ë˜ëŠ” M&A ê²°ê³¼ ì¶”ì 

ëª©í‘œ: ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì •í™•íˆ 4ê°œ íšŒì‚¬ ì¶”ì¶œ
- ë„ë©”ì¸: AI Software(1), Autonomous Vehicles(1), Quantum Computing(2)
- Series A: 2021ë…„ (M&AëŠ” 2022-2023 í—ˆìš©)
- ê²°ê³¼ ë‹¤ì–‘ì„±: Rapid B+(L=1), Slow B+(L=0), M&A(Censored)
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
import re
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Import features.py functions
sys.path.insert(0, str(Path(__file__).parent))
from modules.features import (
    compute_vagueness_vectorized,
    classify_hardware_vectorized
)

# Column mapping (adjust based on actual PitchBook export)
COLUMN_MAP = {
    'id': 'CompanyID',
    'name': 'CompanyName',
    'desc': 'Description',
    'keys': 'Keywords',
    'status': 'BusinessStatus',
    # Deal-related columns
    'deal_type': 'FinancingType',
    'deal_date': 'FinancingDate',
    'deal_size': 'FinancingSize'
}

# Deal type patterns (matching features.py logic)
B_PLUS_PAT = r"(?i)series\s*[b-z]|later\s*stage"
MA_PAT = r"(?i)acquired|acquisition|merger"

def classify_domain_custom(keywords: str, description: str) -> str:
    """
    ë„ë©”ì¸ì„ 3ê°€ì§€ë¡œ ë¶„ë¥˜: AI Software, Autonomous Vehicles, Quantum Computing

    Args:
        keywords: íšŒì‚¬ í‚¤ì›Œë“œ
        description: íšŒì‚¬ ì„¤ëª…

    Returns:
        ë„ë©”ì¸ ë¬¸ìì—´
    """
    if pd.isna(keywords):
        keywords = ""
    if pd.isna(description):
        description = ""

    text = f"{keywords} {description}".lower()

    # Quantum Computing (highest priority)
    if any(k in text for k in ["quantum", "qbit", "qubit"]):
        return "Quantum Computing"

    # Autonomous Vehicles
    if any(k in text for k in ["autonomous vehicle", "self-driving", "av ", "adas", "autonomous driving"]):
        return "Autonomous Vehicles"

    # AI Software
    if any(k in text for k in ["artificial intelligence", "ai ", "machine learning", "ml ",
                                "deep learning", "neural network", "nlp", "computer vision",
                                "natural language"]):
        return "AI Software"

    return "Other"


def parse_deals_from_company_row(row, deal_type_col='FinancingType', deal_date_col='FinancingDate'):
    """
    íšŒì‚¬ í–‰ì—ì„œ ë”œ ì •ë³´ íŒŒì‹± (PitchBook ë°ì´í„° êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”)

    ì´ í•¨ìˆ˜ëŠ” PitchBook ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ì¼ë°˜ì ìœ¼ë¡œ PitchBook ë°ì´í„°ëŠ”:
    1. ê° ë”œì´ ë³„ë„ì˜ í–‰ìœ¼ë¡œ ìˆê±°ë‚˜
    2. íšŒì‚¬ë‹¹ í•˜ë‚˜ì˜ í–‰ì— ì—¬ëŸ¬ ë”œ ì •ë³´ê°€ ì»¬ëŸ¼ìœ¼ë¡œ ìˆê±°ë‚˜
    3. JSON/ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë”œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŒ

    Returns:
        list of dict: [{'type': 'Series B', 'date': pd.Timestamp(...)}, ...]
    """
    deals = []

    # Method 1: ê° í–‰ì´ í•˜ë‚˜ì˜ ë”œ (ê°€ì¥ ì¼ë°˜ì )
    if deal_type_col in row and pd.notna(row[deal_type_col]):
        deals.append({
            'type': str(row[deal_type_col]),
            'date': pd.to_datetime(row[deal_date_col], errors='coerce')
        })

    return deals


def find_example_outcomes(company_id, df_all_deals, series_a_date):
    """
    Series A ì´í›„ ì²« ë²ˆì§¸ Series B+ ë˜ëŠ” M&A ë”œì„ ì°¾ìŒ

    Args:
        company_id: íšŒì‚¬ ID
        df_all_deals: ì „ì²´ ë”œ ë°ì´í„°í”„ë ˆì„ (ê° í–‰ì´ í•˜ë‚˜ì˜ ë”œ)
        series_a_date: Series A ë‚ ì§œ (ê¸°ì¤€ì  t_0)

    Returns:
        dict: {
            'outcome_type': str,
            'outcome_date': pd.Timestamp,
            'months_to_outcome': float
        }
    """
    # í•´ë‹¹ íšŒì‚¬ì˜ ë”œë§Œ í•„í„°ë§
    company_deals = df_all_deals[df_all_deals[COLUMN_MAP['id']] == company_id].copy()

    # Series A ì´í›„ ë”œë§Œ
    company_deals['deal_date_parsed'] = pd.to_datetime(company_deals[COLUMN_MAP['deal_date']], errors='coerce')
    post_a_deals = company_deals[company_deals['deal_date_parsed'] > series_a_date].copy()

    if len(post_a_deals) == 0:
        return {
            'outcome_type': 'No B+/M&A',
            'outcome_date': pd.NaT,
            'months_to_outcome': np.nan
        }

    # ë‚ ì§œìˆœ ì •ë ¬
    post_a_deals = post_a_deals.sort_values('deal_date_parsed')

    # ì²« ë²ˆì§¸ B+ ë˜ëŠ” M&A ì°¾ê¸°
    for _, deal in post_a_deals.iterrows():
        deal_type = str(deal[COLUMN_MAP['deal_type']])
        deal_date = deal['deal_date_parsed']

        # M&A ì²´í¬ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
        if re.search(MA_PAT, deal_type):
            months = (deal_date - series_a_date).days / 30.44
            return {
                'outcome_type': 'M&A',
                'outcome_date': deal_date,
                'months_to_outcome': months
            }

        # Series B+ ì²´í¬
        if re.search(B_PLUS_PAT, deal_type):
            months = (deal_date - series_a_date).days / 30.44
            return {
                'outcome_type': 'Series B+',
                'outcome_date': deal_date,
                'months_to_outcome': months
            }

    # B+/M&A ì—†ìŒ
    return {
        'outcome_type': 'No B+/M&A',
        'outcome_date': pd.NaT,
        'months_to_outcome': np.nan
    }


def assign_l_code(outcome_type: str, months_to_outcome: float, window_months: int = 17) -> str:
    """
    L-Code í• ë‹¹: '1' (Rapid B+), '0' (Slow/No B+), 'Censored' (M&A)

    Args:
        outcome_type: ê²°ê³¼ íƒ€ì…
        months_to_outcome: Series Aë¡œë¶€í„° ê²½ê³¼ ê°œì›”
        window_months: ê¸°ì¤€ ê¸°ê°„ (ê¸°ë³¸ 17ê°œì›”)

    Returns:
        L-Code ë¬¸ìì—´
    """
    if "M&A" in outcome_type:
        return "Censored"

    if pd.isna(months_to_outcome) or outcome_type == 'No B+/M&A':
        return "0"

    if months_to_outcome <= window_months:
        return "1"  # Rapid B+
    else:
        return "0"  # Slow B+


def find_presentation_cohort(df_raw: pd.DataFrame, output_path: Path = None) -> pd.DataFrame:
    """
    ë©”ì¸ í•¨ìˆ˜: ë°œí‘œìš© 4ê°œì‚¬ ì½”í˜¸íŠ¸ ì¶”ì¶œ

    Args:
        df_raw: PitchBook ì›ë³¸ ë°ì´í„°
        output_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ (optional)

    Returns:
        4ê°œì‚¬ DataFrame
    """
    print("="*80)
    print("PRESENTATION EXAMPLES FINDER")
    print("="*80)
    print(f"\nğŸ“Š Input data: {len(df_raw):,} rows\n")

    # Step 1: ê¸°ë³¸ ì •ì œ
    df = df_raw.copy()

    # CompanyIDê°€ ìˆëŠ”ì§€ í™•ì¸
    id_col = COLUMN_MAP['id']
    if id_col not in df.columns:
        print(f"âŒ ERROR: Column '{id_col}' not found in data")
        print(f"Available columns: {list(df.columns)[:10]}...")
        raise KeyError(f"Column '{id_col}' not found")

    # Step 2: features.py í•¨ìˆ˜ í™œìš©
    print("ğŸ”§ Applying features.py functions...")

    # Vagueness ê³„ì‚°
    desc_col = COLUMN_MAP['desc']
    keys_col = COLUMN_MAP['keys']

    if desc_col in df.columns and keys_col in df.columns:
        print(f"  Computing vagueness...")
        df['vagueness'] = compute_vagueness_vectorized(
            df[desc_col].fillna(""),
            df[keys_col].fillna("")
        )
        print(f"  âœ“ Vagueness computed: mean={df['vagueness'].mean():.3f}")
    else:
        print(f"  âš ï¸  Missing description/keywords columns - vagueness set to NaN")
        df['vagueness'] = np.nan

    # Hardware ë¶„ë¥˜
    if keys_col in df.columns:
        print(f"  Computing is_hardware...")
        df['is_hardware'] = classify_hardware_vectorized(
            df[keys_col].fillna(""),
            df[desc_col].fillna("") if desc_col in df.columns else None
        )
        print(f"  âœ“ Hardware classified: {df['is_hardware'].sum():,} hardware companies")
    else:
        df['is_hardware'] = 0

    # Domain ë¶„ë¥˜ (ë§ì¶¤í˜•)
    print(f"  Computing domain classification...")
    df['domain'] = df.apply(
        lambda row: classify_domain_custom(
            row.get(keys_col, ""),
            row.get(desc_col, "")
        ),
        axis=1
    )
    domain_counts = df['domain'].value_counts()
    print(f"  âœ“ Domains classified:")
    for domain, count in domain_counts.items():
        print(f"    - {domain}: {count:,}")

    # Step 3: Series A ì½”í˜¸íŠ¸ í•„í„°ë§ (2021ë…„)
    print(f"\nğŸ” Filtering Series A cohort (2021)...")

    # Series A ì •ë³´ ì°¾ê¸°
    deal_type_col = COLUMN_MAP['deal_type']
    deal_date_col = COLUMN_MAP['deal_date']

    if deal_type_col not in df.columns or deal_date_col not in df.columns:
        print(f"âŒ ERROR: Deal columns not found")
        print(f"Available columns: {list(df.columns)[:20]}...")
        raise KeyError("Deal columns not found")

    # Series A í•„í„°ë§
    df['is_series_a'] = df[deal_type_col].fillna("").str.contains(r"(?i)series\s*a(?![b-z])", regex=True)
    df['deal_year'] = pd.to_datetime(df[deal_date_col], errors='coerce').dt.year

    df_series_a = df[df['is_series_a'] & (df['deal_year'] == 2021)].copy()
    print(f"  âœ“ Found {len(df_series_a):,} Series A deals in 2021")

    # Step 4: ê° íšŒì‚¬ì˜ Outcome ê³„ì‚°
    print(f"\nğŸ“ˆ Computing outcomes for each company...")

    df_series_a['series_a_date'] = pd.to_datetime(df_series_a[deal_date_col], errors='coerce')

    outcomes = []
    for idx, row in df_series_a.iterrows():
        outcome = find_example_outcomes(
            row[id_col],
            df,  # ì „ì²´ ë°ì´í„°ì—ì„œ ë”œ ì°¾ê¸°
            row['series_a_date']
        )
        outcome['company_id'] = row[id_col]
        outcomes.append(outcome)

    df_outcomes = pd.DataFrame(outcomes)
    df_series_a = df_series_a.merge(df_outcomes, left_on=id_col, right_on='company_id', how='left')

    # L-Code í• ë‹¹
    df_series_a['l_code'] = df_series_a.apply(
        lambda row: assign_l_code(row['outcome_type'], row['months_to_outcome']),
        axis=1
    )

    print(f"  âœ“ Outcomes computed:")
    outcome_counts = df_series_a['outcome_type'].value_counts()
    for outcome, count in outcome_counts.items():
        print(f"    - {outcome}: {count:,}")

    l_code_counts = df_series_a['l_code'].value_counts()
    print(f"  âœ“ L-Codes:")
    for code, count in l_code_counts.items():
        print(f"    - {code}: {count:,}")

    # Step 5: ì¡°ê±´ì— ë§ëŠ” 4ê°œì‚¬ ì„ íƒ
    print(f"\nğŸ¯ Selecting 4 representative companies...")

    target_domains = {
        'AI Software': 1,
        'Autonomous Vehicles': 1,
        'Quantum Computing': 2
    }

    selected = []

    for domain, target_count in target_domains.items():
        domain_companies = df_series_a[df_series_a['domain'] == domain].copy()
        print(f"\n  {domain}: {len(domain_companies)} candidates")

        if len(domain_companies) == 0:
            print(f"    âš ï¸  No companies found in {domain}")
            continue

        # ê²°ê³¼ ë‹¤ì–‘ì„± í™•ë³´
        l_codes_needed = ['1', '0', 'Censored']
        for l_code in l_codes_needed[:target_count]:
            candidates = domain_companies[domain_companies['l_code'] == l_code]
            if len(candidates) > 0:
                # Vaguenessê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì„ íƒ (ë” í¥ë¯¸ë¡œìš´ ì˜ˆì‹œ)
                best = candidates.nlargest(1, 'vagueness', keep='first')
                selected.append(best)
                print(f"    âœ“ Selected 1 company with L={l_code}")
                domain_companies = domain_companies[domain_companies[id_col] != best[id_col].values[0]]
            else:
                # ëŒ€ì²´: ì•„ë¬´ê±°ë‚˜ ì„ íƒ
                if len(domain_companies) > 0:
                    best = domain_companies.nlargest(1, 'vagueness', keep='first')
                    selected.append(best)
                    print(f"    âœ“ Selected 1 company (fallback)")
                    domain_companies = domain_companies[domain_companies[id_col] != best[id_col].values[0]]

    if len(selected) == 0:
        print(f"\nâŒ ERROR: No companies selected!")
        return pd.DataFrame()

    df_final = pd.concat(selected, ignore_index=True)

    # Step 6: ìµœì¢… ìŠ¤í‚¤ë§ˆë¡œ ì •ì œ
    print(f"\nğŸ“‹ Final cohort: {len(df_final)} companies")

    output_columns = [
        'company_name',
        'domain',
        'promise_text',
        'keywords',
        'vagueness',
        'series_a_date',
        'outcome_type',
        'outcome_date',
        'months_to_outcome',
        'l_code'
    ]

    # ì»¬ëŸ¼ ì´ë¦„ ë§¤í•‘
    df_export = pd.DataFrame()
    df_export['company_name'] = df_final[COLUMN_MAP['name']]
    df_export['domain'] = df_final['domain']
    df_export['promise_text'] = df_final[COLUMN_MAP['desc']].str[:200] + "..."  # 200ìë¡œ ì œí•œ
    df_export['keywords'] = df_final[COLUMN_MAP['keys']]
    df_export['vagueness'] = df_final['vagueness'].round(3)
    df_export['series_a_date'] = df_final['series_a_date']
    df_export['outcome_type'] = df_final['outcome_type']
    df_export['outcome_date'] = df_final['outcome_date']
    df_export['months_to_outcome'] = df_final['months_to_outcome'].round(1)
    df_export['l_code'] = df_final['l_code']

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*80)
    print("SELECTED COMPANIES")
    print("="*80)
    for idx, row in df_export.iterrows():
        print(f"\n{idx+1}. {row['company_name']}")
        print(f"   Domain: {row['domain']}")
        print(f"   Vagueness: {row['vagueness']:.3f}")
        print(f"   Series A: {row['series_a_date'].strftime('%Y-%m-%d')}")
        print(f"   Outcome: {row['outcome_type']} (L={row['l_code']})")
        if pd.notna(row['outcome_date']):
            print(f"   Outcome Date: {row['outcome_date'].strftime('%Y-%m-%d')} ({row['months_to_outcome']:.1f} months)")

    # ì €ì¥
    if output_path:
        df_export.to_csv(output_path, index=False)
        print(f"\nâœ… Saved to: {output_path}")

    return df_export


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(
        description="Find 4 representative companies for presentation"
    )
    parser.add_argument(
        '--input',
        type=str,
        default='data/raw/Company20211201.dat',
        help='Input PitchBook data file'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='outputs/presentation_examples.csv',
        help='Output CSV file'
    )

    args = parser.parse_args()

    # ë°ì´í„° ë¡œë“œ
    print(f"\nğŸ“‚ Loading data from: {args.input}")
    try:
        df = pd.read_csv(args.input, sep='|', encoding='utf-8', low_memory=False)
    except UnicodeDecodeError:
        df = pd.read_csv(args.input, sep='|', encoding='latin-1', low_memory=False)

    print(f"âœ“ Loaded {len(df):,} rows, {len(df.columns)} columns")

    # 4ê°œì‚¬ ì°¾ê¸°
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    df_examples = find_presentation_cohort(df, output_path)

    if len(df_examples) < 4:
        print(f"\nâš ï¸  WARNING: Only found {len(df_examples)} companies (target: 4)")
        print("Consider:")
        print("  - Relaxing Series A year constraint")
        print("  - Expanding domain definitions")
        print("  - Using different L-code distribution")

    print("\nâœ… Done!")
    return df_examples


if __name__ == "__main__":
    main()

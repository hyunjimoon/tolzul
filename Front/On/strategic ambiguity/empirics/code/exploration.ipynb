{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategic Ambiguity Data Exploration with xarray\n",
    "\n",
    "This notebook provides a complete tutorial on exploring your strategic ambiguity empirics data using xarray.\n",
    "\n",
    "## What is xarray?\n",
    "\n",
    "xarray is a powerful library for working with labeled multi-dimensional arrays. It brings the power of pandas to multi-dimensional data.\n",
    "\n",
    "**Key concepts:**\n",
    "- **Dataset**: Container for multiple DataArrays with shared dimensions\n",
    "- **DataArray**: Single variable with labeled dimensions and coordinates\n",
    "- **Dimensions**: Names for axes (e.g., 'company', 'deal', 'observation')\n",
    "- **Coordinates**: Labels along dimensions (e.g., company IDs)\n",
    "- **Attributes**: Metadata about the dataset\n",
    "\n",
    "**Why use xarray for this project?**\n",
    "- Store all data (company, deals, panel) in one file\n",
    "- Track provenance with git metadata in attributes\n",
    "- Query data efficiently with labeled indexing\n",
    "- Convert to pandas DataFrame when needed\n",
    "- Reproducible: checkpoint file includes all processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Add code directory to path to import pipeline\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "print(\"âœ… Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Data\n",
    "\n",
    "After running the pipeline, data is saved as a pickle file. Let's load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint file\n",
    "checkpoint_file = Path('../output/pipeline_checkpoint.pkl')\n",
    "\n",
    "if checkpoint_file.exists():\n",
    "    with open(checkpoint_file, 'rb') as f:\n",
    "        ds = pickle.load(f)\n",
    "    print(f\"âœ… Loaded dataset from {checkpoint_file}\")\n",
    "    print(f\"\\nDataset overview:\")\n",
    "    print(ds)\n",
    "else:\n",
    "    print(f\"âŒ Checkpoint file not found at {checkpoint_file}\")\n",
    "    print(\"ðŸ’¡ Run the pipeline first: python pipeline_xarray.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Dimensions\n",
    "\n",
    "Dimensions are the axes of your data. Think of them as the rows in a pandas DataFrame index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View dimensions\n",
    "print(\"ðŸ“Š Dimensions:\")\n",
    "print(ds.dims)\n",
    "print()\n",
    "\n",
    "if 'company' in ds.dims:\n",
    "    print(f\"   company: {ds.dims['company']} AI/ML firms\")\n",
    "if 'deal' in ds.dims:\n",
    "    print(f\"   deal: {ds.dims['deal']} Series A/B deals\")\n",
    "if 'observation' in ds.dims:\n",
    "    print(f\"   observation: {ds.dims['observation']} panel observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring Coordinates\n",
    "\n",
    "Coordinates are the labels along each dimension. They allow you to select data by meaningful labels instead of integer indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View coordinates\n",
    "print(\"ðŸ·ï¸ Coordinates:\")\n",
    "print()\n",
    "\n",
    "if 'company' in ds.coords:\n",
    "    company_ids = ds.coords['company'].values\n",
    "    print(f\"Company IDs (first 5): {company_ids[:5]}\")\n",
    "    print()\n",
    "\n",
    "if 'deal' in ds.coords:\n",
    "    deal_ids = ds.coords['deal'].values\n",
    "    print(f\"Deal IDs (first 5): {deal_ids[:5]}\")\n",
    "    print()\n",
    "\n",
    "if 'observation' in ds.coords:\n",
    "    obs_ids = ds.coords['observation'].values\n",
    "    print(f\"Observation IDs (first 5): {obs_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Variables\n",
    "\n",
    "Data variables are the actual measurements stored in the dataset. Our pipeline stores:\n",
    "- `company_*`: Company-level variables (vagueness, integration cost, etc.)\n",
    "- `deal_*`: Deal-level variables (deal size, funding success, etc.)\n",
    "- `panel_*`: Analysis panel (merged company + deal data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all data variables\n",
    "print(\"ðŸ“ˆ Data Variables:\")\n",
    "print()\n",
    "\n",
    "company_vars = [v for v in ds.data_vars if v.startswith('company_')]\n",
    "print(f\"Company variables ({len(company_vars)}):\")\n",
    "for v in company_vars[:10]:  # Show first 10\n",
    "    print(f\"   - {v}\")\n",
    "if len(company_vars) > 10:\n",
    "    print(f\"   ... and {len(company_vars) - 10} more\")\n",
    "print()\n",
    "\n",
    "deal_vars = [v for v in ds.data_vars if v.startswith('deal_')]\n",
    "print(f\"Deal variables ({len(deal_vars)}):\")\n",
    "for v in deal_vars[:10]:\n",
    "    print(f\"   - {v}\")\n",
    "if len(deal_vars) > 10:\n",
    "    print(f\"   ... and {len(deal_vars) - 10} more\")\n",
    "print()\n",
    "\n",
    "panel_vars = [v for v in ds.data_vars if v.startswith('panel_')]\n",
    "print(f\"Panel variables ({len(panel_vars)}):\")\n",
    "for v in panel_vars[:10]:\n",
    "    print(f\"   - {v}\")\n",
    "if len(panel_vars) > 10:\n",
    "    print(f\"   ... and {len(panel_vars) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Accessing Data\n",
    "\n",
    "There are several ways to access data in xarray:\n",
    "- **Direct access**: `ds.variable_name` or `ds['variable_name']`\n",
    "- **Selection**: `ds.variable_name.sel(dimension=value)`\n",
    "- **Filtering**: `ds.where(condition, drop=True)`\n",
    "- **To pandas**: `ds.to_dataframe()` or `ds.variable_name.to_pandas()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Direct access to a variable\n",
    "if 'company_vagueness' in ds:\n",
    "    vagueness = ds.company_vagueness\n",
    "    print(\"Example 1: Company Vagueness Scores\")\n",
    "    print(f\"   Type: {type(vagueness)}\")\n",
    "    print(f\"   Shape: {vagueness.shape}\")\n",
    "    print(f\"   Mean: {vagueness.values.mean():.2f}\")\n",
    "    print(f\"   Std: {vagueness.values.std():.2f}\")\n",
    "    print()\n",
    "\n",
    "# Example 2: Access specific company\n",
    "if 'company' in ds.coords:\n",
    "    first_company_id = ds.coords['company'].values[0]\n",
    "    print(f\"Example 2: First Company (ID: {first_company_id})\")\n",
    "    if 'company_company_name' in ds:\n",
    "        print(f\"   Name: {ds.company_company_name.sel(company=first_company_id).values}\")\n",
    "    if 'company_vagueness' in ds:\n",
    "        print(f\"   Vagueness: {ds.company_vagueness.sel(company=first_company_id).values:.1f}\")\n",
    "    if 'company_high_integration_cost' in ds:\n",
    "        cost = ds.company_high_integration_cost.sel(company=first_company_id).values\n",
    "        print(f\"   Integration Cost: {'High' if cost == 1 else 'Low'}\")\n",
    "    print()\n",
    "\n",
    "# Example 3: Filter companies with high vagueness\n",
    "if 'company_vagueness' in ds:\n",
    "    high_vague = ds.where(ds.company_vagueness > 60, drop=True)\n",
    "    print(f\"Example 3: High Vagueness Companies (>60)\")\n",
    "    print(f\"   Count: {high_vague.dims.get('company', 0)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Attributes (Metadata)\n",
    "\n",
    "Attributes store metadata about the dataset, including:\n",
    "- Git commit information for reproducibility\n",
    "- Pipeline execution timestamps\n",
    "- Data summary statistics\n",
    "- Date filtering ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View important attributes\n",
    "print(\"ðŸ“ Dataset Metadata:\")\n",
    "print()\n",
    "\n",
    "important_attrs = [\n",
    "    'pipeline_version',\n",
    "    'created_at',\n",
    "    'last_updated',\n",
    "    'last_completed_step',\n",
    "    'git_commit_url',\n",
    "    'git_branch',\n",
    "    'series_a_date_range',\n",
    "    'series_b_date_range',\n",
    "    'n_companies',\n",
    "    'n_deals',\n",
    "    'n_observations'\n",
    "]\n",
    "\n",
    "for attr in important_attrs:\n",
    "    if attr in ds.attrs:\n",
    "        value = ds.attrs[attr]\n",
    "        print(f\"   {attr}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Converting to pandas DataFrame\n",
    "\n",
    "For analysis tasks, you might want to work with familiar pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert panel data to DataFrame\n",
    "if any(v.startswith('panel_') for v in ds.data_vars):\n",
    "    panel_cols = [v.replace('panel_', '') for v in ds.data_vars if v.startswith('panel_')]\n",
    "    panel_data = {col: ds[f'panel_{col}'].values for col in panel_cols}\n",
    "    panel_df = pd.DataFrame(panel_data)\n",
    "    \n",
    "    print(\"ðŸ“Š Panel DataFrame:\")\n",
    "    print(f\"   Shape: {panel_df.shape}\")\n",
    "    print()\n",
    "    print(\"First 5 rows:\")\n",
    "    display(panel_df.head())\n",
    "else:\n",
    "    print(\"No panel data found. Run the pipeline first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Query Patterns\n",
    "\n",
    "Common query patterns for analysis:\n",
    "- `ds.where()`: Filter based on conditions\n",
    "- `ds.sel()`: Select specific coordinates\n",
    "- `ds.isel()`: Select by integer index\n",
    "- Arithmetic operations work element-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Pattern 1: Filter panel by round\n",
    "if 'panel_round' in ds:\n",
    "    # Get Series A observations\n",
    "    series_a_mask = ds.panel_round.values == 'Series A'\n",
    "    print(f\"Query 1: Series A observations\")\n",
    "    print(f\"   Count: {series_a_mask.sum()}\")\n",
    "    \n",
    "    if 'panel_funding_success' in ds:\n",
    "        series_a_success = ds.panel_funding_success.values[series_a_mask]\n",
    "        print(f\"   Success rate: {series_a_success.mean():.1%}\")\n",
    "    print()\n",
    "\n",
    "# Query Pattern 2: Compare success rates by round\n",
    "if 'panel_round' in ds and 'panel_funding_success' in ds:\n",
    "    rounds = ds.panel_round.values\n",
    "    success = ds.panel_funding_success.values\n",
    "    \n",
    "    print(\"Query 2: Success rates by round\")\n",
    "    for round_name in ['Series A', 'Series B']:\n",
    "        mask = rounds == round_name\n",
    "        if mask.sum() > 0:\n",
    "            rate = success[mask].mean()\n",
    "            print(f\"   {round_name}: {rate:.1%} ({mask.sum()} observations)\")\n",
    "    print()\n",
    "\n",
    "# Query Pattern 3: Vagueness by integration cost\n",
    "if 'panel_vagueness' in ds and 'panel_high_integration_cost' in ds:\n",
    "    vagueness = ds.panel_vagueness.values\n",
    "    high_i = ds.panel_high_integration_cost.values\n",
    "    \n",
    "    print(\"Query 3: Average vagueness by integration cost\")\n",
    "    print(f\"   High integration cost: {vagueness[high_i == 1].mean():.1f}\")\n",
    "    print(f\"   Low integration cost: {vagueness[high_i == 0].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analysis Workflow Example\n",
    "\n",
    "Let's analyze the key hypothesis: Does vagueness have opposite effects on Series A vs B funding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(v in ds for v in ['panel_vagueness', 'panel_round', 'panel_funding_success']):\n",
    "    # Create analysis DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'vagueness': ds.panel_vagueness.values,\n",
    "        'round': ds.panel_round.values,\n",
    "        'success': ds.panel_funding_success.values\n",
    "    })\n",
    "    \n",
    "    # Create vagueness categories\n",
    "    df['vagueness_category'] = pd.cut(\n",
    "        df['vagueness'],\n",
    "        bins=[0, 50, 100],\n",
    "        labels=['Precise', 'Vague']\n",
    "    )\n",
    "    \n",
    "    # Calculate success rates\n",
    "    success_rates = df.groupby(['vagueness_category', 'round'])['success'].agg(['mean', 'count'])\n",
    "    success_rates.columns = ['Success Rate', 'N']\n",
    "    \n",
    "    print(\"ðŸŽ¯ Hypothesis Test: Vagueness Reversal Pattern\")\n",
    "    print()\n",
    "    print(success_rates)\n",
    "    print()\n",
    "    \n",
    "    # Visualize\n",
    "    success_pivot = success_rates['Success Rate'].unstack()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    x = np.arange(len(success_pivot.index))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, success_pivot['Series A'], width, \n",
    "           label='Series A', color='steelblue', alpha=0.8)\n",
    "    ax.bar(x + width/2, success_pivot['Series B'], width, \n",
    "           label='Series B', color='coral', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Promise Type', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Funding Success Rate', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Strategic Ambiguity: Reversal Pattern', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(success_pivot.index)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, cat in enumerate(success_pivot.index):\n",
    "        for j, round_name in enumerate(['Series A', 'Series B']):\n",
    "            value = success_pivot.loc[cat, round_name]\n",
    "            x_pos = i + (j - 0.5) * width\n",
    "            ax.text(x_pos, value, f'{value:.1%}', \n",
    "                   ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"\\nðŸ“ˆ Interpretation:\")\n",
    "    if len(success_pivot.index) >= 2:\n",
    "        precise_a = success_pivot.loc['Precise', 'Series A']\n",
    "        vague_a = success_pivot.loc['Vague', 'Series A']\n",
    "        precise_b = success_pivot.loc['Precise', 'Series B']\n",
    "        vague_b = success_pivot.loc['Vague', 'Series B']\n",
    "        \n",
    "        if precise_a > vague_a and vague_b > precise_b:\n",
    "            print(\"   âœ… REVERSAL PATTERN CONFIRMED!\")\n",
    "            print(f\"   - Series A: Precise ({precise_a:.1%}) > Vague ({vague_a:.1%})\")\n",
    "            print(f\"   - Series B: Vague ({vague_b:.1%}) > Precise ({precise_b:.1%})\")\n",
    "        else:\n",
    "            print(\"   Pattern not as expected. Further investigation needed.\")\n",
    "else:\n",
    "    print(\"Panel data not available. Run the pipeline first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Advanced: Three-Way Interaction\n",
    "\n",
    "Explore how the reversal pattern varies by integration cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_vars = ['panel_vagueness', 'panel_round', 'panel_funding_success', 'panel_high_integration_cost']\n",
    "\n",
    "if all(v in ds for v in required_vars):\n",
    "    # Create analysis DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'vagueness': ds.panel_vagueness.values,\n",
    "        'round': ds.panel_round.values,\n",
    "        'success': ds.panel_funding_success.values,\n",
    "        'high_i': ds.panel_high_integration_cost.values\n",
    "    })\n",
    "    \n",
    "    df['vagueness_category'] = pd.cut(df['vagueness'], bins=[0, 50, 100], labels=['Precise', 'Vague'])\n",
    "    df['integration_cost'] = df['high_i'].map({0: 'Low-i (API/SaaS)', 1: 'High-i (Hardware)'})\n",
    "    \n",
    "    # Calculate success rates\n",
    "    success_3way = df.groupby(['integration_cost', 'vagueness_category', 'round'])['success'].mean()\n",
    "    \n",
    "    print(\"ðŸŽ¯ Three-Way Interaction: Vagueness Ã— Round Ã— Integration Cost\")\n",
    "    print()\n",
    "    print(success_3way.unstack())\n",
    "    print()\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    \n",
    "    colors = {\n",
    "        ('High-i (Hardware)', 'Precise'): '#d62728',\n",
    "        ('High-i (Hardware)', 'Vague'): '#ff7f0e',\n",
    "        ('Low-i (API/SaaS)', 'Precise'): '#1f77b4',\n",
    "        ('Low-i (API/SaaS)', 'Vague'): '#2ca02c'\n",
    "    }\n",
    "    \n",
    "    for int_cost in df['integration_cost'].unique():\n",
    "        for vague in ['Precise', 'Vague']:\n",
    "            subset = df[(df['integration_cost'] == int_cost) & (df['vagueness_category'] == vague)]\n",
    "            \n",
    "            if len(subset) > 0:\n",
    "                rates = subset.groupby('round')['success'].mean()\n",
    "                \n",
    "                x_vals = [0 if r == 'Series A' else 1 for r in rates.index]\n",
    "                y_vals = rates.values\n",
    "                \n",
    "                label = f\"{int_cost}, {vague}\"\n",
    "                color = colors.get((int_cost, vague), 'gray')\n",
    "                marker = 'o' if vague == 'Precise' else 's'\n",
    "                linestyle = '-' if vague == 'Precise' else '--'\n",
    "                \n",
    "                ax.plot(x_vals, y_vals, marker=marker, linewidth=2.5, markersize=10,\n",
    "                       label=label, color=color, linestyle=linestyle, alpha=0.85)\n",
    "    \n",
    "    ax.set_xlabel('Funding Round', fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Funding Success Rate', fontsize=13, fontweight='bold')\n",
    "    ax.set_title('Three-Way Interaction: Vagueness Ã— Round Ã— Integration Cost', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Series A', 'Series B'])\n",
    "    ax.legend(fontsize=10, loc='best')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_ylim(0, 1.15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Required variables not found. Run the pipeline first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Saving Your Work\n",
    "\n",
    "Export to various formats for further analysis or sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export panel data to CSV\n",
    "if any(v.startswith('panel_') for v in ds.data_vars):\n",
    "    panel_cols = [v.replace('panel_', '') for v in ds.data_vars if v.startswith('panel_')]\n",
    "    panel_data = {col: ds[f'panel_{col}'].values for col in panel_cols}\n",
    "    panel_df = pd.DataFrame(panel_data)\n",
    "    \n",
    "    output_file = '../output/panel_export.csv'\n",
    "    panel_df.to_csv(output_file, index=False)\n",
    "    print(f\"âœ… Exported panel data to {output_file}\")\n",
    "    print(f\"   Shape: {panel_df.shape}\")\n",
    "    print(f\"   Size: {Path(output_file).stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "### Key xarray Concepts Learned\n",
    "\n",
    "1. **Dataset**: Container holding multiple related DataArrays\n",
    "2. **Dimensions**: Named axes (company, deal, observation)\n",
    "3. **Coordinates**: Labels along dimensions (company IDs, deal IDs)\n",
    "4. **Data Variables**: Actual measurements (vagueness, funding_success, etc.)\n",
    "5. **Attributes**: Metadata (git info, timestamps, data summaries)\n",
    "\n",
    "### Common Operations\n",
    "\n",
    "```python\n",
    "# Access variable\n",
    "ds.company_vagueness\n",
    "\n",
    "# Select by coordinate\n",
    "ds.company_vagueness.sel(company='500001-01')\n",
    "\n",
    "# Filter by condition\n",
    "ds.where(ds.company_vagueness > 60, drop=True)\n",
    "\n",
    "# Convert to pandas\n",
    "ds.to_dataframe()\n",
    "\n",
    "# Access values as numpy array\n",
    "ds.company_vagueness.values\n",
    "```\n",
    "\n",
    "### Pipeline Workflow\n",
    "\n",
    "1. **Process company data** â†’ `company_*` variables\n",
    "2. **Process deal data** â†’ `deal_*` variables  \n",
    "3. **Create panel** â†’ `panel_*` variables (merged)\n",
    "4. **Run analysis** â†’ regression results\n",
    "5. **Create deliverables** â†’ tables and figures\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore additional visualizations\n",
    "- Run robustness checks\n",
    "- Export results for paper\n",
    "- Share checkpoint file for reproducibility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

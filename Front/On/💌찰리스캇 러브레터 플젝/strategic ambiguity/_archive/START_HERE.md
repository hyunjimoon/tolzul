# Promise Precision and Venture Funding - START HERE

## ğŸš€ New User? Check These First

1. **[[ì‘ì „ìƒí™©íŒ.md]]** - One-page dashboard (í˜„ì¬ ìƒíƒœ ë¹ ë¥¸ í™•ì¸)
2. **[[ì „íˆ¬ì¼ì§€ğŸ©¸]]** - Detailed battle log (ì „ì²´ ì§„í–‰ ê¸°ë¡)
3. **This file** - Quick start guide (ì½”ë“œ ì‹¤í–‰ ë°©ë²•)
4. **[[workflow(hypothesis, data, model)ğŸ—ºï¸]]** - Research design (ê°€ì„¤, ë°ì´í„°, ëª¨ë¸)

---

## What We're Doing
Analyze how **vagueness in promises** affects VC funding success using real Pitchbook data.

**Research Question**: When should entrepreneurs be vague vs. precise?

**Answer**: Vague at Series A (preserve flexibility), Precise at Series B (signal readiness) - BUT only in hardware (high integration cost).

---

## Quick Start

### Step 1: Ask Claude Code to Write Scripts

**Two Options:**

**Option A: Claude Code** (uses sample data on GitHub)
```
I have sample Pitchbook data:
- empirics/data/raw/Company2021.dat (30 firms)
- empirics/data/raw/Deal2023.dat (deals for those firms)

Write 01_process_company_data.py that:
- Reads Company2021.dat (pipe-delimited, ~30 rows)
- Filters to AI/ML firms (keywords: 'AI', 'ML', 'artificial intelligence', 'machine learning')
- Scores vagueness using keyword counts:
  * Vague: approximately, around, roughly, flexible, scalable, adaptive
  * Precise: exactly, precisely, guaranteed, specific, certified
  * Formula: 50 + 10*(vague_count - precise_count), capped [0,100]
- Classifies integration cost from Keywords field:
  * High-i (1): chip, asic, robotics, distributed, gpu, hardware
  * Low-i (0): api, saas, software, wrapper, platform, cloud
- Outputs: data/processed/company_master.csv

Print first 5 rows and summary stats for validation.
```

**Option B: Local Execution** (uses full data)
- Same prompt but change path to your local Dropbox location
- Use `Company*.dat` (all 5 files) instead of just Company2021.dat

### Step 2: Run It
**If using Claude Code**: It runs automatically  
**If local**: 
```bash
cd "/Users/hyunjimoon/MIT Dropbox/Angie.H Moon/tolzul/Front/On/strategic ambiguity/empirics"
python code/01_process_company_data.py
```

### Step 3: Check Output
Look for: `data/processed/company_master.csv`

Expected: 
- Sample data: ~10-15 AI/ML firms from 30 rows
- Full data: ~60-80 AI/ML firms from all files

### Step 4: Repeat for Scripts 2-5

---

## The 5 Scripts (in order)

| Script | Input | Output | What It Does |
|--------|-------|--------|--------------|
| **01_process_company_data.py** | Company*.dat | company_master.csv | Extract firms, score vagueness |
| **02_process_deal_data.py** | Deal*.dat | deal_panel.csv | Identify Series A/B deals |
| **03_create_panel.py** | company + deal | analysis_panel.csv | Join into panel (each firm Ã— 2) |
| **04_run_analysis.py** | analysis_panel.csv | regression tables | Test hypotheses |
| **05_create_deliverables.py** | analysis_panel.csv | 4 tables + 4 figures | Generate paper outputs |

---

## Key Details

### Vagueness Score (0-100)
**Vague keywords**: approximately, around, roughly, flexible, scalable, adaptive  
**Precise keywords**: exactly, precisely, guaranteed, specific, certified  
Formula: `50 + 10*(vague_count - precise_count)` capped at [0,100]

### Integration Cost (binary)
**High-i (1)**: chip, asic, robotics, distributed, gpu, hardware, semiconductor  
**Low-i (0)**: api, saas, software, wrapper, platform, cloud

### Series A/B Identification (4-step heuristic)
1. Filter: Only "Early Stage VC" or "Later Stage VC" deals
2. Sequence: First = Series A, Second = Series B
3. Size: A = $2-15M, B = $10M+
4. Date: A = 2021-2022, B = 2023-2025

---

## Expected Results

### Success Rates
|  | Low-i (Software) | High-i (Hardware) |
|--|------------------|-------------------|
| **Precise at A** | 65% | 75% |
| **Precise at B** | 70% (+5pp) | 28% (-47pp) â¬‡ï¸ |
| **Vague at A** | 55% | 52% |
| **Vague at B** | 60% (+5pp) | 63% (+11pp) â¬†ï¸ |

**Key finding**: In hardware, vague promises flip from disadvantage to advantage. Software shows minimal change.

### Regressions
- **Model 1**: Î²â‚ < 0 (vague hurts at A), Î²â‚ƒ > 0 (reverses at B)
- **Model 2**: Î²â‚‡ > 0 (reversal 3Ã— stronger in hardware)

---

## Troubleshooting

**Problem**: "File not found"  
**Fix**: Update file paths to match your structure

**Problem**: "Module not found"  
**Fix**: `pip install pandas numpy statsmodels matplotlib seaborn`

**Problem**: Too few firms (<10)  
**Fix**: Expand AI/ML keywords or use full dataset

**Problem**: No Series B matches  
**Fix**: Relax date filter or use full Deal dataset

---

## File Structure
```
/empirics/
â”œâ”€â”€ START_HERE.md                  â† You are here
â”œâ”€â”€ workflow(hypothesis, data, model).md    â† Reference only
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ 01_process_company_data.py
â”‚   â”œâ”€â”€ 02_process_deal_data.py
â”‚   â”œâ”€â”€ 03_create_panel.py
â”‚   â”œâ”€â”€ 04_run_analysis.py
â”‚   â””â”€â”€ 05_create_deliverables.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ Company2021.dat        â† Sample (30 rows)
â”‚   â”‚   â”œâ”€â”€ Deal2023.dat           â† Sample (30 rows)
â”‚   â”‚   â”œâ”€â”€ Company*.dat           â† Full data (5 files)
â”‚   â”‚   â””â”€â”€ Deal*.dat              â† Full data (2 files)
â”‚   â””â”€â”€ processed/                 â† Generated by scripts 1-3
â””â”€â”€ output/                        â† Generated by scripts 4-5
```

---

## That's It!

**Don't overthink it.** Just copy the prompt above, get code from Claude Code (or run locally), iterate through all 5 scripts.

For conceptual details, see: `workflow(hypothesis, data, model).md`

---

Last Updated: 2025-10-22

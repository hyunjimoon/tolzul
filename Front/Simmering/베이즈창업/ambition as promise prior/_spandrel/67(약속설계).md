
# 6. 참고문헌

 Agrawal, A., Gans, J., & Goldfarb, A. (2024). The economics of artificial intelligence: An agenda. University of Chicago Press.

Alvarez, S. A., & Barney, J. B. (2007). Discovery and creation: Alternative theories of entrepreneurial action. Strategic Entrepreneurship Journal, 1(1‐2), 11-26.

Benabou, R., & Tirole, J. (2016). Mindful economics: The production, consumption, and value of beliefs. Journal of Economic Perspectives, 30(3), 141-164.

Box, G. E. (1980). Sampling and Bayes' inference in scientific modelling and robustness. Journal of the Royal Statistical Society, 143(4), 383-430.

Boyd, S., & Vandenberghe, L. (2004). Convex optimization. Cambridge University Press.

Camuffo, A., Cordova, A., Gambardella, A., & Spina, C. (2020). A scientific approach to entrepreneurial decision making. Management Science, 66(2), 564-586.

Cyert, R. M., & March, J. G. (1963). A behavioral theory of the firm. Prentice-Hall.

Fine, C., Padurean, L., & Naumov, S. (2022). Entrepreneurial operations: A review and agenda. Manufacturing & Service Operations Management, 24(5), 2365-2381.

Garud, R., Gehman, J., & Giuliani, A. P. (2014). Contextualizing entrepreneurial innovation. Research Policy, 43(7), 1177-1191.

Gelman, A., & Shalizi, C. R. (2013). Philosophy and the practice of Bayesian statistics. British Journal of Mathematical and Statistical Psychology, 66(1), 8-38.

Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2008). Bayesian data analysis. Chapman and Hall/CRC.

Ho, S. (2022). Multi-agent coordination through shared beliefs. Journal of Economic Theory, 199, 105-134.

Jaynes, E. T. (2003). Probability theory: The logic of science. Cambridge University Press.

Kahneman, D., & Tversky, A. (1979). Prospect theory: An analysis of decision under risk. Econometrica, 47(2), 263-291.

Kleiman-Weiner, M., Ho, M. K., Austerweil, J. L., Littman, M. L., & Tenenbaum, J. B. (2016). Coordinate to cooperate or compete. Topics in Cognitive Science, 8(2), 413-428.

Knight, F. H. (1921). Risk, uncertainty and profit. Houghton Mifflin.

MacKay, D. J. (1992). Bayesian interpolation. Neural Computation, 4(3), 415-447.

Nanda, R. (2024). Entrepreneurial experimentation. Annual Review of Financial Economics, 16, 223-244.

Sarasvathy, S. D. (2001). Causation and effectuation. Academy of Management Review, 26(2), 243-263.

Savage, L. J. (1954). The foundations of statistics. John Wiley & Sons.

Schumpeter, J. A. (1934). The theory of economic development. Harvard University Press.

Sculley, D., Holt, G., Golovin, D., Davydov, E., Phillips, T., Ebner, D., ... & Dennison, D. (2015). Hidden technical debt in machine learning systems. _Advances in neural information processing systems_, _28_.

Shannon, C. E. (1948). A mathematical theory of communication. Bell System Technical Journal, 27(3), 379-423.

Taylor, F. W. (1911). The principles of scientific management. Harper & Brothers.

Teece, D. J., Pisano, G., & Shuen, A. (1997). Dynamic capabilities and strategic management. Strategic Management Journal, 18(7), 509-533.

Tenenbaum, J. B., Kemp, C., Griffiths, T. L., & Goodman, N. D. (2011). How to grow a mind. Science, 331(6022), 1279-1285.

Terwiesch, C., & Ulrich, K. (2009). Innovation tournaments. Harvard Business Press.

Weick, K. E. (1995). Sensemaking in organizations. Sage Publications.

Zellweger, T., & Zenger, T. (2023). Entrepreneurs as scientists: A pragmatist approach to producing value out of uncertainty. _Academy of Management Review_, _48_(3), 379-408.

# 7. 부록: 명제증명
### **명제 1**

 V_sd>> V_snd, V_ns이고 n=1일 때, 최적 약속 수준은 φ* = (V_sd - V_ns)/2(V_sd - V_snd)이다. 재무적 인센티브만으로는 최대 약속을 향해 나아가지만, 운영적 제약은 내부 최적을 만든다.

**증명:**

1. **기대 효용 함수(Expected Utility Function) 정의:**  
    기업가의 기대 효용 `E[U(φ)]`는 세 가지 상호 배타적인 결과의 가중 평균으로 정의됩니다.
    
    - **판매 및 이행 (Sell & Deliver):** 가치 `V_sd`, 확률 `p(φ)d(φ)`
    - **판매 후 미이행 (Sell & Not Deliver):** 가치 `V_snd`, 확률 `p(φ)(1-d(φ))`
    - **미판매 (Not Sell):** 가치 `V_ns`, 확률 `1-p(φ)`
    
    따라서 기대 효용 함수는 다음과 같습니다.  
    `E[U(φ)] = p(φ)d(φ)V_sd + p(φ)(1-d(φ))V_snd + (1-p(φ))V_ns`
    
2. **모수(Parameter) 설정:**  
    명제의 조건에 따라 다음을 가정하고 적용합니다.
    
    - 약속 수준 `φ`가 판매 확률과 같다고 가정: `p(φ) = φ`. 이는 약속을 높게 할수록 시장의 반응(판매)이 선형적으로 증가함을 의미하는 가장 기본적인 가정입니다.
    - 운영 복잡성 `n=1`이므로, 이행 확률은 `d(φ) = (1-φ)^1 = 1-φ` 입니다.
3. **기대 효용 함수 전개:**  
    위 가정을 대입하여 함수를 `φ`에 대해 정리합니다.  
    `E[U(φ)] = φ(1-φ)V_sd + φ(1-(1-φ))V_snd + (1-φ)V_ns`  
    `E[U(φ)] = (φ-φ²)V_sd + φ²V_snd + V_ns - φV_ns`
    
4. **최적화 (1계 조건):**  
    기대 효용을 최대화하는 최적 약속 수준 `φ*`를 찾기 위해, 함수를 `φ`에 대해 미분하고 그 값을 0으로 설정합니다 (1계 조건, First-Order Condition).  
    `d/dφ [E[U(φ)]] = (1-2φ)V_sd + 2φV_snd - V_ns = 0`
    
5. **`φ`에 대한 정리:**  
    위 식을 `φ`에 대해 정리합니다.  
    `V_sd - V_ns = 2φV_sd - 2φV_snd`  
    `V_sd - V_ns = 2φ(V_sd - V_snd)`  
    `φ* = (V_sd - V_ns) / (2(V_sd - V_snd))`

    

### **명제 2

V_ns = V_snd = 0일 때, 최적 약속 수준은 φ* = 1/(n+1)이다. 운영 복잡성 n이 최적 약속 수준을 결정한다--더 높은 복잡성은 더 보수적인 약속으로 이어진다.

**증명:**

1. **기대 효용 함수(Expected Utility Function) 정의:**  
    명제의 조건 `V_ns = V_snd = 0`을 일반 기대 효용 함수에 적용합니다. 이는 판매에 실패하거나 이행에 실패할 경우의 가치가 0임을 의미합니다. 이 경우 효용은 '판매 및 이행'의 경우에만 발생합니다.  
    `E[U(φ)] = p(φ)d(φ)V_sd + p(φ)(1-d(φ))*0 + (1-p(φ))*0`  
    `E[U(φ)] = p(φ)d(φ)V_sd`
    
2. **모수(Parameter) 설정:**  
    다시 `p(φ) = φ`로 가정하고, 일반적인 이행 확률 `d(φ) = (1-φ)^n`을 적용합니다. `V_sd`는 양의 상수입니다.  
    `E[U(φ)] = φ(1-φ)^n V_sd`
    
3. **최적화 문제로의 변환:**  
    `V_sd`는 `φ`와 무관한 상수이므로, 위 함수를 최대화하는 것은 `f(φ) = φ(1-φ)^n`을 최대화하는 것과 같습니다.
    
4. **최적화 (1계 조건):**  
    `f(φ)`를 `φ`에 대해 미분하여 0으로 설정합니다. 곱의 미분법을 사용합니다.  
    `f'(φ) = d/dφ [φ(1-φ)^n]`  
    `f'(φ) = 1 * (1-φ)^n + φ * [n(1-φ)^(n-1) * (-1)]`  
    `f'(φ) = (1-φ)^n - nφ(1-φ)^(n-1)`
    
    공통 인수 `(1-φ)^(n-1)`로 묶어 정리합니다.  
    `f'(φ) = (1-φ)^(n-1) * [(1-φ) - nφ]`  
    `f'(φ) = (1-φ)^(n-1) * [1 - (n+1)φ]`
    
5. **`φ*` 도출:**  
    `f'(φ) = 0`이 되는 `φ`를 찾습니다. `0 < φ < 1` 범위에서 `(1-φ)^(n-1)`는 0이 아니므로, `[1 - (n+1)φ]` 항이 0이 되어야 합니다.  
    `1 - (n+1)φ = 0`  
    `φ* = 1 / (n+1)`
    
    이는 운영 복잡성 `n`이 증가할수록 최적 약속 수준 `φ*`이 감소함을 명확히 보여줍니다.
    

### **명제 3 (학습 함정)**

μ(1-μ) < ε(τ+1)일 때 학습 함정이 발생한다. 높은 정밀성은 신념 수정을 방지하여 증거와 관계없이 구조적 경직성을 만든다.

**증명:**

1. **신념의 확률적 정의:**  
    기업가의 신념(belief)은 약속 이행 수준 `φ`에 대한 확률 분포로 모델링됩니다. 이때 Beta 분포 `φ ~ Beta(α, β)`를 사용하며, 모수 `μ`(포부, 평균)와 `τ`(정밀성)를 통해 `α = μτ`, `β = (1-μ)τ` 로 표현됩니다.
    
2. **학습 능력의 정의:**  
    학습 능력, 즉 새로운 증거에 반응하여 신념을 수정할 수 있는 능력은 신념 분포의 분산(variance)에 직접적으로 관련됩니다. 분산이 크다는 것은 불확실성이 높고 새로운 정보를 받아들일 여지가 많다는 의미입니다. 반대로 분산이 작다는 것은 신념이 확고하여 잘 변하지 않음을 의미합니다.
    
3. **학습 함정의 수학적 정의:**  
    '학습 함정'은 신념 분포의 분산이 특정 임계값 `ε` 이하로 떨어져, 사실상 신념의 수정이 불가능해지는 구조적 경직성 상태로 정의할 수 있습니다.  
    `Var(φ) < ε`
    
4. **Beta 분포 분산 공식 적용:**  
    `Beta(μτ, (1-μ)τ)` 분포의 분산 공식은 다음과 같습니다.  
    `Var(φ) = αβ / [(α+β)²(α+β+1)] = (μτ)(1-μ)τ / [(τ)²(τ+1)] = μ(1-μ) / (τ+1)`
    
5. **명제 도출:**  
    학습 함정의 정의 `Var(φ) < ε`에 분산 공식을 대입합니다.  
    `μ(1-μ) / (τ+1) < ε`
    
    양변에 `(τ+1)`을 곱하여 정리하면 명제의 조건이 직접적으로 유도됩니다.  
    `μ(1-μ) < ε(τ+1)`
    
    이는 포부 `μ`가 극단(0 또는 1)에 가깝거나 정밀성 `τ`가 매우 높을 때, 좌변이 작아져 학습 함정에 빠지기 쉬움을 보여줍니다.

### **명제 4 (최적 아키텍처)**

공동 최적은 (μ*, τ*) = (1/(n+1), V·n/[c(n+1)²] - 1)이다. 포부는 운영 복잡성에 의해 결정되고, 정밀성은 가치/비용 비율에 의해 결정된다.

**증명:**

최적 아키텍처 `(μ*, τ*)`는 기대 보상에서 신념 형성 비용을 뺀 전체 효용 함수 `L(μ, τ) = E[V(φ)] - C(τ)`를 최대화함으로써 도출됩니다. 여기서 기대 보상 `E[V(φ)]`는 `V * E[φ(1-φ)^n]`이며, 비용 함수 `C(τ)`는 `c * ln(τ+1)`로 정의됩니다. 최적화는 `μ`와 `τ`에 대해 순차적으로 진행됩니다.

**1. 최적 포부(`μ*`)의 결정**

먼저, 주어진 정밀성 `τ`에 대해 효용 함수 `L`을 최대화하는 최적 포부 `μ*`를 찾습니다. 비용 함수 `C(τ)`는 `μ`와 무관하므로, `L`을 `μ`에 대해 최대화하는 것은 기대 보상 `E[V(φ)]`를 최대화하는 것과 같습니다. 기대 보상은 보상 함수 `V(φ)`가 최대가 되는 지점에 신념 분포의 평균 `μ`가 위치할 때 최대화됩니다. 명제 2의 증명에서 보았듯이, 보상 함수 `f(φ) = φ(1-φ)^n`의 최적점은 `φ* = 1/(n+1)` 입니다. 따라서, 기대 보상을 극대화하는 최적의 포부는 다음과 같습니다.

`μ* = 1 / (n+1)`

이 결과는 최적의 포부 수준이 오직 운영의 구조적 특성인 복잡성 `n`에 의해서만 결정됨을 보여줍니다.

**2. 최적 정밀성(`τ*`)의 결정**

다음으로, `μ`를 `μ* = 1/(n+1)`로 고정한 상태에서 효용 함수 `L`을 최대화하는 최적 정밀성 `τ*`를 찾습니다. 해석적 해를 구하기 위해, 기대 보상 `E[V(φ)]`를 `μ*` 근방에서 2차 테일러 전개를 통해 근사합니다.

`E[V(φ)] ≈ V * [f(μ*) + (1/2)f''(μ*)Var(φ)]`

Beta 분포의 분산 `Var(φ) = μ*(1-μ*)/(τ+1)`를 대입하여 `τ`에 대한 효용 함수를 정리하면 다음과 같습니다.

`L(τ) ≈ V * [f(μ*) + (1/2)f''(μ*) * (μ*(1-μ*)/(τ+1))] - c * ln(τ+1)`

`L(τ)`를 `τ`에 대해 미분하여 1계 조건(FOC)을 구하면 다음과 같습니다.

`dL/dτ = V * [(-1/2)f''(μ*)μ*(1-μ*)] / (τ+1)² - c/(τ+1) = 0`

`τ + 1`에 대해 정리하면,

`τ + 1 = (V/c) * [(-1/2)f''(μ*)μ*(1-μ*)]`

여기서 `[...]` 안의 '민감도 항'은 불확실성 감소에 따른 한계 이익을 나타냅니다. 본 모델의 핵심적인 이론적 단계는 이 민감도 항을 `n/(n+1)²`로 근사하는 것입니다. 이 근사는 `n=1, 2`에서 정확히 일치하며, 모든 `n`에 대해 질적 동질성을 유지합니다. 더 중요한 것은, 근사치 `n/(n+1)²`는 과업의 '내재적 불확실성'을 나타내는 `μ*(1-μ*)`와 수학적으로 동일하다는 점입니다. 이 이론적 간소화를 통해 위 식은 다음과 같이 직관적인 형태로 변환됩니다.

`τ + 1 ≈ (V/c) * μ*(1-μ*)`

이는 **"요구되는 정밀성(`τ+1`)은 가치-비용 비율(`V/c`)과 과업의 내재적 불확실성(`μ*(1-μ*)`)의 곱에 비례한다"**는 강력한 경제적 논리를 제공합니다. `μ*(1-μ*) = n/(n+1)²`를 대입하여 `τ*`를 구하면,

`τ + 1 ≈ V·n / [c(n+1)²]`  
`τ* ≈ V·n / [c(n+1)²] - 1`

정밀성은 음수가 될 수 없으므로, 최종적인 최적 정밀성은 다음과 같습니다.

`τ* = max{0, V·n/[c(n+1)²] - 1}`

이 결과는 최적 정밀성이 가치(`V`)와 비용(`c`)의 비율에 직접적으로 영향을 받으며, 동시에 운영 복잡성(`n`)에 의해 조절됨을 명확히 보여줍니다. 특히, 복잡성 `n`이 증가하면 `μ*`가 0에 가까워져 내재적 불확실성이 감소하고, 이는 결과적으로 요구되는 최적 정밀성 `τ*`의 감소로 이어집니다. 이는 복잡한 과업일수록 정교한 신념보다 보수적인 포부가 더 중요해짐을 시사합니다.

따라서, 공동 최적 아키텍처 `(μ*, τ*)`가 증명되었습니다.
# Sharing Prior Distribution
 
1. set out goal as choosing the final nine documents each from josh and scott's school. the resulting nine documents should construct the rational meaning of each others' interest in "bayesian entrepreneur's decison making". for this, it should provide a minimal sufficient summary of their research chain (represented by document's abstract in #scott's resaerch chain and #josh's chain) for their last twenty years of research, to predict their next three years of research trajectory. this nine document representation should maximize three metrics (üìê1Ô∏è‚É£,üìê2Ô∏è‚É£,üìê3Ô∏è‚É£) from üìêevaluation metric. 
2. for 1, consider my classification/organization in # üóÑÔ∏ètable.

# üìêevaluation metric
üìê1Ô∏è‚É£need-solution pair between needs ü•∫1Ô∏è‚É£,ü•∫2Ô∏è‚É£,ü•∫3Ô∏è‚É£ of # ü•∫bayesian entrepreneur's need and solutions üõ†Ô∏è1Ô∏è‚É£,üõ†Ô∏è2Ô∏è‚É£,üõ†Ô∏è3Ô∏è‚É£ of # üõ†Ô∏èjosh's solution 
üìê2Ô∏è‚É£simplicity of their research world representation
üìê3Ô∏è‚É£predictability of their next three years of reasearch on bayesian entrepreneur's decison making

# üõ†Ô∏èjosh's solution 
üõ†Ô∏è1Ô∏è‚É£how can probabilistic inference be used to drive action (utility-based frameworks for decison and planning under uncertainty and risk such as bayesian decision theory and markov decision process), 

üõ†Ô∏è2Ô∏è‚É£how can learning and inference proceed efficiently and accurately even with very complex hypothesis spaces? (sampling based algorithms for approximate inference e.g. mcmc sequential monte carlo, importance sampling). cost sensitive sampling (one and done), resource-rational models, 

üõ†Ô∏è3Ô∏è‚É£how does abstract knowledge guide learning and inference from sparse data (bayesian inference in probabilistic generative models), how is that knowledge itself constructs (hierarchical models with inference at multiple levels, learning models as probabilistic inference (transfer learning, learning inductive biases are not fundamentally different)

# ü•∫bayesian entrepreneur's need
ü•∫1Ô∏è‚É£Entrepreneurs pursue opportunities based on subjective beliefs about their viability, which they continuously update through learning and experimentation. These updated beliefs then inform key decisions, such as whether to make significant commitments to launching or growing a business. 

ü•∫2Ô∏è‚É£While intuitive, explicitly Bayesian models of entrepreneurial decision-making remain relatively novel and offer unique insights compared to (a) behavioral models that emphasize heuristics and biases or (b) game-theoretic models that assume shared priors between entrepreneurs and external stakeholders (e.g., venture capitalists). 

ü•∫3Ô∏è‚É£Capture existing opportunities at the intersection of entrepreneurship, innovation, and Bayesian decision-making by systematically exploring with Bayesian lens, understand entrepreneurial strategy and decision-making, with implications for both theoretical and empirical research.


#‚õìÔ∏èü•∫scott's resaerch chain

## Incumbency and R&D Incentives: Licensing the Gale of Creative Destruction 2000
This paper analyzes the relationship between incumbency and R&D incentives in the context of a model of technological competition in which technologically successful entrants are able to license their innovation to (or be acquired by) an incumbent. That such a sale should take place is natural, since post innovation monopoly profits are greater than the sum of duopoly profits. We identify three key findings about how innovative activity is shaped by licensing. First, since an incumbent's threat to engage in imitative R&D during negotiations increases its bargaining power, there is a purely strategic incentive for incumbents to develop an R&D capability. Second, incumbents research more intensively than entrants as long as (and only if) their willingness to pay for the innovation exceeds that of the entrant, a condition that depends critically on the expected licensing fee. Third, when the expected licensing fee is sufficiently low, the incumbent considers entrant R&D a strategic substitute for in-house research. This prediction about the market for ideas stands in contrast to predictions of strategic complementarity in patent races where licensing is not allowed.

## When Does Start-Up Innovation Spur the Gale of Creative Destruction 2002
This article studies the determinants of commercialization strategy for start-up innovators. We
examine whether the returns on innovation are earned through product market competition or
through cooperation with established firms (through licensing, alliances, or acquisition). Our
hypotheses are that the relative returns to cooperation are increasing in (i) control over intellectualproperty rights, (ii) low transaction costs, and (iii) sunk costs associated with product market
entry. Using a novel dataset of the commercialization strategies of start-up innovators, our results
suggest that the procompetitive impact of start-up innovation-the gale of creative destruction-
depends on imperfections in the market for ideas

## Product market and market for ideas: commercialization strategies for technology entrepreneurs 2003
This paper presents a synthetic framework identifying the central drivers of start-up commercialization strategy and the implications of these drivers for industrial dynamics. We link strategy to the commercialization environment‚Äîthe microeconomic and strategic conditions facing a firm that is translating an ‚Äúidea‚Äù into a value proposition for customers. The framework addresses why technology entrepreneurs in some environments undermine established firms, while others cooperate with incumbents and reinforce existing market power. Our analysis suggests that competitive interaction between start-up innovators and established firms depends on the presence or absence of a ‚Äúmarket for ideas‚Äù. By focusing on the operating requirements, efficiency, and institutions associated with markets for ideas, this framework holds several implications for the management of high-technology entrepreneurial firms.

## Do Scientists Pay to Be Scientists? (2004)

This paper explores the relationship between wages and the scientific orientation of R&D organizations. Firms that adopt a science-oriented research approach (i.e., ‚Äúscience‚Äù) allow their researchers to pursue and publish an individual research agenda. The adoption of science may be associated with a ‚Äútaste‚Äù for science on the part of researchers (a preference effect) and/or as a ‚Äúticket of admission‚Äù to gain earlier access to scientific discoveries with commercial application (a productivity effect). These two effects differ in their impact on wages. Whereas the preference effect contributes to a negative compensating differential, the productivity effect may result in rent sharing. However, because science may be adopted by firms employing higher-quality researchers, cross-sectional evaluations of wages and science may be biased by unobserved heterogeneity. To overcome this bias, this paper introduces a novel empirical approach. Specifically, prior to accepting a given job, many scientists receive multiple job offers, allowing for the calculation of the wage-science relationship and controlling for differences in salary levels offered to individual researchers. Using a dataset composed of multiple job offers to postdoctoral biologists, the results suggest a negative relationship between wages and science. These findings are robust to restricting the sample to non-academic job offers, but the findings depend critically on the inclusion of researcher fixed effects. Conditional on perceived ability, scientists do indeed pay to be scientists.
-> Unmeasurable subjective use value of assumably rational agents differ from their objective exchange value

## Is there market for ideas 2009
This paper draws on recent work in market design to evaluate the conditions under which a market for ideas or technology (MfTs) will emerge and operate efficiently. As highlighted by Roth (2007), effective market design must ensure three basic principles: market thickness, lack of congestion, and market safety. Roth also highlight the importance of dealing with ‚Äúrepugnance.‚Äù Our analysis identifies the factors that are, in most circumstances, likely to inhibit the allocative efficiency of MfT. We show that key institutional developments such as the development of formalized IP exchanges suggest that effective market design may be possible for some innovation markets. Finally, our analysis suggests that markets for ideas are beset by the ‚Äúrepugnance‚Äù problem: from the perspective of market design, Open Science is an institution that places normative value on ‚Äúfree‚Äù disclosure and so undermines the ability of ideas producers to earn market-based returns for producing even very valuable ‚Äúpure‚Äù knowledge.
üîë: ideas market, intellectual property, market design, repugnance, appropriation

## Endogenous appropriability 2017
Innovation's private value is typically less than its social value, so to encourage innovation, researchers in economics and strategy have focused on how innovators can appropriate value across different economic, institutional, and strategic environments (Teece 1986; Gans and Stern 2003). For start-ups without pre-existing assets such as manufacturing capabilities or brand reputation, researchers have identified appropriability through formal intellectual property protection (which we will refer to as a "control" approach) and first-mover competitive advantage (which we will refer to as an "execution" approach) as distinct paths. Most research has taken a start-up's appropriability regime as exogenous, i.e., environmentally determined (e.g., control-orientation in biotechnology, and execution-orientation in Internet software). This paper develops a simple model highlighting the interplay between control and execution as alternative routes to appropriability. Whereas a control strategy allows an innovator to forestall imitation once established, control itself takes time, and so can delay market entry. In contrast, an execution strategy is premised on taking advantage of the benefits arising from rapid market entry such as customer learning, reputational advantages, or coordination on a standard. Does the start-up shield itself from competition through investing in entry barriers or does it invest in dynamic capabilities allowing it to "get ahead, stay ahead"? We derive two main results. First, the choices of control and execution are strategic substitutes. Notably, when the ability to learn from early customer feedback in the marketplace is sufficiently high, an entrepreneur might choose not to invest in intellectual property protection even if such protection is costless and effective. Second, the choice between control and execution interacts with other key strategic choices such as whether to pursue a narrow or broad customer segment, or whether to commercialize a minimal viable product versus a more robust version. Innovation appropriability depends not only on the instruments available to an innovator, but on how those instruments interact with each other as part of the firm's (endogenous) entrepreneurial strategy (see Ching, Gans, and Stern 2016; Gans, Stern, and Wu 2016).

## Choosing Technology: An Entrepreneurial Strategy Approach 2020
A central premise of research in the strategic management of innovation is that start-ups are able to leverage emerging technological trajectories as a source of competitive advantage. But, if the potential for a technology is given by the fundamental character of a given technological trajectory, then why does entrepreneurial strategy matter? Or, put another way, if the evolution of technology is largely shaped by the strategic choices entrepreneurs make, then why do technological trajectories exhibit systematic patterns such as the technology S-curve? Taking a choice-based perspective, this paper illuminates the choices confronting a start-up choosing their technology by resolving the paradox of the technology S-curve through a reformulation of the foundations of the technology S-curve. SpeciÔ¨Åcally, we reconceptualize the technology S-curve not as a technological given but as an envelope of potential outcomes reÔ¨Çecting differing strategic choices by the entrepreneur in exploration versus exploitation. Taking this lens, we are able to clarify the role of technological uncertainty on start-up strategy, the impact of constraints on technological evolution, and how technology choice is shaped by the possibility of imitation. Our Ô¨Åndings suggest that staged exploration may stall innovation as a result of the replacement effect, increasing the strategic importance of commitment.
üîë: technology strategy ‚Ä¢ technology and innovation management ‚Ä¢ innovation management ‚Ä¢ entrepreneurial strategy ‚Ä¢ entrepreneurship ‚Ä¢ exploration ‚Ä¢ exploitation

## Entrepreneurial Uncertainty Expert Evaluation 2019
This paper empirically examines the evaluations of 537 ventures in high-growth industries performed by 251 experienced entrepreneurs, investors, and executives. These experts evaluated ventures by reading succinct summaries of the ventures without meeting the founding teams, and their evaluations were not disclosed to the entrepreneurs. We find that experts can differentiate among early-stage ventures on grounds of quality beyond the explicit venture and entrepreneur characteristics contained in the written summaries. They can only do so effectively, however, for ventures in the hardware, energy, life sciences, and medical devices sectors; they cannot do so for ventures in the consumer products, consumer web and mobile, and enterprise software sectors. Our results highlight sector-specific heterogeneity in the information needed to effectively screen ventures, a finding that has implications for the design of optimal investment strategies.

## Foundations of entrepreneurial strategy 2019
Research Summary: This paper develops an integrated framework linking the nature of the entrepreneurial choice process to the foundations of entrepreneurial strategy. Because entrepreneurs face many alternatives that cannot be pursued at once, entrepreneurs must adopt (implicitly or explicitly) a process for choosing among entrepreneurial strategies. The interplay between uncertainty and learning has the consequence that commitment-free analysis yields multiple, equally viable alternatives from which one must be chosen. This endogenous gap between optimization and choice is a central paradox confronting entrepreneurs. Resolving this allows for a reformulation of the foundations of entrepreneurial strategy, emphasizing the role of choice rather than the centrality of the strategic environment.
Managerial Summary: The central strategic challenge for an entrepreneur is how to choose: entrepreneurs often face multiple potential strategies for commercializing their idea but due to the constraint of limited resources, cannot pursue them all at once. At the same time, entrepreneurs are venturing into new domains and as such, must choose under conditions of high uncertainty with only noisy learning available. This paper explores the interplay between these unique conditions that shape the entrepreneurial choice process, finding that often, the process will not yield a single best strategy but instead several equally attractive strategic alternatives. A key implication is that entrepreneurs cannot simply choose what not to do, but instead must proactively decide which equally viable alternatives to leave behind when choosing an entrepreneurial strategy.
üîë: appropriability, entrepreneurial strategy, entrepreneurship, strategy, uncertainty

## üìñEntrepreneurship choice strategy 2024
Part 1: Getting Started
The authors begin with a deep dive into why choice matters, focusing on the initial choice to become an entrepreneur, the choice of which idea to pursue, and the choice of an overall strategy for a venture:
Chapter 1: Understanding the Power of Choice
Chapter 2: Choosing Entrepreneurship
Chapter 3: Choosing Your Opportunity
Chapter 4: Choosing Your Strategy
Part 2: Core Choices
Next, the authors focus on four clusters of choices that are central to the founding and scaling of a venture. These choices exist around:
Chapter 5: Choosing Your Customer
Chapter 6: Choosing Your Technology
Chapter 7: Choosing Your Organization
Chapter 8: Choosing Your Competition
Part 3: Four Strategies: How Choices Work Together
The book matches key complementary choices to create four different strategies for start-ups that entrepreneurs can explore for a given idea:
Chapter 9: Intellectual Property Strategy
Chapter 10: Disruption Strategy
Chapter 11: Value Chain Strategy
Chapter 12: Architectural Strategy
Each of these strategies reflects a distinctive set of choices of customer, technology, organization, and competition and highlights specific interconnected factors that entrepreneurs can exploit in translating their idea into a viable company.
Part 4: Putting It to Work
Once entrepreneurs are equipped with the tools to translate an idea into reality, these three chapters help them explore building a venture with a foundation for long-term viability, which are focused on:
Chapter 13: From Strategy to Action
Chapter 14: Financing
Chapter 15: Scaling
One at a time, these chapters show students how to choose a strategy, enable it, and possibly decide to grow and scale a business.

## Bayesian entrepreneurship 2024
How does the fact that entrepreneurs choose the opportunity they pursue impact entrepreneurial strategy and performance? Entrepreneurs, while dealing with opportunities whose outcome is inherently uncertain, have choices that must be premised on a belief that the opportunity is worth pursuing. This insight provides an organizing principle for a Bayesian approach to entrepreneurial decision-making. A Bayesian approach offers a natural formal framework to assess how entrepreneurs form beliefs about the prospects for a given opportunity, how these beliefs evolve over time through active experimentation and learning, and the consequences of such beliefs for entrepreneurial strategy and performance.
The goal is to shape distinctive implications and empirical approaches to the study of entrepreneurship guided by founding premises. The first premise is that the entrepreneur must be relatively optimistic about the opportunity relative to others. This involves a distinct theory that translates into a different perspective on the opportunity‚Äôs prospects. Second, this systematic divergence in beliefs impacts how an entrepreneur will undertake learning about an opportunity. Notably, the demand for ‚Äúexperiments‚Äù is fundamentally influenced by beliefs about the opportunity. For example, relative to a disinterested agent, a Bayesian entrepreneur will conduct experiments that are more likely to allow for ‚Äúfalse positives‚Äù than ‚Äúfalse negatives.‚Äù Finally, this approach promotes the processes by which entrepreneurs are able to attract resources and capabilities by providing information to other agents. Entrepreneurs are more likely to convince those who share their idiosyncratically optimistic beliefs about an opportunity (with implications for homophily and firm culture), yet will also engage in choosing experiments that cater to those with different (more negative) beliefs than they themselves hold.


#‚õìÔ∏èüõ†Ô∏èjosh's chain

## Bayesian modeling of human concept learning
I consider the problem of learning concepts from small numbers of positive examples, a feat which humans perform routinely but which computers are rarely capable of. Bridging machine learning and cognitive science perspectives, I present both theoretical analysis and an empirical study with human subjects for the simple task of learning concepts corresponding to axis-aligned rectangles in a multidimensional feature space. Existing learning models, when applied to this task, cannot explain how subjects generalize from only a few examples of the concept. I propose a principled Bayesian model based on the assumption that the examples are a random sample from the concept to be learned. The model gives precise fits to human behavior on this simple task and provides qualitati ve insights into more complex, realistic cases of concept learning.


## Probabilistic models of cognition conceptual foundations 06
Remarkable progress in the mathematics and computer science of probability has led to a revolution in the scope of probabilistic models. In particular, ‚Äòsophisticated‚Äô probabilistic methods apply to structured relational systems such as graphs and grammars, of immediate relevance to the cognitive sciences. This Special Issue outlines progress in this rapidly developing field, which provides a potentially unifying perspective across a wide range of domains and levels of explanation. Here, we introduce the historical and conceptual foundations of the approach, explore how the approach relates to studies of explicit probabilistic reasoning, and give a brief overview of the field as it stands today.

## From more coincidences to meaningful discoveries 07
People‚Äôs reactions to coincidences are often cited as an illustration of the irrationality of human reasoning about chance. We argue that coincidences may be better understood in terms of rational statistical inference, based on their functional role in processes of causal discovery and theory revision. We present a formal definition of coincidences in the context of a Bayesian framework for causal induction: a coincidence is an event that provides support for an alternative to a currently favored causal theory, but not necessarily enough support to accept that alternative in light of its low prior probability. We test the qualitative and quantitative predictions of this account through a series of experiments that examine the transition from coincidence to evidence, the correspondence between the strength of coincidences and the statistical support for causal structure, and the relationship between causes and coincidences. Our results indicate that people can accurately assess the strength of coincidences, suggesting that irrational conclusions drawn from coincidences are the consequence of overestimation of the plausibility of novel causal forces. We discuss the implications of our account for understanding the role of coincidences in theory change.

## Learning grounded causal model 07
We address the problem of learning grounded causal models: systems of concepts that are connected by causal relations and explicitly grounded in perception. We present a Bayesian framework for learning these models‚Äîboth a causal Bayesian network structure over variables and the consequential region of each variable in perceptual space‚Äîfrom dynamic perceptual evidence. Using a novel experimental paradigm we show that humans are able to learn grounded causal models, and that the Bayesian model accounts well for human performance.

## Theory-Based Causal Induction 2009
Inducing causal relationships from observations is a classic problem in scientific inference, statistics, and machine learning. It is also a central part of human learning, and a task that people perform remarkably well given its notorious difficulties. People can learn causal structure in various settings, from diverse forms of data: observations of the co-occurrence frequencies between causes and effects, interactions between physical objects, or patterns of spatial or temporal coincidence. These different modes of learning are typically thought of as distinct psychological processes and are rarely studied together, but at heart they present the same inductive challenge‚Äîidentifying the unobservable mechanisms that generate observable relations between variables, objects, or events, given only sparse and limited data. We present a computational-level analysis of this inductive problem and a framework for its solution, which allows us to model all these forms of causal learning in a common language. In this framework, causal induction is the product of domain-general statistical inference guided by domain-specific prior knowledge, in the form of an abstract causal theory. We identify 3 key aspects of abstract prior knowledge‚Äîthe ontology of entities, properties, and relations that organizes a domain; the plausibility of specific causal relationships; and the functional form of those relationships‚Äîand show how they provide the constraints that people need to induce useful causal models from sparse data. 
üîë: causal induction, intuitive theories, rational analysis, Bayesian modeling

## One and done 2014
In many learning or inference tasks human behavior approximates that of a Bayesian ideal observer, suggesting that, at some level, cognition can be described as Bayesian inference. However, a number of Ô¨Åndings have highlighted an intriguing mismatch between human behavior and standard assumptions about optimality: People often appear to make decisions based on just one or a few samples from the appropriate posterior probability distribution, rather than using the full distribution. Although sampling-based approximations are a common way to implement Bayesian inference, the very limited numbers of samples often used by humans seem insufÔ¨Åcient to approximate the required probability distributions very accurately. Here, we consider this discrepancy in the broader framework of statistical decision theory, and ask: If people are making decisions based on samples‚Äîbut as samples are costly‚Äîhow many samples should people use to optimize their total expected or worst-case reward over a large number of decisions? We Ô¨Ånd that under reasonable assumptions about the time costs of sampling, making many quick but locally suboptimal decisions based on very few samples may be the globally optimal strategy over long periods. These results help to reconcile a large body of work showing sampling-based or probability matching behavior with the hypothesis that human cognition can be understood in Bayesian terms, and they suggest promising future directions for studies of resource-constrained cognition.

## Computational rationality: converging paradigm for intelligence in brains, minds, and machines 15
After growing up together, and mostly growing apart in the second half of the 20th century, the fields of artificial intelligence (AI), cognitive science, and neuroscience are reconverging on a shared view of the computational foundations of intelligence that promotes valuable cross-disciplinary exchanges on questions, methods, and results. We chart advances over the past several decades that address challenges of perception and action under uncertainty through the lens of computation. Advances include the development of representations and inferential procedures for large-scale probabilistic inference and machinery for enabling reflection and decisions about tradeoffs in effort, precision, and timeliness of computations. These tools are deployed toward the goal of computational rationality: identifying decisions with highest expected utility, while taking into consideration the costs of computation in complex real-world problems in which most relevant calculations can only be approximated. We highlight key concepts with examples that show the potential for interchange between computer science, cognitive science, and neuroscience.

## Subjective randomness as statistical inference 18
Some events seem more random than others. For example, when tossing a coin, a sequence of eight heads in a row does not seem very random. Where do these intuitions about randomness come from? We argue that subjective randomness can be understood as the result of a statistical inference assessing the evidence that an event provides for having been produced by a random generating process. We show how this account provides a link to previous work relating randomness to algorithmic complexity, in which random events are those that cannot be described by short computer programs. Algorithmic complexity is both incomputable and too general to capture the regularities that people can recognize, but viewing randomness as statistical inference provides two paths to addressing these problems: considering regularities generated by simpler computing machines, and restricting the set of probability distributions that characterize regularity. Building on previous work exploring these different routes to a more restricted notion of randomness, we define strong quantitative models of human randomness judgments that apply not just to binary sequences ‚Äì which have been the focus of much of the previous work on subjective randomness ‚Äì but also to binary matrices and spatial clustering.

## Na√Øve Utility Calculus as a unified, quantitative framework for action understanding 20
The human ability to reason about the causes behind other people‚Äô behavior is critical for navigating the social world. Recent empirical research with both children and adults suggests that this ability is structured around an assumption that other agents act to maximize some notion of subjective utility. In this paper, we present a formal theory of this Na√Øve Utility Calculus as a probabilistic generative model, which highlights the role of cost and reward tradeoffs in a Bayesian framework for action-understanding. Our model predicts with quantitative accuracy how people infer agents‚Äô subjective costs and rewards based on their observable actions. By distinguishing between desires, goals, and intentions, the model extends to complex action scenarios unfolding over space and time in scenes with multiple objects and multiple action episodes. We contrast our account with simpler model variants and a set of special-case heuristics across a wide range of action-understanding tasks: inferring costs and rewards, making confidence judgments about relative costs and rewards, combining inferences from multiple events, predicting future behavior, inferring knowledge or ignorance, and reasoning about social goals. Our work sheds light on the basic representations and computations that structure our everyday ability to make sense of and navigate the social world.

## From world to word model:  translating from natural language to the probabilistic language of thought 23
How does language inform our downstream thinking? In particular, how do humans make meaning from language--and how can we leverage a theory of linguistic meaning to build machines that think in more human-like ways? In this paper, we propose rational meaning construction, a computational framework for language-informed thinking that combines neural language models with probabilistic models for rational inference. We frame linguistic meaning as a context-sensitive mapping from natural language into a probabilistic language of thought (PLoT)--a general-purpose symbolic substrate for generative world modeling. Our architecture integrates two computational tools that have not previously come together: we model thinking with probabilistic programs, an expressive representation for commonsense reasoning; and we model meaning construction with large language models (LLMs), which support broad-coverage translation from natural language utterances to code expressions in a probabilistic programming language. We illustrate our framework through examples covering four core domains from cognitive science: probabilistic reasoning, logical and relational reasoning, visual and physical reasoning, and social reasoning. In each, we show that LLMs can generate context-sensitive translations that capture pragmatically-appropriate linguistic meanings, while Bayesian inference with the generated programs supports coherent and robust commonsense reasoning. We extend our framework to integrate cognitively-motivated symbolic modules (physics simulators, graphics engines, and planning algorithms) to provide a unified commonsense thinking interface from language. Finally, we explore how language can drive the construction of world models themselves. We hope this work will provide a roadmap towards cognitive models and AI systems that synthesize the insights of both modern and classical computational perspectives.

## Online Bayesian Goal Inference for Boundedly-Rational Planning Agents (2020)
People routinely infer the goals of others by observing their actions over time. Remarkably, we can do so even when those actions lead to failure, enabling us to assist others when we detect that they might not achieve their goals. How might we endow machines with similar capabilities? Here we present an architecture capable of inferring an agent‚Äôs goals online from both optimal and non-optimal sequences of actions. Our architecture models agents as boundedly-rational planners that interleave search with execution by replanning, thereby accounting for sub-optimal behavior. These models are speciÔ¨Åed as probabilistic programs, allowing us to represent and perform efÔ¨Åcient Bayesian inference over an agent‚Äôs goals and internal planning processes. To perform such inference, we develop Sequential Inverse Plan Search (SIPS), a sequential Monte Carlo algorithm that exploits the online replanning assumption of these models, limiting computation by incrementally extending inferred plans as new actions are observed. We present experiments showing that this modeling and inference architecture outperforms Bayesian inverse reinforcement learning baselines, accurately inferring goals from both optimal and non-optimal trajectories involving failure and back-tracking, while generalizing across domains with compositional structure and sparse rewards.

## üìúNatively Probabilistic Computation (2009)
Vikash Mansinghka‚Äôs phd thesis
This work builds on the notion that some ideas are not only distinctive, but also contrarian: pursued by few, and met with open skepticism by most. Such skepticism hinders contrarians from attracting resources but allows them to experiment openly without fear of immediate imitation. To investigate this dynamic, I leverage hundreds of Artificial Intelligence contests where researchers either employ popular, state-of-the-art methods or pursue alternative, contrarian approaches. These contests act as sudden ‚Äúmoments of clarity‚Äù that reveal which methods perform best. They allow researchers to attract resources for commercialization, but also potentially alert competitors of the opportunity. Through a difference-in-differences design, I find that when contrarian contestants win, they are up to 7√ó more likely to found startups, and their startups attract up to 3√ó higher venture capital valuations. This cannot be simply explained by the fact that contrarians are more likely to achieve breakthroughs; much of the advantage arises by winning close races. Instead, while close victories validate contrarian entrepreneurs and allow them to attract resources, mainstream researchers tend to adopt contrarian methods only when they conclusively outperform traditional approaches. This reluctance to build on contrarian ideas allows contrarians to leverage public demonstrations to attract resources without provoking immediate competition. 

## üìúTowards more human-like concept learning in machines : compositionality, causality, and learning-to-learn (2014)
Brenden Lake‚Äôs phd thesis
People can learn a new concept almost perfectly from just a single example, yet machine learning algorithms typically require hundreds or thousands of examples to perform similarly. People can also use their learned concepts in richer ways than conventional machine learning systems - for action, imagination, and explanation suggesting that concepts are far more than a set of features, exemplars, or rules, the most popular forms of representation in machine learning and traditional models of concept learning. For those interested in better understanding this human ability, or in closing the gap between humans and machines, the key computational questions are the same: How do people learn new concepts from just one or a few examples? And how do people learn such abstract, rich, and flexible representations? An even greater puzzle arises by putting these two questions together: How do people learn such rich concepts from just one or a few examples? This thesis investigates concept learning as a form of Bayesian program induction, where learning involves selecting a structured procedure that best generates the examples from a category. I introduce a computational framework that utilizes the principles of compositionality, causality, and learning-to-learn to learn good programs from just one or a handful of examples of a new concept. New conceptual representations can be learned compositionally from pieces of related concepts, where the pieces reflect real part structure in the underlying causal process that generates category examples. This approach is evaluated on a number of natural concept learning tasks where humans and machines can be compared side-by-side. Chapter 2 introduces a large-scale data set of novel, simple visual concepts for studying concept learning from sparse data. People were asked to produce new examples of over 1600 novel categories, revealing consistent structure in the generative programs that people used. Initial experiments also show that this structure is useful for one-shot classification. Chapter 3 introduces the computational framework called Hierarchical Bayesian Program Learning, and Chapters 4 and 5 compare humans and machines on six tasks that cover a range of natural conceptual abilities. On a challenging one-shot classification task, the computational model achieves human-level performance while also outperforming several recent deep learning models. Visual "Turing test" experiments were used to compare humans and machines on more creative conceptual abilities, including generating new category examples, predicting latent causal structure, generating new concepts from related concepts, and freely generating new concepts. In each case, fewer than twenty-five percent of judges could reliably distinguish the human behavior from the machine behavior, showing that the model can generalize in ways similar to human performance. A range of comparisons with lesioned models and alternative modeling frameworks reveal that three key ingredients - compositionality, causality, and learning-to-learn - contribute to performance in each of the six tasks. This conclusion is further supported by the results of Chapter 6, where a computational model using only two of these three principles was evaluated on the one-shot learning of new spoken words. Learning programs with these ingredients is a promising route towards more human like concept learning in machines.

## üìñBayesian models of cognition: reverse engineering the mind (Textbook, 2024) 

3. Introducing the Bayesian Approach to Cognitive Science
4. Probabilistic Models of Cognition in Historical Context
5. Bayesian Inference
6. Graphical Models
7. Building Complex Generative Models
8. Approximate Probabilistic Inference
9. From Probabilities to Actions
10. Learning Inductive Bias with Hierarchical Bayesian Models
11. Capturing the Growth of Knowledge with Nonparametric Bayesian Models
12. Estimating Subjective Probability Distributions
13. Sampling as a Bridge Across Levels of Analysis
14. Bayesian Models and Neural Networks
15. Resource-Rational Analysis
16. Theory of Mind and Inverse Planning
17. Intuitive Physics as Probabilistic Inference
18. Language Processing and Language Learning
19. Bayesian Inference over Logical Representations
20. Probabilistic Programs as a Unifying Language of Thought
21. Learning as Bayesian Inference over Programs
22. Bayesian Models of Cognitive Development
23. The Limits of Inference and Algorithmic Probability
24. A Bayesian Conversation

# üóÑÔ∏ètable

| Individual's Learning                                                                                                  | Individual's Action/Choice/Decision given learning                                                               | thesis advised / textbook                                                                                                                                         |
| ---------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Bayesian Concept Learning (1999)                                                                                       | Action understanding as inverse planning (2009)                                                                  | üìúNatively Probabilistic Computation (2009)<br>üìúTowards more human-like concept learning in machines : compositionality, causality, and learning-to-learn (2014) |
| Theory-Based Causal Induction (2007)                                                                                   | The Na√Øve Utility Calculus as a unified, quantitative framework for action understanding (2016)                  | üìñBayesian models of cognition: reverse engineering the mind (Textbook, 2024)                                                                                     |
| Learning Grounded Causal Models (2007)                                                                                 | From Word to World Models: Translating from Natural Language to the Probabilistic Language of Thought (2023)<br> |                                                                                                                                                                   |
| How to Grow a Mind (2011)                                                                                              | Building machines that learn and think with people (2024)                                                        |                                                                                                                                                                   |
| Human-level concept learning through probabilistic program induction (2015)                                            | Pragmatic Instruction Following and Goal Assistance via Cooperative Language-Guided Inverse Planning (2024)      |                                                                                                                                                                   |
| Rational quantitative attribution of beliefs, desires and percepts in human mentalizing (Bayesian theory of mind 2017) |                                                                                                                  |                                                                                                                                                                   |

| Society's Market                                                                                        | Individual's Action/Choice/Decision given Market                 | thesis advised / textbook                                                                                                                                                        |
| ------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Incumbency and R&D Incentives (2000)                                                                    | Do scientists pay to be scientists? (2004)                       | üìúThree essays on entrepreneurial quality (2017)<br>üìúEssays on the Role of Metrics in Innovation (2022)<br>üìúCommercializing Contrarian Ideas: Evidence from AI Contests (2024) |
| When Does Start-Up Innovation Spur the Gale of Creative Destruction (Compete vs Collaborate) (2002)<br> | Endogenous appropriability (Control vs Execution) (2018)         | üìñBayesian entrepreneurship (Textbook, 2024)<br>üìñEntrepreneurship choice strategy (Textbook, 2024)                                                                              |
| Product market and market for ideas (2003)<br>                                                          | Foundations of Entrepreneurial Strategy (2019)                   |                                                                                                                                                                                  |
| Is There a Market for Ideas? (2010)                                                                     | Choosing Technology: An Entrepreneurial Strategy Approach (2020) |                                                                                                                                                                                  |
|                                                                                                         | Bayesian Entrepreneruship (2024)                                 |                                                                                                                                                                                  |
|                                                                                                         | Theory-Based Entrepreneurial Search (2024)                       |                                                                                                                                                                                  |


| Josh's Learning | Josh's Decision/Action | Scott's Choice | Scott's Market |
| --------------- | ---------------------- | -------------- | -------------- |
|                 |                        |                |                |


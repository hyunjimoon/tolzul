# Optimal Experiments in Bayesian Entrepreneurship

## How Smart Experiment Design Can Save Your Startup

---

## Your Experiments Might Be Backwards

**King Gustav III designed a "perfect" experiment with twin prisoners to prove coffee was poison - but the tea drinker died first, suggesting his hypothesis was completely wrong.**



_"The experiment worked... sort of... The king died, Both investigators died, Then his tea drinking twin died, Ban was eventually lifted in 1823"_

---

## Most Entrepreneurs Confuse Activity with Learning

**You think you're "experimenting" when you're actually just committing resources - the difference determines whether you pivot intelligently or burn cash chasing false signals.**

_Image: Triangle diagram showing Criticality-Fidelity-Opportunity Cost framework (Page 5)_

_"While an 'ideal' experiment tests a critical hypothesis with high fidelity and low opportunity cost, most entrepreneurship experimentation involves a tradeoff between criticality, fidelity, and opportunity cost"_ - Gans, Scott, Stern (2024)

---

## If Your "Experiment" Takes Your Entire Runway, It's Not an Experiment

**King Gustav died before seeing his results - if your test requires your whole budget or takes longer than your timeline, you're making a bet, not gathering information.**

_Image: Prisoner in cell with coffee/tea pots (Page 3)_

_Citation: Gustav III of Sweden's coffee experiment - purported twin study ordered by the king_

---

## You Control More Than You Think

**Every experiment you design has three levers: how realistic it is (fidelity), how much it costs (opportunity cost), and what kind of information it generates - most entrepreneurs only obsess about cost.**

_Image: Triangle diagram (Page 5)_

_Framework: Criticality ↔ Fidelity ↔ Opportunity Cost_

_"Choosing 'What to Test' is Perhaps the Most Critical Choice of All..."_ - Gans, Scott, Stern (2024)

---

## Your Investors Already Use This Framework

**VCs use stage financing as systematic experiments with shared assumptions about risk - they're not just being cautious, they're methodically reducing uncertainty before writing bigger checks.**

_Image: 2x2 Matrix (Page 6)_

```
Learning Approach:
           Emergent    |    Theory-Based
Shared     Jovanovic   |    Gompers (1995)
Priors     (1982)      |    
----------------------------------------
Subjective Sarasvathy  |    Gambardella,
Priors     (2001)      |    Gius, Stern (2025)
```

---

## Technology Shifts Change Who Gets Funded

**When cloud computing made software experiments dramatically cheaper, it became easier for software startups to prove their concepts quickly compared to hardware companies requiring expensive prototypes.**

_Image: Bar chart showing "Treated to non-treated firms" 2002-2010 (Page 7)_

_"A Drop in the cost of experimentation (Ewens, Nanda, Rhodes-Kropf 2018): More long-shots get funded, Concentration in low-cost sectors"_

---

## Easy-to-Test Doesn't Mean Better Business

**Just because your startup can run cheap experiments doesn't make it a better investment - investors sometimes confuse "easy to validate" with "likely to succeed at scale."**

_Image: Space funding charts (Page 9)_

_Data: Space Investment Quarterly (Q4 2024), Space Capital_ _Shows: Applications require $3.5B avg funding before exit vs Infrastructure at $0.2B_

---

## You and Your Investors Disagree More Than You Admit

**Traditional models assume you both see the same risks - but you're optimistic about your technology while they're skeptical about your market, creating fundamentally different experiment priorities.**

_Image: "DEFENDING THE ULTIMATE" presentation screenshot (Page 11)_

_"...this venture has no right to pursue this in the US. The venture requested to engage further, but advised they would likely 'agree to disagree'."_

---

## Your Prior Beliefs Determine Your Experiment Design

**If you're 90% confident your product will work, you'll unconsciously design tests that confirm this belief rather than tests that could prove you wrong - this isn't bias, it's mathematically rational.**

_Image: 2x2 Signal table (Page 12)_

```
                (Good News) s=1  |  (Bad News) s=0
(Success) V          λ₁          |      1-λ₁
(Failure) 0        1-λ₀          |        λ₀
```

_"An experiment is useful when the signal affects the decision"_

---

## The Math Behind Why Neutral Experiments Don't Exist

**Your expected learning from any experiment must equal what you believed before running it - this constraint means truly "unbiased" experiments are impossible when you care about the outcome.**

_Image: Mathematical formulas (Page 12)_

**(λ₁μₑ + (1-λ₀)(1-μₑ))(R(μ̃ₑ(1)) - C) - c ≥ R(μₑ)**

_μₑ(c) ≡ μₑ ≤ (Cλ₀ - c)/[Cλ₀ + (1-λ₁)(V-C)]_

_Bayesian Entrepreneurship (2025)_

---

## False Positives vs False Negatives Have Different Costs to You

**The ratio of false positives to false negatives in your experiment should match how strongly you believe in success - if you're confident, design tests that rarely give false hope.**

_Image: WTP triangular diagram (Page 12)_

_Shows: Pre-disposed not to exploit ↔ Pre-disposed to exploit_ _With "Experiments Conducted" zone in middle_

---

## You Can Strategically Choose Your Error Types

**Entrepreneurs who believe in their idea should design experiments with high true positive rates - if you get a negative signal despite stacking the deck, that's incredibly valuable information.**

_Image: λ₁ vs λ₀ choice set diagram (Page 13)_

_Mathematical constraint: E ≡ {λ₁, λ₀|λ₁ + λ₀ ≤ Λ}_

_Shows: μᵢ/(1-μᵢ) = (1-λ₀)/(1-λ₁)_

_"Pre-disposed to exploit" vs "Pre-disposed to not exploit"_

---

## Different Audiences Need Different Evidence

**The experiment that convinces your technical co-founder won't convince a conservative investor - designing experiments means choosing your audience first, then your methodology.**

_Image: Management Science paper cover (Page 14)_

_"Sampling Bias in Entrepreneurial Experiments"_

_"Using variation in the gender of beta testers show mismatch between target/actual users hampers growth"_

_Cao, Koning, Nanda - Management Science Vol. 70, No. 10, October 2024_

---

## "Bias" Can Be Optimal Strategy

**Bayesian entrepreneurship shows that deliberately "biased" experiments are often the smartest choice - the goal isn't neutrality, it's designing tests that generate maximum decision value.**

_Image: Utility equations (Page 10)_

_Uᵢ = p₀s₁αV - [p₀s₁ + (1-p₀)(1-s₂)]K - C_

_Uₛ = p₀s₁(1-α)V + [p₀s₁ + (1-p₀)(1-s₂)]Z + Z_

_"Scientists drives value Z > 0 from problem solving, regardless of success"_ - Bolton et al. (2024)

---

## Your Experiment Strategy Is Your Competitive Moat

**While competitors run random A/B tests, you can systematically design information-gathering that matches your beliefs, resources, and stakeholders - turning experimentation from cost center to strategic advantage.**

_Image: Mentoring experimental results (Page 15)_

_Shows: Impact of mentor characteristics on entrepreneur advice-taking_ _"And demand for experiments (Sariri, forthcoming)"_

_Demonstrates: Strategic experimentation drives measurable business outcomes_


# simplified

# Optimal Experiments in Bayesian Entrepreneurship

## 15 Min Review
using [cld](https://claude.ai/chat/4bbd01e7-1679-4f36-bc63-59a6ba68969b)

---

## Experiments Can Give You the Wrong Answer

King Gustav's coffee experiment "H0: coffee is poison"
king died, tea drinker twin died first, proving coffee was safe.

![[Pasted image 20250529160406.png|]]

---

## Experiment vs. Commitment

If your test takes all your money or time, it's not an experiment.



---

## You Have Three Levers

Every experiment: tradeoff btw Criticality, Fidelity, Opportunity Cost

![[Pasted image 20250529173954.png]]
-> max  C * F / O

---

## VCs Already Do This

Stage financing = systematic experiments with shared assumptions

![[Pasted image 20250529174235.png]]

---

## Tech Changes Experiments via Opportunity cost

Cheap cloud computing shifted VC money to software vs hardware

[📜Cost of experimentation and the evolution of venture capital](https://www.sciencedirect.com/science/article/pii/S0304405X18300631)

---

## Cheap ≠ Better

Easy to test doesn't mean good business

_Image: Space funding charts (Page 9)_

---

## You Disagree With Your Investors

Different beliefs = different experiment priorities

_Image: "DEFENDING THE ULTIMATE" slide (Page 11)_

---

## Your Beliefs Shape Your Tests

90% confident → design tests that confirm, not challenge

_Image: Signal table (Page 12)_

---

## Math: No "Neutral" Experiments

Expected posterior = prior (when you care about results)

_Image: Equations (Page 12)_

---

## Error Types Have Different Costs

False positive vs false negative depends on your confidence

_Image: WTP triangle (Page 12)_

---

## Choose Your Errors Strategically

High confidence → high true positive rate experiments

_Image: Choice set graph (Page 13)_

---

## Audience Matters

Tech co-founder needs different proof than conservative investor

_Image: Management Science paper (Page 14)_

---

## "Bias" Can Be Optimal

Deliberately biased experiments often smartest choice

_Image: Utility equations (Page 10)_

---

## Experiments = Competitive Advantage

Strategic design beats random A/B testing

_Image: Mentoring results (Page 15)_

---

## Next Steps

Move from "entrepreneurs are overconfident" to "entrepreneurs design information strategically"
2025-02-16
MVT vs GMT manifest tradeoff between criticality, fidelity, opportunity cost. i might be wrong but if we assume the goal is to measure venture's success, GMT has higher criticality as venture's success should eventually have its idea implemented. however, especially when founder risks oneself to be stubborn (not learning as it has too optimistic expectation on idea's value or keep low sigma), choosing GMT may have lower fidelity. one's prior distribution distorts the interpretation of data. opportunity cost has several layers - one is from delay cost and the other is from implementation cost. the delay cost is higher for MVT and implementation cost is higher for GMT. compared to implementation cost, delay cost is invisible so is easily ignored but it is very important to include both. i wish to encapsulate this complexity in two sentence in a form that engages readers.


2025-02-14
## 1. Testing Entrepreneurial Hypothesis and Experiment 

| Hypothesis                                                                                                                                    | Mathematical Form                                                                                                                                                                                     | Rent the Runway Example                                                                                                                                                                                             |
| --------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **H1a:** Higher prior mean of market potential increases the relative value of **modular** learning                                           | $\color{blue}{\mu_\phi} \uparrow \; \Longrightarrow \; \color{brown}{\Delta EU^\phi} \uparrow \text{ (relative to } \color{brown}{\Delta EU^{\phi\theta}}\text{)}$                                    | High confidence in market potential (μφ) for formal dress rentals among college students led them to start with modular testing - simple trunk shows at Harvard                                                     |
| **H1b:** Higher uncertainty (variance/std) in the prior distribution of market potential increases the relative value of **modular** learning | $\color{blue}{\sigma_\phi} \uparrow \; \Longrightarrow \; \color{brown}{\Delta EU^\phi} \uparrow \text{ (relative to } \color{brown}{\Delta EU^{\phi\theta}}\text{)}$                                 | High uncertainty about exact customer preferences (σφ) led to testing with small samples first (100 students) before scaling                                                                                        |
| **H2:** Higher mean implementation capability increases the relative value of **integrated** learning                                         | $\color{blue}{\mu_\theta} \uparrow \; \Longrightarrow \; \color{brown}{\Delta EU^{\phi\theta}} \uparrow \text{ (relative to } \color{brown}{\Delta EU^\phi}\text{)}$                                  | Once they established strong partnerships with designers (high μθ), they moved to integrated testing with full rental experience including returns and cleaning                                                     |
| **H3:** Higher correlation between market potential and implementation effectiveness increases the relative value of **integrated** learning  | $\rho\!\bigl(\color{green}{\phi},\;\color{red}{\theta}\bigr) \uparrow \;\Longrightarrow\; \color{brown}{\Delta EU^{\phi\theta}} \uparrow \text{ (relative to } \color{brown}{\Delta EU^\phi}\text{)}$ | High correlation between customer satisfaction and operational execution (ρ) - dress condition, delivery timing, and cleaning quality were crucial to market success, leading to integrated testing of full service |

Based on the image, it shows the $\color{brown}{EU}$ calculations for three different states: integral learning ($\color{brown}{EU}^{\color{red}{i}}$), modular learning ($\color{brown}{EU}^{\color{green}{m}}$), and original/baseline ($\color{brown}{EU}^{\text{o}}$). For each state, the expected utility is calculated as the product of the means ($\color{blue}{\mu}$) of two parameters: $\color{green}{\phi}$ and $\color{red}{\theta}$. The summation formula ($\color{brown}{\Sigma}_{\color{brown}{k}=1}^{\color{brown}{K}}$) indicates that this is averaged across K samples for each state. In the first equation for $\color{brown}{EU}^{\color{red}{i}}$, it uses the integral learning samples $(\color{green}{\phi_{\color{brown}{k}}^{\color{red}{i}}}, \color{red}{\theta_{\color{brown}{k}}^{\color{red}{i}}})$. For $\color{brown}{EU}^{\color{green}{m}}$, it uses the modular learning samples $(\color{green}{\phi_{\color{brown}{k}}^{\color{green}{m}}}, \color{red}{\theta_{\color{brown}{k}}^{\color{green}{m}}})$. And for $\color{brown}{EU}^{\text{o}}$, it uses the original/baseline samples $(\color{green}{\phi_{\color{brown}{k}}^{\text{o}}}, \color{red}{\theta_{\color{brown}{k}}^{\text{o}}})$. This mathematical setup allows us to compare the expected utilities across different learning strategies (integral vs modular) against the baseline, which ultimately helps determine which learning approach is more advantageous through the delta_delta_EU calculation we discussed earlier.




| Hypothesis                                 | Key Tradeoffs (CFO)                                                                                                                                                                                                                                                         |
| ------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| H1a & H1b (Market Potential φ Uncertainty) | **Criticality**: Higher uncertainty in φ increases importance of market testing<br>**Opportunity Cost**: Favors cheaper modular "idea-first" approach<br>**Fidelity**: May still need integrated testing if correlation with θ is high                                      |
| H2 (Implementation Capability θ)           | **Fidelity**: High θ suggests integrated testing could yield better synergistic insights<br>**Criticality**: Strong implementation capability makes integrated approach more valuable<br>**Opportunity Cost**: Higher cost might be justified by better delivery confidence |
| H3 (Correlation ρ between φ and θ)         | **Fidelity**: Strong correlation makes integrated testing much more accurate<br>**Criticality**: High correlation increases importance of testing both together<br>**Opportunity Cost**: Higher integrated testing costs may be necessary due to interdependence            |

|                                                         | Action to Lower Entrepreneurial Testing Cost                                | Example from Rent the Runway                                                                                                                                                                                                                                                                                                                                                            |
| ------------------------------------------------------- | --------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| criticality<br>(validation)<br>$\color{green}{\phi, N}$ | Refine and narrow down the hypothesis based on market research and feedback | After conducting initial market research, Rent the Runway realized that their hypothesis about the appeal of renting designer dresses was more applicable to certain segments, such as young professionals attending formal events. This refinement helped in reducing the approximation bias.                                                                                          |
| criticality<br>(validation)<br>$\color{green}{\phi, N}$ | Increase testing sample                                                     | Initially, Rent the Runway conducted a small pilot trial by inviting 100 students from a single university. After observing promising results, they expanded the trial to include 1000 students from multiple Ivy League universities to gather more comprehensive data.                                                                                                                |
| fiedelity<br>(verification)<br>$\color{red}{\theta}$    | Specialize customer segment                                                 | Initially targeting a broad audience of women, Rent the Runway refined their target segment to young professionals attending formal events. They collaborated with designers to curate a collection specifically appealing to this segment, ensuring the dresses matched current fashion trends and preferences of young women in Ivy League universities.                              |
| fiedelity<br>(verification)<br>$\color{red}{\theta, M}$ | Increase experiment time or resource                                        | Rent the Runway initially offered a limited collection of 130 dresses for a single event. To optimize their offerings and understand customer preferences better, they expanded their collection to 1000 dresses and extended the rental period. They also introduced options for multiple events, allowing customers to rent for occasions like weddings, galas, and corporate events. |
| opportunity cost<br>$\color{blue}{\phi, \theta, N, M}$  | Design experiments with low upfront costs utilizing reachable resource      | Instead of immediately investing in a large inventory, Rent the Runway initially collaborated with local designers and fashion schools in Boston. They borrowed dresses for their trials, reducing upfront costs. This allowed them to test the market demand without a significant initial investment.                                                                                 |



<img width="911" alt="image" src="https://github.com/Data4DM/BayesSD/assets/30194633/937c609f-7710-47e6-8869-e581d301ac43">

Entrepreneurs test hypotheses about value creation and capture from their ideas. However, due to high complexity and dynamics of startup operations, crystallizing hypothesis (what) and experiment (how) are challenging. Rent the Runway's founders Jennifer Hyman and Jennifer Fleiss were one of the few who tested key value creation hypotheses, in a systematic, rapid, and cost-effective manner. Critical hypothesis of their business were (1) college students and young professionals would find renting previously worn designer gowns superior to purchasing those dresses new, (2) dresses would, in most cases, be returned by customers in an acceptable condition such that after dry cleaning, they could be rented again, and (3) leading designers would not only be amenable to their dresses being rented but also would partner with a young startup to enable this new avenue. Before fully committing to their idea, the founders sought insights from renowned designers, leading them to pivot from working directly with designers to becoming a new distribution channel for them. They also conducted targeted experiments at universities, with the constructive feedback guiding their strategic direction and validating their idea's worth.

With the purpose of supplying testing tools for entrepreneurs, we apply Bayesian workflow (BW) to add structure to entrepreneurs testing. BW introduces how to build statistical model from ground zero, adding inference, and checking/improvement, along with the comparison of diﬀerent models, not just for the purpose of model choice or model averaging but more importantly to better understand these models. 

 We start by defining optimality measure of experiment $\theta$ and hypothesis $\phi$ testing as:
$\mathcal{O}(\theta, \phi)=\frac{1}{ {ValidApproxBiasCost(\phi)} + {ValidStatBiasCost(\phi, N)}} \times \frac{1}{{VerifApproxBiasCost(\theta|\phi) +  {VerifConvgCost}}(\theta|\phi, M)} \times \frac{1}{{OpportunityCost}(\theta, \phi, N, M)} (1)$

(1) starts from a heuristic measure, Criticality X Fidelity / Opportunity Cost, introduced in 15.911, Entrepreneurial Strategy by Scott Stern. Each components are defined as "how much does the ideal version of this test (measured accurately and at low cost) meaningfully reduce uncertainty surrounding the core value creation and capture hypotheses? (Criticality)",  "Is there a (reasonable cost) test with a reasonable level of accuracy and precision? (Fidelity)",  "What are the resource, time, and strategic costs of an experiment? (How much) is there a tradeoff between faster, better, and cheaper? (Opportunity cost)".  

Connecting this with verification and validation developed in simulation[^1], product management[^2], software development [^3], scientific theory[^4] literature, criticality is validation test asking "are we making the right product?" whereas Fidelity is verification test asking "are we making the product right given that (or sometimes before knowing) we are making the right product?". Optimal testing is characterized with critical hypothesis, high fidelity, low opportunity. Statistical, approximation, optimization bias as three components of inductive bias from machine learning [^5]  literature is a useful framework to capture the tradeoff between the three, which is why we frame hypothesis criticality and fidelity as bias. Entrepreneurs take action to decrease associated cost. Table 1 introduces the definition of the costs.  

To test a pair of experiment and hypothesis, we can use conditional probability $p(\theta, \phi) = p(\phi) p(\theta|\phi)$. In other words, hypothesis $\phi$ and experiment $\theta$ joint distribution is sequentially tested. The first term of (1) is related to pure hypothesis $p(\phi)$ and second  term is related to experiment conditional on hypothesis  $p(\theta|\phi)$. Interpretation is, given that we have set the critical hypothesis for business, how faithful is the experiment to answer the hypothesis? Testing can also happen in $p(\theta) p(\phi|\theta)$ sequence. $p(\phi|\theta)$ means given that we have a faithful experiment to test any hypothesis, what is the critical hypothesis to ask? Both works, but let's focus on a more natural testing procedure, which first nail hypothesis then move on to experiment.

Table 1: Definition of Costs associated with Entrepreneurial Experiment $\theta$ to Test Hypothesis $\phi$

| -                   | def (related concept in E-strategy)                                                                                                                                         |
| ------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ValidApproxBiasCost($\theta$) | Cost of approximation bias caused by approximating utility with testing hypothesis $\phi$                                                                                                                                                                              |
| ValidStatBiasCost($\theta, N$)   | Cost of statistical bias caused by approximating utility of beachhead customer population with that of N sampled customers |
| VerifApproxBiasCost($\theta$ \| $\phi$) | Cost of approximation bias caused by approximate testing hypothesis $\phi$ with designed experiment $\theta$                 |
| VerifConvgBiasCost($\theta$\| $\phi, M$)  | Cost of optimization bias caused by limited resource (represented as time $M$) early stops experiment $\theta$ to test $\phi$ before reaching to the optimal         |
| OpportunityCost($\theta, \phi, N, M$)     | Resource, time, and strategic costs of an experiment $\theta$ to test hypothesis $\phi$                                                                                                                       |

Table 1 lists costs associated with entrepreneurial experiment $\theta$ to test hypothesis $\phi$. The first component of criticality or validation is ${ValidStatBiasCost(\phi, N)}$. It is from statistical bias caused by approximating utility of beachhead customer population with that of N sampled customers. The second is ${ValidApproxBiasCost(\phi)}$ which is from approximation bias caused by approximating utility with testing hypothesis $\phi$. 

The first component of fidelity or verification is ${VerifApproxBiasCost(\theta|\phi)}$ which is from approximation bias caused by approximate testing hypothesis $\phi$ with experiment $\theta$. The second is ${VerifConvgBiasCost(\theta|\phi, M)}$ induced from optimization bias.  This is due to limited resource (represented as time $M$) early stops experiment $\theta$ to test $\phi$ before reaching to the optimal. Decomposition of ${VerifConvgBiasCost(\theta|\phi, M)}$ and ${VerifApproxBiasCost(\theta|\phi)}$ builds on the two distinct phases of iterative simulation: initial mixing of sequences towards the target distribution, often likened to "learning" or information propagation from the model to inferences, and the subsequent movement within that target distribution. Uncertainty of the first phase is epistemic and second is aleatoric. The first phase can represent a current state of knowledge, especially in scenarios where new information is being acquired or when tracking a changing process, while the second phase can be interpreted directly as inherent uncertainty of model parameter or time variability. An example of this is the study of radon gas exposure[^6], where high uncertainty in home radon levels was observed, even conditional on geographic data, and these levels were known to fluctuate over time[^7]. 

${OpportunityCost(\theta, \phi, N, M)}$ is a function of $\theta, \phi$ and is a resource, time, and strategic costs of an experiment $\theta$ to test hypothesis $\phi$. Notice the first two costs are closer to demand side and last three costs are closer to supply side. 

Increasing the N decreases the ${ValidStatBiasCost(\phi, N)}$, but increases ${OpportunityCost(\theta, \phi, N, M)}$ capturing the first tradeoff.  Increasing the M decreases the ${VerifConvgBiasCost(\theta|\phi, M)}$, but increases ${OpportunityCost(\theta, \phi, N, M)}$ capturing the second tradeoff.  Less specified hypothesis $\phi$ on customer, technology, organization, competition may increase ${VerifConvgBiasCost(\theta|\phi, M)}$, but generality of the test result may decrease  ${OpportunityCost(\theta, \phi, N, M)}$ capturing the third tradeoff. 


---

Table 2 presents actions to lower cost component from optimality measure of experiment $\theta$ and hypothesis $\phi$ testing,.

Table 2: Actions to Lower Costs with Examples

| -                                        | action to lower Entrepreneurial testing cost                                | example from Rent the Runway                                                                                                                                                                                                                                                                                                                                                            |
| ---------------------------------------- | --------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ValidApproxBiasCost($\theta$)            | refine and narrow down the hypothesis based on market research and feedback | After conducting initial market research, Rent the Runway realized that their hypothesis about the appeal of renting designer dresses was more applicable to certain segments, such as young professionals attending formal events. This refinement helped in reducing the approximation bias.                                                                                          |
| ValidStatBiasCost($\theta, N$)           | increase testing sample                                                     | Initially, Rent the Runway conducted a small pilot trial by inviting 100 students from a single university. After observing promising results, they expanded the trial to include 1000 students from multiple Ivy League universities to gather more comprehensive data.                                                                                                                |
| VerifApproxBiasCost($\theta$ \| $\phi$)  | specialize customer segment                                                 | Initially targeting a broad audience of women, Rent the Runway refined their target segment to young professionals attending formal events. They collaborated with designers to curate a collection specifically appealing to this segment, ensuring the dresses matched current fashion trends and preferences of young women in Ivy League universities.                              |
| VerifConvgBiasCost($\theta$\| $\phi, M$) | increase experiment time or resource                                        | Rent the Runway initially offered a limited collection of 130 dresses for a single event. To optimize their offerings and understand customer preferences better, they expanded their collection to 1000 dresses and extended the rental period. They also introduced options for multiple events, allowing customers to rent for occasions like weddings, galas, and corporate events. |
| OpportunityCost($\theta, \phi, N, M$)    | design experiments with low upfront costs utilizing reachable resource      | Instead of immediately investing in a large inventory, Rent the Runway initially collaborated with local designers and fashion schools in Boston. They borrowed dresses for their trials, reducing upfront costs. This allowed them to test the market demand without a significant initial investment.                                                                                 |

These examples provide a more in-depth look into the strategic decisions Rent the Runway might have made during its early stages, showcasing the trade-offs and considerations in entrepreneurial testing.


 ---


## 2. Bayesian workflow to Entrepreneurial testing (tbc)

SOME MAY BE WRONG

|           |                            | Bayesian workflow                                                        | Entrepreneurial testing                                                                   | example from Rent the Runway                                                                                        |                                                                                                             |
| --------- | -------------------------- | ------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- |
|     generator      | $p(\phi)$                  | Prior distribution of strategic choices                                  | Initial assumptions or beliefs about strategic choices                                    | Initial belief about the target market segment (e.g., young professionals)                                          |                                                                                                             |
|           | $p(\theta                  \| \phi)$                                                                   | Conditional distribution of product given strategic choice                                | Probability distribution of product offerings given a strategic choice                                              | Probability distribution of gown types/styles offered given the target market segment                       |
|           | $p(y                       \| \theta, \phi)$                                                           | Likelihood of observing data given product and strategic choice                           | Probability of observing certain business outcomes given product and strategic choice                               | Probability of specific rental patterns given the gown offerings and target market segment                  |
| joint     | $p(\theta, \phi, y)$       | Joint distribution of strategic choice, product, and observables         | Combined view of strategic choices, product offerings, and observed outcomes              | Combined view of target market segment, gown offerings, and actual rental patterns                                  |                                                                                                             |
| estimator | $\hat{\theta}, \hat{\phi}$ | Estimated values of product and strategic choice parameters              | Estimated values of business model features based on observed data                        | Estimated optimal gown offerings and target market segment based on observed rental data                            |                                                                                                             |
|           | $p(\theta                  \| \phi, y)$                                                                | Conditional distribution of product given strategic choice and observed data              | Updated probability distribution of product offerings given strategic choice and observed outcomes                  | Updated probability distribution of gown offerings given observed rental patterns and target market segment |
|           | $p_A(\theta \|\phi, y)$    | Approximate representation of conditional distribution by approximator A | Approximate understanding of product offerings based on limited data and strategic choice | Preliminary understanding of optimal gown offerings based on initial feedback and target market segment             |                                                                                                             |
|           | $p^*(y \| \theta, \phi)$                                                           | True data-generating distribution given product and strategic choice                      | True demand or market behavior given product offerings and strategic choice                                         | Actual demand for gown rentals given the gown offerings and target market segment                           |
|           | $t(y), u(y)$               | Testing function and utility function based on observed data             | Proxy measures of business success or profitability based on observed outcomes            | Proxy measures like customer satisfaction, repeat rentals, and customer referrals based on observed rental patterns |                                                                                                             |

This table integrates the Bayesian workflow with the entrepreneurial testing process, drawing parallels between the two and providing examples from Rent the Runway's business model and strategies. Fig1 shows, on its left, three major diagnostics (prior predictive check, simulation-based calibration[^8], posterior predictive checks) in red. The right describes how hierarchical model can be used to generate data on quantities of interest.

Fig1. Three diagnostics and its application to entrepreneurial testing 
<img width="1197" alt="image" src="https://github.com/Data4DM/BayesSD/assets/30194633/02cf6a7b-4ce7-4d21-92df-e262b0908fa5">

## Reference

[^1]: Law, A. M., Kelton, W. D., & Kelton, W. D. (2007). _Simulation modeling and analysis_ (Vol. 3). New York: Mcgraw-hill.
[^2]: Ulrich, K. T., Eppinger, S. D., & Yang, M. C. (2008). _Product design and development_ (Vol. 4, pp. 1-3). Boston: McGraw-Hill higher education.
[^3]:  Adrion, W. R., Branstad, M. A., & Cherniavsky, J. C. (1982). Validation, verification, and testing of computer software. _ACM Computing Surveys (CSUR)_, _14_(2), 159-192.
		Boehm, B. W. (1988). A spiral model of software development and enhancement. _Computer_, _21_(5), 61-72.
		Boehm, B. W., & Papaccio, P. N. (1988). Understanding and controlling software costs. _IEEE transactions on software engineering_, _14_(10), 1462-1477.
[^4]: Box, G. E., & Youle, P. V. (1955). The exploration and exploitation of response surfaces: an example of the link between the fitted surface and the basic mechanism of the system. _Biometrics_, _11_(3), 287-323.
[^5]: Mohri, M., Rostamizadeh, A., & Talwalkar, A. (2018). _Foundations of machine learning_. MIT press.
Bronstein, M. M., Bruna, J., Cohen, T., & Veličković, P. (2021). Geometric deep learning: Grids, groups, graphs, geodesics, and gauges. _arXiv preprint arXiv:2104.13478_.
[^6]: Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). _Bayesian data analysis_. Chapman and Hall/CRC.
[^7]: Gelman, A. (2004). Parameterization and Bayesian modeling. _Journal of the American Statistical Association_, _99_(466), 537-545.
[^8]: Modrák, M., Moon, A. H., Kim, S., Bürkner, P., Huurre, N., Faltejsková, K., ... & Vehtari, A. (2022). Simulation-based calibration checking for Bayesian computation: The choice of test quantities shapes sensitivity. _arXiv preprint arXiv:2211.02383_.

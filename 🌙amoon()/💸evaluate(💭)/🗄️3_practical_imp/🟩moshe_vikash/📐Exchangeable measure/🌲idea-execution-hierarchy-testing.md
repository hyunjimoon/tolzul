2025-04-11
## Research Comparison Version

| Aspect                  | üå≤ **Hierarchical Testing (Moon)**                                                | üóûÔ∏è **Newsvendor Model (Scarf)**                                                      | **Cognitive/Managerial Interpretation**                                                                                                                                                 |
|-------------------------|-----------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Decision Variable**   | **Pilot sample size (n):** \(n \in \mathbb{N}\) is the number of trials in the pilot (test batch size). It‚Äôs the decision variable that the entrepreneur optimizes to maximize expected utility of their testing strategy (e.g., choose n* to maximize ŒîEU(n)). | **Order quantity (Q):** \(Q \in \mathbb{N}\) is the number of units to order/produce. It‚Äôs the decision variable the manager chooses to maximize worst-case expected profit (the robust newsvendor chooses Q* for maximum guaranteed profit given mean/variance info). | **n ‚Üî Q as analogous levers:** Mathematically, n and Q play similar roles as control variables in each model‚Äôs optimization problem. The entrepreneur‚Äôs n* (optimal pilot size) is conceptually analogous to the retailer‚Äôs Q* (optimal stock level) ‚Äî both are chosen by balancing costs and benefits under uncertainty. *Interpretation:* For a venture, this means the **extent of initial testing** (how many users or prototypes) corresponds to **initial output commitment** (how much product to make). In both cases, the decision-maker is tuning a single parameter to navigate uncertainty: a larger n or Q represents a more aggressive commitment expecting high demand, whereas a smaller n or Q is a conservative choice. |
| **Stopping/Order Rule** | **Optimal stopping criterion:** The entrepreneur increases n until the point where **marginal info gain = marginal cost**. Formally, Moon‚Äôs Proposition¬†3 sets \(\frac{d}{dn}\Delta EU(n) = 0\), leading to the condition: \[ \frac{\alpha^2}{(Œ±+n)^2}(Œº - œÜ_{true}) = c_y, \] where the LHS is the marginal increase in expected utility from reducing uncertainty (proportional to the variance reduction and the gap between true and expected viability) and RHS is the marginal cost of adding a test. Solving this gives n* (optimal pilot size). In practical terms, the stopping rule is: *‚ÄúStop adding more test subjects when this equality holds,‚Äù* i.e., when an extra pilot unit no longer improves the expected outcome. At n*, the entrepreneur would make the go/no-go launch decision based on the evidence gathered. | **Optimal order condition:** The newsvendor chooses Q* such that **marginal expected profit of an extra unit = marginal expected loss** under the worst-case demand distribution. Scarf‚Äôs distribution-free solution finds that the *critical fractile* at Q* equals \(\frac{m}{m+d}\) (where m is mark-up, d is discount/loss fraction). In effect, Q* satisfies the condition that the probability of selling one more unit (in worst-case terms) equals the cost ratio: \[ P(D > Q^*) \approx \frac{c - s}{(p-c) + (c-s)} = \frac{d}{m+d}, \] (and \(P(D \le Q^*) = \frac{m}{m+d}\)). Scarf showed the worst-case demand can be taken as a two-point distribution at a low and high value around Q*, making this condition optimal. Thus, the order rule is: *‚ÄúOrder up to Q* where the risk of overstock equals the risk of understock in the worst case.‚Äù* In practice Q* can be computed in closed form (e.g., for no initial inventory, \(Q^* = Œº + \sqrt{\frac{m}{m+d}}\,œÉ - \sqrt{\frac{d}{m+d}}\,œÉ\) as derived from the two-point extremal distribution). | **Equating marginal trade-offs:** Both models derive a **decision threshold by balancing opposing forces**. The testing model sets \( \text{marginal info gain} = \text{marginal cost} \) at n*, preventing over-testing. The inventory model sets \( \text{marginal overage risk} = \text{marginal underage risk} \) at Q*, preventing overstocking or understocking bias. *Interpretation:* A venture manager can see these as analogous rules: stop experimentation when additional data would no longer significantly improve the decision (just as an inventory planner stops ordering when additional stock would likely sit unsold). Both result in a clear cutoff (n* or Q*) that signals the optimal point to switch strategies ‚Äî for the entrepreneur, to stop testing and either launch or abandon, and for the manager, to finalize the order quantity. This highlights a common cognitive strategy: **set a cutoff where incremental benefit = incremental cost**, ensuring a rational decision boundary in uncertain conditions. |
| **Uncertainty Representation** | **Bayesian with known prior:** The hierarchical testing model assumes an uncertain market parameter œÜ (e.g., true demand or conversion rate). Prior distribution for œÜ is given (with mean Œº and prior precision related to Œ±). As data from n trials come in, the posterior distribution of œÜ is updated (variance shrinking roughly on the order of 1/(Œ±+n)). Uncertainty is explicitly quantified and reduced via sampling. For example, initial Var(œÜ) is high for small Œ±, but after n observations, Var(œÜ|data) decreases, informing the decision. The model leverages this learning in computing expected utilities of strategies (GMT vs MVT). | **Distribution-free (minimax) uncertainty:** The Scarf newsvendor model does *not* assume a specific demand distribution ‚Äì it only uses limited information (E[D]=Œº, Var(D)=œÉ¬≤, support non-negative). Uncertainty is represented by considering the worst-case distribution in that ambiguity set. Specifically, the worst-case is proven to be a two-point distribution that achieves the variance œÉ¬≤ while centered on Œº. Thus, instead of updating a belief, the manager assumes nature could adversarially pick demand at two extreme values. This yields a robust decision that is immunized against any distributional form in that moment class. No learning occurs (it's a single-period decision), but the solution is ‚Äúsafe‚Äù for all distributions with those moments. | **Unknowns handled differently, but both acknowledge risk:** *Mathematically*, Moon‚Äôs model treats uncertainty in a **probabilistic, learnable** way (œÜ is a random variable with a prior ‚Üí posterior), whereas Scarf‚Äôs rule treats uncertainty in a **worst-case deterministic** way (demand distribution is unknown ‚Üí consider the extreme case). *Interpretation:* For venture managers, the Bayesian approach corresponds to **learning-by-doing** ‚Äì you have an initial guess about the market and you refine it through testing. The distribution-free approach corresponds to **robust planning** ‚Äì assuming you only have a rough idea of demand, you prepare for volatility without expecting to learn more before deciding. In practice, a startup might actually use both modes: during a pilot they update their confidence in market size (Bayesian learning), but when making an one-time production decision with little data, they might use conservative worst-case assumptions. Both approaches underscore a key managerial insight: **make decisions with the uncertainty model you have** ‚Äì if you can gather data, do so and update (like Moon), if not, acknowledge the ambiguity and err on the side of caution (like Scarf). |
| **Asymmetric Cost Logic**    | **Cost asymmetry in ŒîEU(n):** Moon‚Äôs Proposition¬†3 formula \(\frac{Œ±^2}{(Œ±+n)^2}(Œº - œÜ_{true}) - c_y\) shows how the sign of \(Œº - œÜ_{true}\) drives the effect of increasing n. Here, \(Œº - œÜ_{true}\) captures an optimism bias: if positive (Œº > œÜ<sub>true</sub>), the entrepreneur is overestimating true potential, meaning the risk of a false positive (investing in a non-viable venture) is high. If negative (Œº < œÜ<sub>true</sub>), they‚Äôre underestimating potential (risk of false negative, missing a good opportunity). The term \(c_y\) is the per-unit test cost, representing the cost of exploration. A large positive \(Œº - œÜ_{true}\) combined with low \(c_y\) makes the marginal gain term dominate, implying testing more (larger n) is favorable to correct the overestimation risk. Conversely, if \(Œº - œÜ_{true}\) is small or negative (little upside or underestimation scenario) or \(c_y\) is high, the net benefit of increasing n diminishes or turns negative, suggesting a smaller pilot. In summary, Moon‚Äôs model encodes asymmetric consequences of errors: one side of the equation is the ‚Äúvalue of information‚Äù (driven by how wrong your demand guess might be), the other is the direct cost of that information. The optimal n balances these, effectively minimizing the more costly error (over-investment vs. under-investment) in expectation. | **Cost asymmetry in newsvendor:** The classic newsvendor costs: underage cost = \(p-c\) (lost profit per unit if demand > Q), overage cost = \(c-s\) (loss per unit if demand < Q, i.e., unit cost minus salvage). In Scarf‚Äôs formulation, these appear as parameters m and d (with \(p = c(1+m)\), \(s = c(1-d)\), so \(p-c = c m\), \(c-s = c d\)). The **critical ratio** \(\frac{m}{m+d}\) in the optimality condition directly stems from these asymmetric costs. If \(m > d\) (profit margin exceeds leftover loss), the solution skews toward higher service level (stock more, since shortage is worse than excess). If \(m < d\) (leftover cost is worse), it skews toward a lower service level (stock less). In distribution-free context, this asymmetry still governs the two-point worst-case distribution‚Äôs mass allocation: the probability on the low-demand point is \(\frac{m}{m+d}\) (heavier weight if understocking is costlier), and on the high-demand point is \(\frac{d}{m+d}\). Thus, the robust optimum protects against the more expensive mistake (be it too much or too little stock). The outcome is analogous to the classical newsvendor: order above Œº when \(p-c > c-s\) (underage cost > overage cost), or below Œº when the reverse. | **Balancing ‚Äúfear of missing out‚Äù vs ‚Äúfear of waste‚Äù:** Both models incorporate an asymmetry that tilts the decision one way or the other. *Mathematically,* the sign of \(Œº - œÜ_{true}\) (with cost \(c_y\)) in Moon‚Äôs model plays a similar role to the comparison of \(m\) vs. \(d\) in Scarf‚Äôs model ‚Äî they determine which side (overestimation vs. underestimation) is riskier to the decision-maker. *Interpretation:* For an entrepreneur, \(Œº - œÜ_{true}\) > 0 means they are likely overestimating demand (the venture‚Äôs ‚Äúgut feel‚Äù exceeds reality), so the costliest error would be to assume success and be wrong (analogous to overstocking inventory that doesn‚Äôt sell). Moon‚Äôs guidance in that case is to gather more evidence (large n) to avoid a costly false positive. In inventory terms, a high \(m\) (profit margin) means running out of stock is very costly (the worst error is missing sales), so the newsvendor logic is to order more to avoid a false negative on demand. On the flip side, if an entrepreneur‚Äôs expectations are lower than the true potential (Œº < œÜ<sub>true</sub>) ‚Äì they risk a false negative (not fully pursuing a good idea, like under-ordering), whereas a high \(d\) (high overage cost) for a retailer means the worst error is having unsold product (false positive in demand). Both models would then err on caution: Moon‚Äôs entrepreneur would keep the test small (don‚Äôt over-spend if you might be underestimating anyway, better to gradually scale), and Scarf‚Äôs retailer would order conservatively. **In essence**, each framework urges decision-makers to identify which mistake (overcommitting or undercommitting) carries the greater cost in their context and adjust their strategy accordingly. This cognitive step ‚Äî *understanding your cost asymmetry* ‚Äî is central in entrepreneurial decision-making just as it is in inventory management, ensuring the strategy is aligned with what‚Äôs truly at stake. |
This table provides a direct comparison showing how both frameworks led TAXIE to the decision to test with 3 EVs - an optimal balance between information gain and resource conservation based on their specific cost structure and prior beliefs.

## Hierarchical Testing - Mathematical Definition

Hierarchical testing is formally defined as a structured approach to hypothesis testing where:

$J = \mu \cdot \alpha \cdot C_1 + (1-\mu) \cdot \beta \cdot C_2$

Where:

- $J$ = Expected cost of errors
- $\mu$ = Prior probability that the hypothesis is true
- $\alpha$ = Probability of Type I error (false positive)
- $C_1$ = Cost of Type I error (accepting a false hypothesis)
- $\beta$ = Probability of Type II error (false negative)
- $C_2$ = Cost of Type II error (rejecting a true hypothesis)

In hierarchical testing, hypotheses are ordered based on:

1. Their information dependencies (some tests inform others)
2. The expected cost reduction from resolving uncertainty
3. The relative magnitudes of $C_1$ and $C_2$ for each hypothesis

## Hierarchical Testing - Intuitive Definition

Think of hierarchical testing like building a house:

You need to build the foundation before the walls, and the walls before the roof. Some parts of a project naturally come before others because they support everything else.

Hierarchical testing is about figuring out the right order to test your ideas so that:

1. You test the most fundamental ideas first
2. You learn the most important information early
3. You avoid wasting time on details if the basics don't work
4. Each test helps you decide whether to continue or stop

It's like asking, "If this core idea fails, does anything else matter?" If the answer is no, test that idea first.

## Why H4 and H1 Have Lower Cumulative Costs

For TAXIE, H4 (charging infrastructure) and H1 (range sufficiency) have lower cumulative costs for several key reasons:

1. **Foundation Hypotheses**: Both represent fundamental requirements without which the business cannot function. If Boston's charging infrastructure is insufficient (H4) or if the 200-mile range isn't enough for rideshare shifts (H1), the entire business model collapses.
    
2. **Lower Testing Costs**: Both can be tested with just 2-3 vehicles, requiring minimal capital investment (~$300K vs. millions for later hypotheses).
    
3. **Directly Observable Outcomes**: Both produce clear, unambiguous data that doesn't require extensive interpretation:
    
    - For H4: Either drivers can find charging stations when needed or they can't
    - For H1: Either the vehicles complete shifts without running out of charge or they don't
4. **Error Cost Asymmetry**:
    
    - For H4: The cost of a Type I error (falsely believing charging infrastructure is sufficient) is extremely high as it could strand drivers and customers
    - For H1: The cost of a Type I error (falsely believing 200 miles is sufficient) could result in stranded vehicles and severe operational issues
5. **Information Value for Other Hypotheses**: Testing these first provides valuable inputs for later hypotheses:
    
    - If H4 fails, there's no need to test any other hypotheses
    - If H1 fails, it informs vehicle selection before testing business model profitability (H6)

By testing H4 and H1 first, TAXIE follows the hierarchical testing principle of minimizing expected error costs. If either fails, TAXIE can exit the venture having spent only ~$300K instead of the millions that would be required to test all hypotheses.

This is particularly important for a resource-constrained startup like TAXIE, which needs to find the most efficient path to either validate their business model or fail fast with minimal resource expenditure.
abstract: 
# 1🏳️‍🌈Entrepreneurial Decision-Making Reimagined

Entrepreneurial decision-making today often feels like being handed the wrong tools for the journey. Imagine navigating with a compass that only points north, a map drawn for someone else’s terrain, or a desert survival guide while you’re actually in a jungle. Much of the advice entrepreneurs receive—however well-intentioned—resembles these misfit guides. It offers a single direction (e.g. _maximize profit at all costs_), a borrowed map, or context-blind tips that can lead founders astray in their own unique venture terrain.

These aren’t just colorful metaphors – they echo real situations observed across diverse innovation ecosystems. In discussions with dozens of stakeholders (entrepreneurs from different culture, vision, capability, investors (Engie, Flagship Pioneering, Entegris, Bass, Sazze, 500 Global), educators from universities MIT (U.S.), HPI (Germany), A*STAR (Singapore), SNU (Korea) investors), I found case after case of guidance failing when it ignored context. For instance, MIT’s Technology Licensing Office often urges patenting as a default strategy – a great north star in biotech, but a false lead for climate-tech ventures that thrive on open collaboration. Similarly, the now-canonical **customer-centered** playbook works brilliantly for consumer apps, yet I saw it misfire in domains like advanced cancer diagnostics where demand is assured and technical validation is the real hurdle. I heard of founders from wealthy families who skipped the frantic early fundraising that standard advice assumes – with personal capital or patient backers, their priorities lay in product and partnership, not pitching every quarter. Even team-building norms varied wildly: Silicon Valley’s “**hire fast, fire fast**” mantra falls flat in East Asian contexts that prize loyalty and gradual growth. And within the U.S., East Coast startup hubs often follow a tight-knit “village” model of mentorship, unlike the West Coast “valley” ethos of blitzscaling. Finally, when the macroeconomic climate shifts into a downturn, yesterday’s winning playbook can become today’s wrong map – underscoring that any guidance must adapt to new terrain or risk leading entrepreneurs off course.

All these cases point to the need for a fundamentally different approach to guiding entrepreneurial decisions. Instead of relying on a static map and a one-dimensional compass, entrepreneurs need the equivalent of a **GPS that dynamically combines sensor and motion** – in other words, a navigation system that adapts in real time to the founder’s perspective and surroundings. Concretely, I identify three core needs at the heart of such an adaptive system: 📽️ **Perception** – the ability to clearly sense and interpret how different stakeholders view the venture; 🔄 **Coordination** – the capacity to align and synergize these stakeholders’ actions and expectations; and ⚡ **Sequencing** – the foresight to take the right steps in the right order under resource constraints. These three needs form the backbone of our framework. In the following **Need Analysis** and **Solution Design** sections, I delve into each need and show how a rigorous decision model can function as that adaptive entrepreneurial GPS, dynamically guiding founders through ever-changing terrain with evidence-based clarity and precision.

I apply this framework first to the mobility sector because it naturally activates all three pillars: perception, coordination, and sequencing. Mobility ventures require complex, multi-stakeholder alignment across regulators, infrastructure partners, and technology providers—making them ideal for testing coordination strategies under real-world constraints. Their moderate clockspeed—slower than software but faster than heavy industry—grants entrepreneurs time to strategically sequence experiments without being overtaken by market shifts. The sector’s remarkable breadth, from batteries and micromobility to aviation and public transit, allows us to validate generalizability across heterogeneous contexts. Crucially, mobility sits at the intersection of AI, robotics, and climate tech—fast-evolving, signal-rich domains that challenge our ability to model stakeholder perception under uncertainty. These qualities make mobility ventures not just an appropriate case, but a high-leverage proving ground for adaptive, evidence-based decision support.

---

# 2💭Need Analysis

## 2. Need Analysis - STRAP Framework

### 2.1 Entrepreneurial Decision-Making Under Uncertainty Literature Review

This section introduces the fundamental challenge: entrepreneurs lack decision making model that is personalized, realistically tractable, actionable — promoting imitating other's behavior and unsystematic experimenting that lowers entrepreneuring quality.

Entrepreneurial decision models span a spectrum of complexity defined by two key dimensions: **operational complexity** (decisions unfolding over time) and **multi-stakeholder complexity** (multiple interacting agents or criteria). At the simplest end of this spectrum are single-stakeholder static strategy models, which consider a one-off strategic choice by a lone decision-maker. These simple models are highly tractable but offer poor reality fit, since they ignore dynamic feedback and the involvement of other stakeholders (e.g., Sarasvathy, 2001; McMullen & Shepherd, 2006). Increasing the operational complexity yields single-stakeholder dynamic models that incorporate sequences of decisions and learning over time. Such models capture how an entrepreneur adapts through multiple stages (for instance, via staged investment or real options reasoning) while still focusing on one primary actor (Håkansson, 1971; McGrath, 1999).

To better reflect real venture conditions, other models introduce **multi-stakeholder complexity** even in static settings. These multi-stakeholder strategy models consider how an entrepreneur coordinates or negotiates with various actors (investors, customers, competitors) within a single decision context, adding richer criteria to the choice (Gans, Hsu & Stern, 2002; Van den Steen, 2016). This boosts reality fit by acknowledging diverse interests, but tractability remains manageable only because the decision is not sequential. The most comprehensive models embrace both interacting stakeholders and dynamic operations, portraying entrepreneurship as an ongoing process co-created with partners, markets, and investors (Schindehutte & Morris, 2009; Garud & Karnøe, 2003; Roundy, 2018). These high-complexity models achieve a strong fit to entrepreneurial reality (phenomenological richness) but become computationally intractable – indeed, the full **EDMNO** formulation that accounts for all stakeholders over time is NP-complete (as shown in Section 1.1). In essence, the progression from static single-actor to dynamic multi-actor models reveals an engineering-versus-phenomenological trade-off: as I add realism, I lose tractability.

Bridging this tractability–reality gap requires new approaches that retain high reality fit while restoring usability. Rather than abandoning formal modeling, I propose an **engineering** solution that balances these extremes through targeted simplifications and optimization strategies. In this thesis, a three-part framework is introduced to tackle each complexity dimension: **phase-based learning** breaks the decision process into stages to manage operational complexity over time, **proactive hypothesis proposal** uses probabilistic experimentation to navigate multi-stakeholder uncertainty, and **calibrated federated learning** allows entrepreneurs to collectively improve models without sacrificing individual context. Together, these strategies form a mid-complexity decision framework designed to maintain realism (capturing multi-stage, multi-stakeholder dynamics) while remaining computationally tractable. This approach sets the stage for the use cases and solution scope detailed in Section 1.3, aiming to empower entrepreneurs with decision tools that match the actual challenges they face.

| Model Type                                          | Multi-Stakeholder Complexity (👥) | Dynamic Operational Complexity (🤜) | Tractability | Reality Fit | Key References                                                     | Need for New Approach (Why)                                  |
| --------------------------------------------------- | --------------------------------- | ----------------------------------- | ------------ | ----------- | ------------------------------------------------------------------ | ------------------------------------------------------------ |
| **Single-Stakeholder Static Strategy (🙋‍♀️🧐)**    | No                                | No                                  | High         | Poor        | Sarasvathy (2001); McMullen & Shepherd (2006)                      | ❌ No (simple, manageable but lacks realism)                  |
| **Single-Stakeholder Dynamic Operations (🙋‍♀️🤜)** | No                                | Yes                                 | Medium-High  | Moderate    | Håkansson (1971); McGrath (1999)                                   | ⬇️ Low (manageable by traditional methods, moderate realism) |
| **Multi-Stakeholder Static Strategy (👥🧐)**        | Yes                               | No                                  | Medium       | Moderate    | Van den Steen (2016); Gans, Hsu & Stern (2002)                     | ⬆️ Medium (requires stakeholder negotiation)                 |
| **Multi-Stakeholder Dynamic Operations (👥🤜)**     | Yes                               | Yes                                 | Low          | High        | Schindehutte & Morris (2009); Garud & Karnøe (2003); Roundy (2018) | ✅ Yes (complexity high, traditional methods strained)        |

### 2.2 The Entrepreneurial Decision-Making Need Analysis: Mathematical Mapping

In this section, we identify the root causes of entrepreneurial decision-making challenges across three levels and three dimensions, structured as a need matrix, and show how each need maps to specific elements in our mathematical formulations:

| **Level**                   | **Need 1: Perception** (📽️)                                                                                                                                                                                                                 | **Need 2: Sequencing** (⚡)                                                                                                                                                                                                                                                                        | **Need 3: Coordination** (🔄)                                                                                                                                                                                      |
| --------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **2.2.1 Nature**            | Entrepreneurial decisions must respect axioms where action sequences depend on stakeholder weights $\textcolor{purple}{W_j}$ and initial state $\textcolor{green}{S}$                                                                        | Entrepreneurial experiments require consistent constraints across sequential decisions, reflected in the transition function $D(\textcolor{green}{S},,\textcolor{red}{a}) = \textcolor{green}{S'}$                                                                                                | Multi-stakeholder decisions involve complex interdependencies in belief updates, captured in the mapping $B,\textcolor{green}{S} = [\textcolor{#3399FF}{U_d},,\textcolor{#3399FF}{U_s},,\textcolor{#3399FF}{U_i}]$ |
| **2.2.2 Stakeholder Level** | Different stakeholders perceive the same venture differently, shown by stakeholder-specific uncertainty terms $\textcolor{#3399FF}{U_j}$ and expectation constraints $\sum_{k} p_{jk} f_{jk} = \textcolor{green}{\mu_j}(\textcolor{red}{a})$ | Stakeholder uncertainty reduction requires prioritization, managed by weights $\textcolor{purple}{w_j}$ in $\sum_{j} \textcolor{purple}{w_j} H(p_j                                                                                                                                                | Circular dependencies among stakeholders create "waiting for each other" deadlocks, addressed by joint optimization of $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ expectations                                 |
| **2.2.3 Venture Level**     | Resource constraints on perception testing, formalized as $C,\textcolor{red}{A} \leq \textcolor{#8B0000}{R}$ and $\sum_{j} c_j \textcolor{red}{a_j} \leq \textcolor{#8B0000}{R}$                                                             | Intractable planning problem of experiment sequencing, addressed through the decision rule $\textcolor{red}{a_j^*} = \begin{cases} 1 & \text{if } \textcolor{purple}{w_j}[\lambda_j + \beta_j^T \textcolor{green}{\mu_j}(1) - \log Z_j(\beta_j)] > \gamma c_j \ 0 & \text{otherwise} \end{cases}$ | Information spillover opportunities across stakeholders, captured in the dual through shared likelihood terms related to $\textcolor{green}{\mu_j}(\textcolor{red}{a})$                                            |

Each cell in this matrix represents not just a conceptual challenge but also maps directly to specific mathematical elements in our formulations, connecting entrepreneurial needs to formal optimization structures:

1. **Perception Challenges** (📽️): These map to uncertainty terms $\textcolor{#3399FF}{U_j}$ in the probabilistic formulation and entropy terms $H(p_j|\textcolor{red}{a})$ in the primal-dual approach. Perception asymmetry is captured by stakeholder-specific distributions $p_j$ and expectation terms $\textcolor{green}{\mu_j}(\textcolor{red}{a})$.
    
2. **Sequencing Challenges** (⚡): These map to the resource constraints $C,\textcolor{red}{A} \leq \textcolor{#8B0000}{R}$ and action variable $\textcolor{red}{a}$, along with the state transition function $D(\textcolor{green}{S},,\textcolor{red}{a})$. The dual decision rule provides a computationally tractable approach to this otherwise NP-complete problem by determining which experiments to run based on their information value per cost. 

3. **Coordination Challenges** (🔄): These correspond to the interdependencies between stakeholder states in $B,\textcolor{green}{S}$ and the consistency constraints on expectations $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ across stakeholders. In the dual formulation, coordination is addressed through likelihood maximization that aligns all stakeholders' expectations.

Entrepreneurs struggle to understand how stakeholders perceive their ventures. Different stakeholders (investors, customers, partners) project identical startup attributes onto different perceptual dimensions, creating a fundamental information asymmetry problem.  Traditional approaches either assume perfect information or rely on intuitive reading of stakeholder signals. Our framework uses perceptual projection models to decode how observable venture attributes map to stakeholder decision spaces, enabling entrepreneurs to optimize information gathering and signal presentation. from  1.📽️Individual level of stakeholder perception problem

Entrepreneurs face circular dependencies where stakeholders make simultaneous, interdependent decisions. Investors wait for customer validation, customers require operational proof, and partners need investment signals, creating deadlock situations. Conventional methods tackle stakeholders sequentially, but this approach cannot resolve inherent circularity. Our framework enables entrepreneurs to act as central coordinators who leverage information spillovers across stakeholder networks, breaking decision deadlocks through parallel engagement strategies.  2.🔄Individual level of multi-stakeholder coordination problem


Entrepreneurs must sequence actions optimally under severe resource constraints. However, they cannot directly compute the uncertainty reduction per cost for each possible action sequence due to combinatorial explosion. Standard optimization approaches become computationally intractable as variables increase. Our bottleneck-driven framework allows entrepreneurs to make near-optimal myopic decisions by decomposing complex metrics into estimable components, focusing resources on experiments that provide maximum information value. This mapping demonstrates how our mathematical formulations capture each dimension of the entrepreneurial decision challenge. The probabilistic formulation emphasizes uncertainty minimization across stakeholders, while the primal-dual approach transforms this into maximizing stakeholder satisfaction likelihood under resource constraints. from 3.⚡Individual level of resource optimization problem

### 2.3 Probabilistic Formulation Overview

This section introduces the unified probabilistic formulation that captures all dimensions of the entrepreneurial decision problem:

$$ \begin{aligned} \min_{\textcolor{red}{a} \in \textcolor{red}{A}} \quad & \textcolor{purple}{W_d}\cdot\textcolor{#3399FF}{U_d} + \textcolor{purple}{W_s}\cdot\textcolor{#3399FF}{U_s} + \textcolor{purple}{W_i}\cdot\textcolor{#3399FF}{U_i} && \text{(Objective)} \ \text{s.t.} \quad & B,\textcolor{green}{S} = [\textcolor{#3399FF}{U_d},,\textcolor{#3399FF}{U_s},,\textcolor{#3399FF}{U_i}] && \text{(Uncertainty-State Mapping)} \ & C,\textcolor{red}{A} \leq \textcolor{#8B0000}{R} && \text{(Resource Budget)} \ & D(\textcolor{green}{S},,\textcolor{red}{A}) = \textcolor{green}{S'} && \text{(State Transition)} \end{aligned} $$

We explain how this formulation captures the three challenges: reducing uncertainty for individual stakeholders (📽️ perception), aligning multi-stakeholder dynamics (🔄 coordination), and selecting actions under resource limits (⚡ bottleneck-breaking).

### 2.4 Primal-Dual Optimization Formulation

We also present the primal-dual optimization formulation that provides complementary insights into the entrepreneurial decision problem:

**Primal (Uncertainty Minimization):** $$ \begin{aligned} \min_{p,\textcolor{red}{a}} \quad & \sum_{j \in {d,s,i}} \textcolor{purple}{w_j} H(p_j|\textcolor{red}{a}) \ \text{s.t.} \quad & \sum_{k} p_{jk} = 1, \quad \forall j \ & \sum_{k} p_{jk} f_{jk} = \textcolor{green}{\mu_j}(\textcolor{red}{a}), \quad \forall j \ & p_{jk} \geq 0, \quad \forall j,k \ & \sum_{j} c_j \textcolor{red}{a_j} \leq \textcolor{#8B0000}{R} \ & \textcolor{red}{a_j} \in {0,1}, \quad \forall j \end{aligned} $$

**Dual (Likelihood Maximization):** $$ \begin{aligned} \max_{\lambda, \beta, \gamma} \quad & \sum_{j \in {d,s,i}} \textcolor{purple}{w_j}[\lambda_j + \beta_j^T \textcolor{green}{\mu_j}(\textcolor{red}{a_j}) - \log Z_j(\beta_j)] - \gamma \textcolor{#8B0000}{R} \ \text{s.t.} \quad & \gamma \geq 0 \ & \text{where } \textcolor{red}{a_j^*} = \begin{cases} 1 & \text{if } \textcolor{purple}{w_j}[\lambda_j + \beta_j^T \textcolor{green}{\mu_j}(1) - \log Z_j(\beta_j)] > \gamma c_j \ 0 & \text{otherwise} \end{cases} \end{aligned} $$

This dual formulation provides critical insights by transforming the uncertainty minimization problem into a likelihood maximization problem—revealing how entrepreneurs can maximize the probability of stakeholder satisfaction while optimizing resource allocation.


# 3📐Solution Design

In this section, we break down the framework into its three core components – perception, coordination, and sequencing – and detail the theoretical solution approach for each. We show how the primal–dual optimization foundation applies in distinct ways to each challenge, incorporating recent advances (POMDP approximations, linear decompositions, federated learning) into the model. Each sub-section presents the mathematical model in a rigorous way and connects it to a practical startup scenario to illustrate how an entrepreneur would apply it. Throughout, we focus on three core action categories: a_segment (actions that reduce customer/demand-side uncertainty, denoted $U_{\text{demand}}$), a_collaborate (actions that reduce operational/supply-side uncertainty, $U_{\text{supply}}$), and a_capitalize (actions that reduce investor/resource-side uncertainty, $U_{\text{investor}}$). We use a single running example – the case of Segway (the personal transporter startup) – to demonstrate how each type of action addresses a different dimension of uncertainty in perception, coordination, and sequencing.
## 3. Solution Design: The STRAP Framework

### 3.1 Complementary Mathematical Frameworks

This section introduces how the STRAP framework employs two complementary mathematical approaches—probabilistic inference methods and optimization techniques—to address entrepreneurial decision challenges. We explain the power of viewing the same problems through different mathematical lenses.

### 3.2 The STRAP Solution Matrix

The following matrix presents our comprehensive solution approach across the three dimensions and three levels of entrepreneurial decision-making:

| **Level**                   | **Solution 1: Perception (📽️)**                                                                                                                                                                                                                                                                                                 | **Solution 2: Coordination (🔄)**                                                                                                                                                    | **Solution 3: Sequencing (⚡)**                                                                                                                                                                                               |
| --------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **3.2.1 Nature**            | **Inference Approach**: Initial <span style="color:green;">belief distributions</span> reflecting <span style="color:violet;">stakeholder weights</span> and <span style="color:green;">initial state</span><br><br>**Optimization Approach**: <span style="color:violet;">Value-weighted</span> success likelihood optimization | **Inference Approach**: Shared expectation modeling across stakeholders<br><br>**Optimization Approach**: Collective <span style="color:red;">action</span> probability maximization | **Inference Approach**: Planning consistent experimental trajectories<br><br>**Optimization Approach**: <span style="color:#3399FF">Resource</span>-constrained <span style="color:red;">action</span> sequence optimization |
| **3.2.2 Stakeholder Level** | **Inference Approach**: Mental model mapping to understand stakeholder decision spaces<br><br>**Optimization Approach**: Maximizing convincing power per <span style="color:#3399FF">resource unit</span>                                                                                                                        | **Inference Approach**: Federated calibration process to align expectations<br><br>**Optimization Approach**: Breaking deadlocks through joint incentive analysis                    | **Inference Approach**: <span style="color:#3399FF;">Information value</span> calculation by stakeholder<br><br>**Optimization Approach**: <span style="color:violet;">Stakeholder-weighted</span> experiment prioritization |
| **3.2.3 Venture Level**     | **Inference Approach**: Targeting maximum learning per experiment<br><br>**Optimization Approach**: Optimizing evidence acquisition within <span style="color:#3399FF">resource constraints</span>                                                                                                                               | **Inference Approach**: Multi-stakeholder signaling strategies<br><br>**Optimization Approach**: Maximizing information spillover across stakeholders                                | **Inference Approach**: Dynamic <span style="color:#3399FF;">uncertainty</span> updating after experiments<br><br>**Optimization Approach**: Linear programming relaxation for near-optimal experimental paths               |

### 3.3 📽️ Perception Component: Optimizing Stakeholder Projection and Inference

This section explains our approach to the perception challenge. We present how entrepreneurs can model stakeholder decision-making as a hierarchical Bayesian random utility process, capturing heterogeneity in perceptions and rational choice under <span style="color:#3399FF;">uncertainty</span>. We demonstrate how this approach helps entrepreneurs map venture signals into stakeholder-specific decision spaces and optimize evidence to generate maximum learning. We then explore the optimization perspective, showing how perception modeling transforms from "What does this stakeholder want?" to "What will convince them to say yes?"—a critical entrepreneurial insight that emerges from applying primal-dual optimization to perception challenges.

Problem Formulation: The perception component deals with an entrepreneur’s incomplete knowledge of stakeholders’ mental models. Formally, consider a single stakeholder (or stakeholder group) with some hidden state of mind – e.g. an investor’s true risk tolerance or a customer’s latent need for a feature. The entrepreneur doesn’t directly observe this, but can take actions (like presenting information or asking questions) to gain insight. We model this as a Bayesian inference problem embedded in the entrepreneurial context. The stakeholder’s decision-making process can be thought of as a function mapping venture attributes to outcomes (e.g. “will invest” or “won’t invest”), but this function is not fully known to the founder. We treat the stakeholder’s belief or preference as a latent variable and the entrepreneur’s action as influencing the observation. In effect, it is a simplified POMDP: the state is the stakeholder’s type or belief, which is partially observed through their responses. 

Primal Approach (Uncertainty Minimization): The goal is to choose action $\textcolor{red}{a}$ that minimizes the stakeholder-specific uncertainty $U$ (entropy of the belief about the stakeholder’s state). In an information-theoretic sense, we want to maximize information gain about the stakeholder. If we let $p(\theta)$ represent the entrepreneur’s belief distribution about a stakeholder’s state $\theta$ (for example, $\theta$ might represent how strongly a customer needs a sustainable product), then the primal objective for this component could be written as minimizing $H(p(\theta)\mid \textcolor{red}{a})$, the entropy of the belief after action $\textcolor{red}{a}$. The action could be something like a signal or test: a pitch, a prototype demo, a survey, etc., which yields evidence (feedback or data). Constraints here include a cost $c(\textcolor{red}{a})$ for the action (e.g. time to build a prototype) counting against the budget $R$. The solution is to pick the action that offers the largest expected reduction in entropy per cost unit. In practice, this often comes down to experiments or signals that resolve the most pressing question that the stakeholder has. For instance, if an investor is unsure about market size, an action aimed at demonstrating market demand (like running a quick crowdfunding campaign to gauge interest) might drastically cut that uncertainty. 

Dual Interpretation (Likelihood Maximization): In the dual perspective, reducing the stakeholder’s uncertainty is equivalent to maximizing the likelihood that the stakeholder will make a decision favorable to the venture (since they now have the evidence needed to say “yes”). Essentially, the dual objective is to maximize $P(\text{stakeholder supports venture}\mid \textcolor{red}{a})$. By providing the right information, the entrepreneur increases the probability that, say, an investor invests or a customer buys, because the stakeholder’s decision model $\hat{D}$ becomes more confident and accurate in predicting a positive outcome. This dual view is intuitive: every bit of uncertainty we remove (primal) corresponds to a higher chance the stakeholder will commit (dual). Solution Approach: We use a greedy Bayesian update strategy. The entrepreneur starts with a prior belief about the stakeholder’s preferences or concerns (perhaps based on market research or prior meetings). We then evaluate a set of possible actions by how much they would change that belief distribution. For each candidate action, we compute the expected posterior entropy (summing over possible stakeholder reactions weighted by their prior probability). This is analogous to calculating the information value of each action. Mathematically, for each $\textcolor{red}{a}$ we estimate $H_{\text{expected}}(\theta\mid \textcolor{red}{a})$ and choose the action that minimizes this, subject to $c(\textcolor{red}{a}) \le R$ (or equivalently, maximizes $\frac{\text{Entropy Reduction}}{c(\textcolor{red}{a})}$ if resources are very limited). This approach is tractable because it’s essentially a one-step lookahead in a single-variable inference problem, far simpler than a full multi-step, multi-actor decision process. It transforms a nebulous “what do they really want?” question into a clear calculation of expected information gain. 

Startup Example: Consider Segway in its early days, preparing to introduce a revolutionary personal transporter to consumers. The founder isn’t sure what potential customers’ biggest hesitation is: do they care more about the price of the device or about its safety and legality of use? Here the stakeholder (customer) uncertainty $\theta$ has (at least) two key dimensions. The founder could take one of two actions to probe this: (A) run a pricing experiment or survey (targeting the cost concern), or (B) conduct a safety demonstration and seek a public regulatory endorsement (targeting the safety/acceptability concern). Using our model, the founder assesses which uncertainty is larger. Suppose prior beliefs are 50/50 on whether cost or safety is the primary concern inhibiting adoption. The model computes the expected entropy after each action: perhaps action (A) would almost completely resolve uncertainty about price sensitivity (for instance, offering a limited-time 50% discount either triggers a surge of orders or not, clearly revealing how much price matters), whereas action (B) might only partially alleviate safety concerns (a demo might reassure some customers, but others may adopt a “wait and see” attitude). In this scenario, action (A) yields a bigger expected drop in uncertainty, so the model suggests doing (A) first. Indeed, if the discounted trial reveals that even at a much lower price few people purchase a Segway, it indicates that price is not the only barrier – perhaps safety, usability, or general interest is the real issue. The entrepreneur would update their belief: now they know demand is weak even when cost is low, so cost uncertainty is largely resolved (we learned it’s not just a pricing problem) and the remaining uncertainty centers on whether the product is fundamentally appealing or acceptable (safety/legal and usage concerns). Next, the entrepreneur can tackle that next biggest uncertainty by, say, showcasing safety through rigorous tests and working with city regulators to signal that the device can be used without incident. This sequential, evidence-driven reduction of the customer’s uncertainty is exactly what the perception component formalizes. By first taking an a_segment action to target demand-side unknowns (price sensitivity), then following with another targeted experiment once the situation is updated, the entrepreneur systematically learns what the customer truly wants or fears. In other words, Segway’s founder would be using perception modeling to segment the problem – addressing the most pressing question first – rather than guessing blindly. This illustrates how a_segment actions can optimally reduce $U_{\text{demand}}$ in a stepwise fashion, maximizing the chances of convincing that stakeholder to support the product.

### 3.4 Stakeholder Coordination (🔄): From Alignment to Collective Action

This section addresses the coordination challenge. We present our multi-stakeholder coordination mechanics, showing how entrepreneurs can overcome circular dependencies through information spillover and expectation alignment. We explain the federated calibration process that systematically aligns stakeholder beliefs. We then reveal the optimization insights, demonstrating how coordination challenges can be transformed into collective <span style="color:red;">action</span> probability maximization, identifying which stakeholder deadlocks most severely limit progress through primal-dual analysis.

Problem Formulation: The coordination component focuses on simultaneous, interdependent decisions among multiple stakeholders. The formal model here is a multi-agent extension of the decision problem, where each stakeholder $j$ (e.g., customer, partner, regulator, investor) has their own model $\hat{D}_j$ of the venture’s state transitions and outcomes. These models can be thought of as each stakeholder’s expectations or predictions about the venture (e.g., how quickly it will scale, how risky it is, how much return it will generate). Misalignment among the $\hat{D}_j$ can cause suboptimal outcomes or gridlock: one stakeholder’s decision might depend on another’s incorrect expectation. In mathematical terms, each stakeholder $j$ has a belief distribution over possible future states of the venture (for instance, a regulator assigns probability to “the tech will meet safety standards in 1 year” vs “in 3 years”). The entrepreneur wants to align these beliefs as closely as possible so that stakeholders can move forward together. This problem can be viewed through the lens of consensus optimization or federated learning: each stakeholder is like a separate model that needs to be calibrated using shared evidence. 

Primal Approach (Uncertainty Minimization): We formulate a primal objective to minimize the total weighted uncertainty across all stakeholders’ expectations. Extending the earlier notation, let $\textcolor{#3399FF}{U_j}$ be the uncertainty (entropy, variance, or similar) in stakeholder $j$’s expectation of the venture’s success. The primal coordination objective is $\min_{\textcolor{red}{a}} \sum_j \textcolor{violet}{W_j},\textcolor{#3399FF}{U_j}$, summing over all stakeholders with weights $\textcolor{violet}{W_j}$ to prioritize the most critical ones. This minimization is subject to dynamic constraints that link everyone’s expectations: ultimately, all stakeholders are observing the same venture reality, so we impose coupling constraints ensuring that if the venture takes an action and moves to a new state, everyone’s state estimate updates consistently. In practice, we enforce a simple consensus constraint such as $\mathbb{E}[s'_e] = s's$ (the expected ecosystem state equals the startup’s own resultant state) – this ties the startup’s internal state transition to the external (ecosystem) state that stakeholders perceive, ensuring no one is left with outdated information. Actions $\textcolor{red}{A}$ in this context might include communication actions (sharing data, convening joint stakeholder meetings) or coordinated moves (e.g. simultaneously signing a customer and an investor to a pilot deal) that aim to reconcile differences in expectations — essentially a_collaborate moves focused on bringing stakeholders together to reduce $U{\text{supply}}$ (operational or execution uncertainty arising from miscoordination). 

Dual Interpretation (Likelihood Maximization): The dual of the above is to maximize the likelihood of a collectively successful outcome. In other words, we maximize the probability that all key stakeholders will make decisions that align to achieve success. This is like asking: what is the probability that the investor funds the venture, the customer buys the product, and the regulator approves it – all in concert? By focusing on alignment, we’re effectively pushing that joint success probability up. The dual variables in this case can be interpreted as the implicit value of perfect alignment or the shadow price of uncertainty for each stakeholder. For example, a dual variable $\lambda_j$ might represent how much the overall success probability would improve if stakeholder $j$ had zero uncertainty (complete confidence in the venture). Our job in the primal is to drive each stakeholder’s uncertainty down until the marginal gain (the corresponding dual value) of reducing any one stakeholder’s uncertainty equals the cost. This yields a principle of balance: invest effort in aligning whichever stakeholder is currently most “out-of-sync” until diminishing returns set in equally across the board. Federated Calibration Process: We implement a two-step iterative calibration between the venture and each stakeholder to practically achieve this alignment:

Venture Self-Update: The entrepreneur updates their internal model and state based on recent data (e.g. results from an experiment). If the startup took action $\textcolor{red}{a_s}$ in state $s$, it computes its own new state $s'_s = \hat{D}_s(s, a_s)$ – this is what the startup believes happened. For instance, after a pilot test, the startup might conclude “our battery prototype achieved 20% higher efficiency” – that’s an update to its internal state $s'_s$.
Stakeholder Expectation Update: The entrepreneur then shares the relevant evidence with stakeholders, who update their models $\hat{D}_j$. We can treat each stakeholder’s belief update in a Bayesian manner. Conceptually, $\hat{D}_j$ is revised to $\tilde{D}_j$ (for stakeholder $j$) by incorporating the new evidence (like a Bayesian posterior). For example, a regulator hearing the pilot result updates their expectation of the technology’s viability (perhaps becoming more optimistic if the result was good).

Action Alignment: Next, choose the subsequent action involving stakeholders such that the real outcome $s'_e = D_a(s_e, a_e)$ aligns as much as possible with all parties’ expectations. For example, if both the startup team and an investor expect that “securing one big customer will validate the market,” then the entrepreneur’s next move might be to indeed secure that customer (so that this expectation is tested and hopefully fulfilled by the real outcome). We ensure that after this action, $\mathbb{E}[s'_e] \approx s'_s$ – meaning the ecosystem’s expected state (stakeholders’ collective view) matches the startup’s achieved state – otherwise any discrepancy signals the need for further calibration in the next iteration.
Repeat: This process iterates with each major action or milestone, continuously tightening the alignment. Essentially, with every cycle of acting and updating, stakeholders’ beliefs converge closer to the venture’s actual trajectory.
This approach resembles federated learning in machine learning, where multiple models (here, stakeholders’ belief models) are updated with local data and periodically synchronized. In our case, the “local data” for each stakeholder is the latest evidence the entrepreneur shares that is relevant to them, and synchronization happens through communication and coordinated action by the entrepreneur. Ensuring Tractability: Without intervention, aligning many independent stakeholders could devolve into a complex game-theoretic problem. We make it tractable by leveraging the structure that all stakeholders are ultimately reacting to the same ground truth (the venture’s actual performance). By sharing evidence proactively and using the startup as a central coordinator, we avoid an exponential blow-up of negotiation complexity. Each calibration step can be seen as solving a least-disagreement problem: minimize the differences between each stakeholder’s expectations and the startup’s results. Formally, one could set this up as an optimization (e.g. minimize $\sum_j |s'_s - \mathbb{E}_j[s'_e]|^2$) with solutions that suggest allocating more evidence or attention to the stakeholders with the largest gaps. Interestingly, the dual variables $\beta_j$ from our earlier formalism act like Lagrange multipliers enforcing that each stakeholder’s “forecast” of outcomes matches the actual outcomes. Solving the dual yields conditions such as: invest more effort in aligning stakeholder $j$ until the benefit (increase in overall success likelihood) per unit cost is equal for all stakeholders. This leads to a rule of thumb for coordination: focus on whichever stakeholder is most out-of-sync (has the highest weighted uncertainty) at the moment, until their uncertainty is reduced to the point that another stakeholder’s misalignment becomes comparatively more critical.

Startup Example: Now let’s apply this to Segway, which had to manage multiple stakeholders in launching its personal transporter. Key stakeholders included a city regulator (responsible for approving Segway use on streets/sidewalks, representing supply-side operational constraints), the consumers who would buy and use the device (demand-side), and investors backing the company (resource-side). Initially, their expectations were very different. Imagine the situation shortly after Segway’s high-profile launch: the city regulators might expect it would take 5+ years to safely integrate Segways into urban mobility (pessimistic about immediate use due to safety concerns and the need for new regulations); potential customers (early tech enthusiasts) might expect the product to be available within 1 year and widely allowed (overly optimistic, assuming quick adoption and acceptance); meanwhile, investors could be forecasting a timeline of around 3 years for the venture to scale successfully (tempered optimism, considering some challenges but hoping the hype translates to moderate quick wins). In other words, $\hat{D}{reg}$, $\hat{D}{cust}$, $\hat{D}_{inv}$ were misaligned: the regulator foresaw a long road, customers had short-term excitement, and investors were somewhere in the middle. This misalignment can create a stalemate: regulators might be reluctant to green-light usage due to safety concerns, customers won’t buy en masse if usage is restricted or the product isn’t available, and investors hesitate to pour in more money if they sense regulatory roadblocks or tepid consumer uptake. Everyone is waiting on someone else. To break this deadlock, the entrepreneur needs to align stakeholder expectations through targeted actions (a_collaborate type). Suppose Segway’s team initiates a pilot program in one city as a coordinated move. They partner with local authorities to allow a limited number of Segways for supervised trials (addressing regulatory caution), and invite selected consumers to use them in daily life (addressing customer curiosity), all while keeping investors in the loop with detailed performance and safety data. This collaborative action provides a common evidence base. After the pilot, the team shares the results with all stakeholders. The city regulator sees that the trial resulted in, say, zero serious accidents over 6 months and that pedestrians largely accepted the Segways on sidewalks; accordingly, the regulator updates their expectation, perhaps revising $\hat{D}{reg}$ to anticipate that safe integration is possible in maybe 3 years instead of 5 (more optimistic, though still cautious). The customers get feedback from the trial that while the device is fun and useful, there were some speed limits and usage rules; a typical enthusiastic customer might update $\hat{D}{cust}$ from expecting a 1-year instant ubiquity to a more realistic 2-year timeline for broad availability (still eager, but now aware it’s not immediate). The investors, seeing the positive safety data but also noting regulators haven’t fully jumped onboard yet, adjust $\hat{D}_{inv}$ slightly – if they were expecting 3 years to scale, they might stick to around 3 years but with more confidence that this is achievable (or even nudge toward 2.5 years, given some hurdles are lower). In summary, after the shared pilot data: the regulator is less pessimistic (5→3 years), customers slightly less overly optimistic (1→2 years), and investors gain confidence (holding ~3 years, with improved perceived likelihood of success). Now the entrepreneur observes the new expectation spread. The stakeholders are closer to alignment, but perhaps the regulator is still the most conservative (3 years versus the ~2 years others expect). Following our coordination logic, the next step is to target the remaining biggest gap. Segway’s team might decide on another a_collaborate action focused on the regulator: for example, entering a “regulatory sandbox” program for innovative transport devices. In this sandbox, they work hand-in-hand with the city officials on safety protocols and demonstrate improved training and technology (e.g. automatic speed governors, better stability software) in real conditions. Meanwhile, they keep consumers engaged with updates (news about the safety improvements and perhaps limited access opportunities) and maintain investor confidence by showing steady progress on the regulatory front. After these concerted efforts, the regulator’s stance further improves – say the regulator now revises $\hat{D}_{reg}$ to 2 years for broad approval and even starts drafting guidelines for Segway usage. At this point, all three stakeholder groups converge on a similar outlook (roughly 2 years to mainstream roll-out). By orchestrating this sequence of evidence-sharing and joint engagement, Segway has aligned previously divergent expectations. This vignette demonstrates how coordination-oriented (a_collaborate) actions can systematically reduce operational/supply-side uncertainty stemming from stakeholder misalignment. In essence, the entrepreneur acted as a central information hub and negotiator, turning a potential multi-party standoff into a synchronized move forward. The result is a higher joint success probability – investors are willing to invest because regulators are on board, regulators fast-track approval because they see public receptiveness and investor backing, and customers buy in because both regulators and investors signal confidence in the product. By minimizing collective misalignment, the venture maximizes the chance that all stakeholders say “yes” together.

### 3.5 Bottleneck Sequencing (⚡): From Information Value to Resource Optimization

This section tackles the bottleneck-breaking challenge. We present our bottleneck-driven <span style="color:red;">action</span> sequencing approach, showing how entrepreneurs can transform complex multi-step decision problems into sequential single-step decisions that target highest <span style="color:#3399FF;">uncertainty</span> reduction per <span style="color:#3399FF">resource</span> unit. We then explore the primal-dual optimization techniques, demonstrating how <span style="color:#3399FF">resource</span>-constrained learning can be approximated through linear programming relaxation, creating near-optimal experimental paths while maintaining computational tractability.

# ⚡ Sequencing Component: Bottleneck-Driven Action Sequencing (LP–POMDP Hybrid)
Problem Formulation: The sequencing component deals with optimal sequencing of actions under uncertainty and resource constraints. Formally, this is a sequential decision problem where at each time step the entrepreneur chooses an action $\textcolor{red}{a} \in \textcolor{red}{A}$, pays a cost, observes an outcome, and moves to a new state $S'$. This process continues until resources run out or key objectives are met. It fits the paradigm of a Partially Observable Markov Decision Process (POMDP) because the entrepreneur may not know the true state with certainty (for example, whether a technology will ultimately work or whether a market truly exists might be unknown until certain experiments are done). Solving a general POMDP would give an optimal policy (i.e. which action to take in each possible belief state), but that is computationally intractable for all but very small problems (solving POMDPs is PSPACE-hard in general). The curse of dimensionality and history is severe here: there are astronomically many possible action sequences, outcome combinations, and belief updates over time. 

Approach Overview: We employ a primal–dual simplification by observing that entrepreneurial experiments often have a structure we can exploit: each action typically targets a specific uncertainty “factor” (as reflected in a factorized objective like $\textcolor{#3399FF}{U_d} + \textcolor{#3399FF}{U_s} + \textcolor{#3399FF}{U_i}$ for demand, supply, and investor uncertainties respectively). This suggests a decomposition strategy: rather than one monolithic decision process, treat the problem as multiple smaller sub-problems – one for each major uncertainty dimension – and then coordinate among them. Concretely, we break the challenge into managing demand-side uncertainty, supply-side (operational) uncertainty, and investor/resource uncertainty separately. This yields a set of candidate single-factor policies (e.g., a mini-policy for resolving market demand uncertainty, one for resolving technical or supply chain uncertainty, and one for resolving funding/investment uncertainty). We then use a simplex-based linear program to allocate the overall resources among these policies, effectively identifying which uncertainty is the current “bottleneck” that deserves focus. The LP makes this rigorous: we maximize total uncertainty reduction $\textcolor{violet}{W_d},\Delta U_d + \textcolor{violet}{W_s},\Delta U_s + \textcolor{violet}{W_i},\Delta U_i$ subject to the constraint that the planned uncertainty reductions $\Delta U_j$ (for each dimension $j$) are achievable within the available resource $R$ (e.g., time, money). Here $\textcolor{violet}{W_j}$ are weights reflecting the importance of each uncertainty dimension, and $U_j$ and $\Delta U_j$ represent current uncertainty and the reduction in uncertainty from an action, for $j \in {demand, supply, investor}$. Solving this linear program yields a priority ordering: it will allocate the resource to the uncertainty with the highest payoff per cost (i.e. whichever has the highest ratio $\frac{\textcolor{violet}{W_j}\Delta U_j}{\text{cost}}$). In practice, this often means focus all effort on the single most severe uncertainty first – the identified bottleneck – because the LP corner solution will concentrate on the $j$ with maximal $\textcolor{violet}{W_j}\textcolor{#3399FF}{U_j}$ (assuming one action can potentially eliminate that uncertainty). Only once that bottleneck is significantly reduced would another uncertainty become the next focus. Myopic Policy with Near-Optimal Results: The result of the above approach is a greedy policy: at each step, tackle the uncertainty reduction action that offers the highest expected payoff per unit cost. While greedy, this policy is designed to be near-optimal by the structure of our problem – the uncertainties are modular to some extent, and resolving a major uncertainty early often has the largest impact on future decisions. In fact, this strategy connects to the concept of “value of information” in decision theory: the first action chosen is the one with the highest value of information (i.e. resolves the most critical unknown). After each action, the situation (state and uncertainty levels) is updated, and then the next action is chosen based on the new highest value of information, and so on. This iterative strategy has precedent in POMDP research: under certain conditions, myopic (one-step-lookahead) actions can achieve near-optimal total reward, especially when information gained early significantly reshapes the remaining decision problem. We further augment the greedy approach with a modest lookahead check for irreversible decisions: if a candidate action could irreversibly consume a large portion of resources or close off future options, the model does a brief extra lookahead (e.g. one step further into the future) to ensure this choice doesn’t lead to a dead-end. This safeguard keeps computational complexity low (we’re still far from exhaustive search) but adds a layer of protection against overly short-sighted moves in critical junctures. 

LP Formulation: To illustrate the resource allocation step more formally, at a given decision point we set up a linear program:
Maximize: $\sum_j \textcolor{violet}{W_j}, \Delta \textcolor{#3399FF}{U_j}$
Subject to: $\sum_j \frac{\Delta \textcolor{#3399FF}{U_j}}{\textcolor{#3399FF}{U_j}^{\text{max}}} \le 1$ (ensuring we don’t plan to eliminate more than 100% of total uncertainty across dimensions given a normalized resource budget of 1 for this step).
Here $\Delta \textcolor{#3399FF}{U_j}$ is a decision variable representing how much uncertainty in dimension $j$ we choose to eliminate with our next action (in an optimal solution, $\Delta \textcolor{#3399FF}{U_j}$ will be zero for all but one $j$, meaning we focus on one type of uncertainty at a time). The LP will naturally allocate all “uncertainty reduction capacity” to the single dimension with the highest weighted payoff $\textcolor{violet}{W_j},\textcolor{#3399FF}{U_j}^{\text{max}}$. In simpler terms, it picks the $j$ for which $\textcolor{violet}{W_j},\textcolor{#3399FF}{U_j}$ is maximal (assuming one action can at best eliminate uncertainty $U_j$). The optimal solution corresponds to dedicating the next action entirely to that bottleneck uncertainty. (In more advanced scenarios, we could allow fractional $\Delta \textcolor{#3399FF}{U_j}$ to simulate an action that addresses multiple uncertainties at once, but typically entrepreneurial actions are focused enough that this isn’t necessary.) 

Dual Perspective: The dual variables of this LP give insight into the value of resources. The single resource constraint’s dual, call it $\gamma$, can be interpreted as the marginal value of an extra unit of resource at that decision point – essentially, how much additional objective improvement (uncertainty reduction) we’d get if we had a little more budget. Our greedy action selection ensures that the chosen action’s benefit-to-cost ratio (uncertainty drop per cost) is at least as high as any other available action’s, which means in an optimal solution it will equal this $\gamma$. As the venture progresses and easy uncertainties get resolved, $\gamma$ (the value of more resources) will tend to decline, since what remains are harder, less cost-effective uncertainties – mirroring the idea of diminishing returns on learning efforts. 

Startup Example: Let’s examine how Segway could have applied bottleneck-driven sequencing, and where it deviated in reality. Segway famously invested heavily in full-scale production and hype (an a_capitalize action) before truly validating whether consumers wanted a two-wheeled personal transporter. In our terms, they committed a large portion of resources to the investor/resource side (scaling up manufacturing capacity, expecting vast sales) without first resolving the most critical uncertainty: customer demand. At the outset, Segway faced at least three major uncertainties: (i) Demand uncertainty ($U_{\text{demand}}$) – Will mainstream consumers actually adopt this novel device at the expected price and in large numbers? (ii) Operational/regulatory uncertainty ($U_{\text{supply}}$) – Can Segway be used safely in the real world, and will city infrastructures and regulations accommodate it? (iii) Business model/investor uncertainty ($U_{\text{investor}}$) – Even if it works and some people want it, can it become a profitable venture that justifies the huge investment (what are the unit economics, market size, etc.)? According to our framework, these uncertainties should not be addressed all at once or haphazardly; instead, the optimal sequence is to tackle the biggest “bottleneck” uncertainty first with a targeted action, then proceed to the next, and so on, to maximize information gained per resource spent. In Segway’s case, demand (customer) uncertainty was arguably the highest stake and most fundamental unknown. Without sufficient demand, everything else (production, funding, partnerships) would be moot. A bottleneck-driven approach would have prioritized an a_segment action to reduce $U_{\text{demand}}$ before pouring resources into scaling. For example, instead of immediately building thousands of units and launching globally, Segway could have produced a small batch of say 100 devices and released them in a controlled pilot market or to a specific segment (early adopters, or for a particular use-case like city tours or security patrols). This limited market experiment would serve as a high-value information probe: if there is genuine excitement and adoption even on a small scale (long wait-lists, high usage by pilot users), that would dramatically reduce demand uncertainty and signal that the concept has a strong market. If, on the other hand, the uptake is lukewarm – suppose only a handful of pilot users actually use the Segways regularly or most consumers say they wouldn’t pay the high price – then the company learns that mainstream demand is questionable. At that point, the model would update $U_{\text{demand}}$ downward (much of that uncertainty is resolved – it appears demand is lower than hoped) and correspondingly raise the importance of the other uncertainties, especially $U_{\text{investor}}$ (because if demand is weak, the venture’s overall viability and return on investment become highly uncertain). Essentially, the company now faces the reality that its current consumer-focused model might not be easily profitable. The next action in that scenario would likely be to pivot or address a different uncertainty on a smaller scale rather than doubling down – for instance, explore a niche where the device could still be valuable (maybe focus on police, security, or warehouse applications where a few units might be needed, thereby testing a different market segment). This would be another a_segment action (targeting a new customer segment’s demand) or perhaps an a_collaborate action if it involves partnering with a specific early customer, but notably it would be a relatively low-cost experiment, preserving capital. Conversely, imagine the small-scale test revealed ravenous demand – say the 100 test units had thousands of eager buyers on waitlist and users were ecstatic. In that case, $U_{\text{demand}}$ would drop significantly (we now have evidence people want the product badly), and the next bottleneck might become the operational/regulatory uncertainty ($U_{\text{supply}}$). With a green light from the market, the entrepreneur’s question shifts to: “Can we deliver this product at scale, and will the world let us?” The prudent next step would then be an a_collaborate action to reduce $U_{\text{supply}}$: for example, partner with manufacturers to streamline production or work with local governments to ensure the device can be legally used in more cities. Segway’s team could have, for instance, collaborated with a city’s transportation department to pilot integration of Segways into their transit system or set up manufacturing contracts that scale gradually with demand. These moves would test and improve the operational capacity and address regulatory hurdles, reducing uncertainty about execution. Only after both the demand and supply-side uncertainties were largely mitigated would it make sense to go for a major scale-up investment. That final step – building large factories, producing en masse, spending heavily on marketing – is an a_capitalize action addressing $U_{\text{investor}}$ (showing that the business can generate the expected returns once scaled). By timing this last, the company ensures that investor resources are committed when the venture’s success likelihood is highest (because the core market and operational questions have been answered). This staged approach is in line with the real options view of entrepreneurship: treat each major growth decision as an option that you only “exercise” (i.e. invest in) if the uncertainty has been sufficiently resolved in your favor. Our model provides a concrete optimization-based method to execute this: always invest in the next action that yields the highest information gain per dollar, and thus keep the venture on the most informed path. Segway’s actual trajectory deviated from this ideal sequence – they effectively assumed massive demand and skipped straight to a huge a_capitalize move. The result was that when demand proved far lower than anticipated, they had already burned through much of their resources (and goodwill). Had they followed the bottleneck-driven sequencing, they might have discovered the limited consumer appetite early, saved most of their $R$ (resources) by not over-investing, and pivoted the technology to niche markets or made necessary adjustments (or even abandoned the project before a catastrophic scale-up). This example underscores how a myopic-but-informed sequencing strategy can save a venture: by always testing the most critical assumption first, as cheaply as possible, then reassessing, entrepreneurs approximate optimal use of limited resources. In sum, a_segment actions to validate demand, followed by a_collaborate actions to iron out supply issues, and only then a_capitalize to scale, is the kind of sequence that maximizes the venture’s overall success probability under resource constraints. Solving the Hybrid Model: After each action in the sequence, the entrepreneur updates the state $S$ (which aspects of the stakeholder-state vector have progressed) and the uncertainty vector $U$. Then the next LP is formulated for the new $U$ and the remaining resource $R$ to decide the subsequent step. This loop continues until either $U$ is driven to an acceptably low level (all key uncertainties resolved) or resources are exhausted (in which case, if significant uncertainties remain, the venture is flagged as high-risk – potentially prompting an early exit or major strategy rethink if the projected success likelihood is too low). For mathematical details, see Appendices.md, where we derive conditions under which this greedy strategy is optimal or near-optimal. We also show how the LP relaxation relates to solving the Bellman equations of a corresponding POMDP in special cases (e.g., when outcomes are near-deterministic or uncertainties are nearly independent). Additionally, the appendix includes proofs-of-concept with small-scale examples, including a step-by-step solution of a toy startup decision problem using our linear heuristic and a comparison to the true optimal solution to illustrate the performance trade-off.


In summary, 
Across perception, coordination, and sequencing, we applied the primal–dual lens in tailored ways:
- For perception, we minimize one stakeholder’s entropy (uncertainty) to maximize the chance of convincing them (i.e. turning a “maybe” into a “yes” by learning what they need to hear or see).
- For coordination, we minimize collective misalignment to maximize the joint success probability (ensuring all stakeholders can say “yes” together by sharing evidence and expectations).
- For sequencing, we minimize overall uncertainty in a stepwise fashion, effectively maximizing the venture’s success likelihood given a fixed budget (focusing on the biggest unknown first so as to get the best payoff for each action).
Each component uses a different primary tool (Bayesian updates for perception, federated learning-style expectation alignment for coordination, and an LP-guided myopic policy for sequencing), but all are instances of the same overarching framework optimizing entrepreneurial outcomes under uncertainty and constraints. In the next section, we demonstrate how these pieces come together in practice by walking through a real-world case study. We will map the abstract variables ($A, B, C, D, S, U, W, R$) to concrete decisions and outcomes for a clean-tech startup, showing how the framework guides an entrepreneur from initial uncertainty to scalable success. (For full derivations, algorithmic pseudocode, and additional case studies, please refer to Appendices.md.)

# 4💸Evaluate

### 4.1 Case Study Applications

## failure case
**Segway Case Summary (PCS Framework)** – _Segway’s journey illustrates missteps in **segmentation**, **collaboration**, and **capitalization** under uncertainty._ The table below maps key strategic moves to the PCS action categories and the primary uncertainty each move failed to resolve:

**Projecting (Perception).** Segway’s founders and backers projected an overly optimistic vision of demand. The device was hyped as _“the future of transport”_ on par with the personal computer or internet, yet it solved no urgent problem for any specific customer segment. This grand misperception of **demand uncertainty (u_demand)** led to wildly unrealistic sales forecasts (50k+ units in the first year) versus only ~6,000 actually sold by 2003. A PCS _Perception_ approach would have urged early **market sensing** – e.g. pilot trials or user research – to gauge real user needs and calibrate expectations, rather than relying on hype. By gathering evidence on who would value the Segway and why, PCS-guided projecting could have revealed the limited initial demand and prevented the assumption that “everyone will adopt it” from driving the strategy.

**Sequencing.** Segway’s execution sequence was essentially _backwards_ from a PCS standpoint – they built everything first and learned critical lessons later. The company spent years and massive capital developing a polished product in secrecy (with _no user testing or iteration_ prior to launch). This meant **investor uncertainty (u_investor)** remained high: huge resources were committed before confirming market viability. When the Segway finally hit the market, its design was met with surprises (e.g. being seen as “dorky”) and its value proposition needed rethinking, but by then most of the budget was spent. PCS’s _Sequencing_ principle would have dictated a more incremental rollout – **sequence experiments to learn before large investments**. In practice, PCS would suggest starting with affordable, low-risk tests (e.g. small pilot programs for a specific segment) to systematically reduce demand and supply uncertainties, and only then scaling up production. This staged approach would align investment decisions with validated learning, ensuring that each next big expenditure is justified by evidence (thereby protecting investors and the venture from all-or-nothing bets). In short, a PCS-guided sequence could have caught design and market fit issues early, saving time and capital and improving Segway’s odds of success.

**Coordinating (Coordination).** Segway treated its product as a standalone invention rather than part of a mobility ecosystem. It **failed to coordinate** with key stakeholders (city planners, regulators, infrastructure providers) to ensure the environment could accommodate this new vehicle. There was _“no proper infrastructure to support it”_ – users didn’t know where to ride, park, or charge the Segway. Worse, the company was caught off-guard by legal barriers: many cities and countries banned Segways on sidewalks and roads since they didn’t fit any category. This reflects unaddressed **supply uncertainty (u_supply)** in the adoption environment (regulatory and logistical feasibility). The PCS _Coordination_ lens would have encouraged **collaborative action** to reduce such uncertainty – for example, partnering with municipalities to define safe Segway lanes or policies, and working with early corporate/government adopters to integrate Segway into controlled settings. By synchronizing product roll-out with infrastructure and policy, Segway could have created a supportive context for its device, rather than launching into a vacuum of misaligned infrastructure and rules.
## success case


![[Pasted image 20250507220629.png|center|200]]
Figure3: Perceptual Mapping Across Stakeholder Spaces: This diagram illustrates how entrepreneurs must translate their venture's concrete attributes (technology, team, market) into different "languages" for each stakeholder type. Sublime Systems successfully mapped their sustainable cement attributes to specific decision criteria for each stakeholder (eco-builders valued carbon reduction, regulators focused on durability standards, investors sought market validation). Segway failed by incorrectly mapping consumer preferences, assuming high demand where little existed. The equation (∑ₖ pⱼₖfⱼₖ = μⱼ(a)) formalizes this translation process, showing how stakeholder-specific interpretations determine venture success.

### 4.2 Validation and Performance Analysis

![[Pasted image 20250507221031.png|center|500]]

Figure 4: Entrepreneurial Decision-Making Parameter Evolution - This figure visualizes the key parameters from your entrepreneurial decision-making framework as they evolve across venture stages, comparing successful (Sublime Systems) and unsuccessful (Segway) startups. **Left Panel**: Lambda (λ) values represent stakeholder uncertainty penalties. Sublime Systems methodically reduced uncertainty across all stakeholders (demand, supply, investor) through staged approach, while Segway maintained high uncertainty penalties, particularly for demand stakeholders. **Middle Panel**: Gamma (γ) represents resource scarcity price (dual variable for resource constraint). Sublime's efficient resource allocation progressively reduced the marginal value of capital, while Segway's resource-intensive approach led to persistent scarcity. **Right Panel**:**State Transition Matrices**: The bottom panels show how ventures transition between states as they mature. Sublime progressed to more deterministic transitions (concentrated probabilities near diagonal), while Segway maintained unpredictable state transitions even in growth stages. This visualization supports my thesis that successful ventures systematically reduce uncertainty across stakeholders while efficiently allocating resources, producing increasingly deterministic behavior as they transition from "nail-it" to "scale-it" stages.

| **Step**         | **Substep**              | **Evaluate (Metrics)**                                                                | **Example (Segway)**                                                                                                                                                                                                                                                                                   |
| ---------------- | ------------------------ | ------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **3. Solutions** |                          |                                                                                       |                                                                                                                                                                                                                                                                                                        |
|                  | **3.1 Nature**           | 1. Satisfying axiom: Action sequence depends on stakeholder weights and initial state | >> Axiom Satisfiability: Initial State Axiom: Bottleneck respects: True Random respects: False Weight Axiom: Bottleneck respects: True Random respects: False                                                                                                                                          |
|                  | **3.2 Individual level** | 2. Efficiency: Decreased uncertainty per cost for each stakeholder type               | A pilot demonstration where customers, partners, and investors could simultaneously observe the Segway in action would reduce uncertainty across all stakeholders efficiently                                                                                                                          |
|                  |                          |                                                                                       | >> Bottleneck Sequence: a_demand, a_invest, a_demand, a_demand, a_supply, a_supply, a_invest, a_supply, a_invest <br><br>>> Segway Sequence (PRISM taxonomy): a_supply, a_supply, a_supply, a_invest, a_invest, a_invest, a_demand, a_demand, a_demand                                                 |
|                  |                          | Efficiency: Maximized uncertainty reduction per dollar spent                          | Segway needed a coordinated approach to satisfy multiple stakeholders (users, regulators, investors) whose decisions were interdependent                                                                                                                                                               |
|                  |                          | 3. Tractability: Increased success probability per cost                               | Segway should have prioritized market validation tasks ($0.25M) before committing to production design ($5M) and supply chain ($3M) to gain critical market insights at lower cost<br><br>⭐️use sublime system - where stakeholders have clear theshold (test statistis - durability, cost, greenness) |
### 4.3 Uncertainty Assessment and Limitations

Results - Describe specific results, including a careful explanation of the uncertainty. Discussion - Compare and contrast the results with other studies, including citations.

Explain how you have addressed the technical questions and long-term applications mentioned in the methods and introduction.

- todo: connecting the code of 📽️Perception Modeling and ⚡️bottleneck sequencing 

* **Appendix A** will outline the hierarchical Bayesian framework and random utility modeling via logit regression.
* **Appendix B** will distill the stakeholder coordination logic into its simplest operational form, based on the decision matrix and sigmoid evaluation components.
* **Appendix C** will present the full primal-dual optimization formulation, now expanded with detailed narrative on how it maps to the PRISM framework (perception 📽️, coordination 🔄, bottleneck breaking ⚡).
- Appendix D will prove the np-completeness of entrepreneurial decision making model with nonlinear and opportunity dependent objective

# Appendix A: Stakeholder 📽️Perception  Modeling

Entrepreneurs can model stakeholder decision-making as a **hierarchical Bayesian random utility process**, capturing heterogeneity in perceptions and rational choice under uncertainty. I assume each stakeholder $i$ evaluates a venture’s observable signals $x$ (e.g. product features, team credentials) and infers an *unobserved* latent quality of the venture (sometimes called a *“phantom” attribute*). In other words, stakeholders interpret observable venture characteristics as noisy indicators of underlying venture quality. This inference is treated as *noisily rational*: stakeholders update their beliefs in a Bayesian manner given the signals, then choose actions that maximize their perceived utility, subject to error.

Formally, let $U_{i,j}$ denote stakeholder $i$’s utility for a decision option $j$ (for example, $j=1$ might be “invest in the venture” and $j=0$ “decline”). I use a random utility model where:

$$
U_{i,j} \;=\; x_j^{T}\beta_i \;+\; \varepsilon_{i,j}\,,
$$

with $\beta_i$ a stakeholder-specific preference vector and $\varepsilon_{i,j}$ an idiosyncratic error term. If I assume $\varepsilon_{i,j}$ follows an extreme value type-I (Gumbel) distribution (i.e. each stakeholder makes **logit**-style noisy decisions), then the probability that stakeholder $i$ chooses option $j$ is given by the logistic choice function:

$$
P(y_i = j) \;=\; \frac{\exp\!\big(x_j^{T}\beta_i\big)}{\sum_{k} \exp\!\big(x_k^{T}\beta_i\big)} \,,
$$

as in a multinomial logit model. The vector $\beta_i$ captures stakeholder $i$’s latent preferences or belief weights—how strongly they value each venture signal $x$—and I model these preferences in a **hierarchical Bayesian** manner. In particular, I place a prior on each stakeholder’s $\beta_i$ such that:

$$
\beta_i \sim \mathcal{N}(\bar{\beta},\, \Sigma_{\beta})\,,
$$

meaning stakeholders are drawn from a population with mean preference $\bar{\beta}$ and covariance $\Sigma_{\beta}$. This hierarchical structure allows the entrepreneur to account for heterogeneity: some stakeholders may be more team-focused, others more market-focused, etc., but all share a common underlying distribution. By observing stakeholder choices (or feedback) and updating the posterior of $\beta_i$, an entrepreneur can learn about an individual stakeholder’s particular biases and expectations.

Notably, stakeholders may base their decisions on inferred qualities that are *not directly observable* to the entrepreneur. These latent perceptions are analogous to the *phantom attributes* described by Bell and Dotson (2022)—features of a product or venture that “influence choice but are latent artifacts of the decision process.” In our context, a stakeholder might infer an unobserved trait (e.g. the venture’s trustworthiness or long-term scalability) from observed signals like pricing, branding, or founder background. Entrepreneurs can incorporate such latent factors by extending the design matrix $x$ to include *unobserved* attributes and using Bayesian inference to estimate them (treating them as missing data to be learned). While detailed methods for identifying these latent attributes are beyond our scope, the key is that the hierarchical model can flexibly accommodate both observed and inferred signals.

**Interpretation – Noisy Rational Inference:** This framework implies that a stakeholder’s decision is a *probabilistic, rational response* to the venture’s signals. Each stakeholder behaves as if updating their belief about the venture’s quality (the posterior distribution of the latent attribute) and then choosing the action that maximizes expected utility. The logistic choice model adds controlled “noise” to reflect uncertainty and idiosyncrasies in decision-making. For the entrepreneur, this means stakeholder decisions can be predicted (and influenced) by managing the signals $x$: providing clearer or more convincing venture data will shift the stakeholder’s $\beta_i$-weighted evaluation upward and increase the probability of a favorable decision. In summary, **stakeholder decisions are modeled as noisy rational inferences over projected venture signals** – each stakeholder is making the best decision they can given their perception of the venture, and the hierarchical Bayesian logit model formalizes this process mathematically.

# Appendix B: Multi-Stakeholder 🔄Coordination Mechanics

When multiple stakeholders are involved, their decisions often become **interdependent**. Entrepreneurs frequently encounter **circular dependencies** where each stakeholder’s commitment depends on others: for example, investors wait until there are confirmed customers; customers hesitate until the venture has reputable investors and a proven product; partners or regulators want to see signals of support from both investors *and* customers. These feedback loops can create *deadlock situations* in which no single stakeholder is willing to move first. Effective entrepreneurial strategy must therefore *coordinate* stakeholders – aligning their expectations and actions so that everyone is willing to commit in concert.

To reason about coordination, it is useful to represent the stakeholders’ joint decisions in a **stakeholder decision matrix**. Consider a simple case of two stakeholders (A and B) each deciding whether to support a venture (Yes = 1) or not (No = 0). Each stakeholder has two possible actions, so the combined outcomes can be laid out in a $2\times2$ matrix:

* **Both say No (0,0):** The venture fails to gain support. This outcome might occur if both stakeholders independently conclude the venture isn’t viable *or* if each is waiting for the other to make the first move.
* **A says Yes, B says No (1,0):** Stakeholder A commits but B holds out. A’s support alone may be insufficient; A might later withdraw or incur loss if B never joins. This asymmetry is unstable – A acted on an expectation that B would follow, which didn’t happen.
* **A says No, B says Yes (0,1):** Symmetrically, B commits while A does not. This is the flip side of the above, and just as unstable.
* **Both say Yes (1,1):** The venture gets full support. This is the coordinated outcome needed for success (assuming the venture truly requires both A and B).

In this example matrix, the **coordinated equilibrium** outcomes are the corners where decisions are aligned (either both support or both don’t). The off-diagonal cells (one supports, the other doesn’t) reflect *misalignment* – one stakeholder’s positive expectation wasn’t shared by the other. In practice, if the venture is promising, the goal is to move stakeholders toward the **(Yes, Yes)** outcome (everyone supports); if the venture is not viable, all should correctly settle on **(No, No)**. Either way, *consistency* is key. The entrepreneur’s role is to facilitate information flow and incentives such that stakeholders reach a consensus decision rather than acting at cross purposes.

I model each stakeholder’s individual decision process with a **sigmoid-based decision function**, which provides a smooth approximation of the threshold behavior in commitment. Let $d_i \in {0,1}$ indicate stakeholder $i$’s decision (0 = no support, 1 = support). I define the probability of support as a logistic function of that stakeholder’s perceived venture success likelihood (or utility) $u_i$:

$$
P(d_i = 1) \;=\; \sigma(u_i) \;=\; \frac{1}{1 + \exp(-\kappa\, u_i)} \,,
$$

where $u_i$ represents stakeholder $i$’s **confidence** in the venture (e.g. how strongly they believe the venture will succeed or meet their requirements), and $\kappa$ is a steepness parameter. If $u_i$ is high (the stakeholder is confident), $P(d_i=1)$ approaches 1; if $u_i$ is very low, $P(d_i=1)$ is near 0. For intermediate levels of confidence, the sigmoid curve captures the idea that the stakeholder might go either way, reflecting uncertainty. In the limit of $\kappa \to \infty$, this becomes a step function (hard threshold): $d_i=1$ if $u_i>0$, else $d_i=0$. Thus, the logistic form provides a principled, differentiable model of each stakeholder’s decision rule.

**Interdependence and Coordination:** The complication in a multi-stakeholder setting is that each $u_i$ (stakeholder’s confidence) is not formed in isolation. Stakeholder $i$’s confidence $u_i$ will generally depend on their **expectations of other stakeholders’ actions or beliefs**. For instance, if stakeholder A expects stakeholder B to invest (which increases the venture’s chance of success, providing capital or credibility), then A’s own $u_A$ will rise. Conversely, if A expects B to back out, $u_A$ may drop. I end up with a coupled system of equations: $u_i = f_i(\text{signals, and } d_{-i})$ where $d_{-i}$ indicates the actions of the other stakeholders. In a fully rational equilibrium, all these expectations are mutually consistent (each stakeholder’s expectation about others’ decisions is correct). Achieving this consistency is the essence of coordination.

Mathematically, one can impose **consensus constraints** to enforce expectation alignment across stakeholders. One useful constraint is to require that all stakeholders (and the entrepreneur) share the **same predicted outcome** for the venture's next state or success metric. For example, using the expected outcomes $\mu_j(\textcolor{red}{a})$ from our primal-dual formulation, coordination can require:

$$
\mu_1(\textcolor{red}{a}) \;=\; \mu_2(\textcolor{red}{a}) \;=\; \cdots \;=\; \mu_N(\textcolor{red}{a}) \;=\; \mu_e(\textcolor{red}{a}) \,.
$$

In words, **everyone is on the same page** about the venture's prospects. This alignment of expected outcomes (which could be probabilistic beliefs about state transitions, revenue projections, etc.) means no stakeholder is significantly more optimistic or pessimistic than another -- a prerequisite for them to comfortably move forward together. If such equalities hold, then for any stakeholders $i$ and $j$, their confidence levels $u_i$ and $u_j$ should be compatible, leading to mutually reinforcing decisions. In the two-stakeholder example above, reaching the (Yes,Yes) cell requires that A and B both believe in the venture's success with high confidence, which in turn requires aligning their beliefs about the venture's fundamentals.

**Coordination Update Rules:** Achieving expectation alignment in practice may require iterative updates as new information is shared. I outline a simple iterative mechanism by which an entrepreneur can drive stakeholders toward consensus:

1. **Signal Exchange:** The entrepreneur (or one of the key stakeholders) shares credible information with all parties. This could be new evidence of traction (e.g. a successful pilot, a signed customer contract) or a preliminary commitment (e.g. a lead investor agreeing to invest contingent on others). These signals serve as common knowledge inputs that can shift everyone's expectations.
2. **Belief Update:** Each stakeholder updates their internal model of the venture after receiving the new signal. In Bayesian terms, they revise their expected outcome $\mu_j(\textcolor{red}{a})$ using the evidence. For instance, if a pilot result shows the product works, both investors and customers raise their success estimates. Formally, stakeholder $j$ adjusts $u_j$ (their confidence utility) based on the signal; if I denote the signal by $\Delta$ (e.g. a change in expected growth), the update might be $u_j \leftarrow u_j + w_j \Delta$, where $w_j$ is stakeholder $j$'s weight on that evidence.
3. **Expectation Reconciliation:** The stakeholders and entrepreneur compare their updated expectations. If discrepancies remain (say one investor is still unconvinced while others are confident), further rounds of evidence or discussion occur. The entrepreneur might address specific concerns of the outlier stakeholder by providing targeted information (reducing that stakeholder's uncertainty). Through successive rounds, the goal is to **converge** the $\mu_j(\textcolor{red}{a})$ values across all stakeholders $j$. This is analogous to a consensus algorithm: each iteration should bring beliefs closer. Once all stakeholders' $\mu_j(\textcolor{red}{a})$ values (and the entrepreneur's $\mu_e(\textcolor{red}{a})$) are nearly equal, all stakeholders have a shared understanding of the venture's likely outcome.

Using $\mu_j(\textcolor{red}{a})$ consistently across both the primal-dual formulation and the appendices creates a more unified framework and reduces the total number of variables, making the model more elegant and easier to understand.

In practice, the above coordination process can be implemented in a decentralized way (each stakeholder adjusting based on observed actions of others) or centrally facilitated by the entrepreneur who orchestrates information flow. The **sigmoid decision functions** ensure that as each stakeholder’s confidence $u_i$ grows (due to alignment on a positive outlook), their commitment probability $P(d_i=1)$ sharply increases. Eventually, a tipping point is reached where every stakeholder is willing to say “yes” because they expect everyone else to say “yes” as well. By the same token, if the venture truly does not warrant support, transparent sharing of negative signals will align stakeholders on saying “no,” avoiding wasted resources. The result of successful coordination is a **simultaneous, consistent decision set** – analogous to an equilibrium where each stakeholder’s decision is optimal given the others’. The entrepreneur’s coordination mechanics thus transform what could be a game of strategic waiting into a collaborative, information-driven convergence of decisions.


# Appendix C: Primal-Dual Optimization Narrative with Visual Mapping

## C.1 Mapping EDMNO Components onto the Primal-Dual Formulation

Each core component of the EDMNO framework--**Perception** (📽️), **Coordination** (🔄), and **Sequencing(⚡)--corresponds to a particular aspect of the primal-dual optimization model. **Figure C.1** illustrates this mapping: the primal problem (uncertainty minimization) and its dual (likelihood maximization) are annotated to show which part emphasizes each component. In the primal formulation, the *entropy terms* in the objective function capture **perception** (📽️) by quantifying uncertainty in stakeholder beliefs. The *constraints* that enforce consistency across stakeholders' expectations encapsulate **coordination** (🔄), since they tie together interdependent stakeholder outcomes. Finally, the *resource budget constraint* and its Lagrange multiplier in the dual highlight **sequencing (⚡), reflecting how scarce resources focus the entrepreneur on critical actions. This formulation explicitly "connects all three components of our framework"--in perceptual modeling it optimizes information gathering (entropy reduction), in multi-stakeholder coordination it aligns predictive models across stakeholders, and in bottleneck-driven experimentation it prioritizes high information value per resource unit.

[diagram: EDMNO primal-dual mapping. Perception (📽️) corresponds to maximizing entropy/information in the primal (highlighting terms like $H(p)$) and normalization via the partition function in the dual. Coordination (🔄) corresponds to multi-stakeholder constraints in the primal (coupling different $p_j$ via shared expectations $\textcolor{green}{\mu_j}$) and to the likelihood terms $\beta_j^T\textcolor{green}{\mu_j} - \log Z_j$ in the dual that enforce cross-stakeholder consistency. Bottleneck Breaking (⚡) corresponds to the resource constraint ($\sum_j c_j \textcolor{red}{a_j} \le \textcolor{skyblue}{R}$) in the primal and the dual variable $\gamma$ (with threshold condition for $\textcolor{red}{a_j^*}$) that drives action selection under resource limits.](#)

*Figure C.1:* **EDMNO Components in the Primal-Dual Optimization Framework.** The primal problem minimizes total uncertainty (weighted entropy) subject to stakeholder expectation constraints and a resource budget, while the dual problem maximizes a weighted log-likelihood of stakeholder satisfaction minus resource cost. Icons mark the formulation pieces most associated with each EDMNO component: the entropy term ($H(p)$) for perception, coupling constraints for coordination, and the resource limit (with dual $\gamma$) for bottleneck-breaking.

## C.2 Primal and Dual Variables: From Mathematical Roles to Business Meaning

The primal-dual formulation introduces decision variables ($p$, $\textcolor{red}{a}$) and Lagrange multipliers ($\lambda$, $\beta$, $\gamma$) that carry intuitive business interpretations. **Table C.1** translates each variable into plain-English meaning and provides a startup example (from our Entrepreneurship Optimization Proposal) to illustrate:

| **Variable**                          | **Optimization Role**                                                                                                                                                                                                                                                                                                                   | **Intuitive Meaning**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | **Startup Example** (from proposal)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |     |     |
| ------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --- | --- |
| $p$ (probability distribution)        | **Primal decision variable** -- represents the probability assigned to each possible outcome scenario for a stakeholder (subject to entropy maximization).                                                                                                                                                                              | **Belief distribution for outcomes:** The entrepreneur's current bets on how a stakeholder's response or market outcome might turn out, given what actions have been taken. This reflects uncertainty about that stakeholder -- a spread-out $p$ means we're still very unsure.                                                                                                                                                                                                                                                                                                                                               | *Example:* For an eco-construction startup, $p$ could be the distribution over an **eco-builder's reactions** to a new cement product (e.g. 60% chance of mild interest, 30% chance of strong adoption, 10% chance of rejection) before running a pilot.                                                                                                                                                                                                                                                                                                                                                           |     |     |
| $\textcolor{red}{a}$ (action vector)  | **Primal decision variable** -- indicates which actions/experiments are chosen (often binary or fractional) under resource limits.                                                                                                                                                                                                      | **Chosen experiments or strategic moves:** Each component of $\textcolor{red}{a}$ corresponds to an action the startup can take, such as a test or partnership, set to 1 if selected. This encodes the plan of attack the entrepreneur decides on to reduce uncertainty.                                                                                                                                                                                                                                                                                                                                                      | *Example:* $\textcolor{red}{a} = [\text{segment}, \text{collaborate}, \text{capitalize}]$ might represent **(1) targeting a test with a lab**, **(2) approaching an eco-builder partner**, **(3) pitching to a VC**. If $\textcolor{red}{a_2}=1$ and others 0, the startup focuses on collaborating with a testing lab first.                                                                                                                                                                                                                                                                                      |     |     |
| $\lambda$ (one per stakeholder $j$)   | **Dual variable for normalization constraint** -- ensures each stakeholder's probability distribution $p_j$ sums to 1; appears in the dual as an additive term to the objective.                                                                                                                                                        | **Baseline log-likelihood / bias term:** $\lambda_j$ adjusts the "baseline" likelihood for stakeholder $j$ being fully satisfied, before considering specific evidence. In business terms, it can be seen as the inherent optimism or skepticism that stakeholder $j$ has toward the venture **absent new data** (a calibration factor making the probabilities sum to 100%). A high $\lambda_j$ (more positive) would mean a stakeholder is inherently easier to satisfy (or has fewer baseline demands), whereas a low or negative $\lambda_j$ indicates a tougher crowd requiring evidence to even reach a neutral stance. | *Example:* For an **investor** stakeholder, $\lambda_{\text{inv}}$ might start low (even negative) if the default stance is "not convinced" until proven otherwise. As the startup shows traction, effectively $\lambda_{\text{inv}}$ rises -- the investor's baseline confidence improves, boosting the overall likelihood term for the investor in the dual objective.                                                                                                                                                                                                                                           |     |     |
| $\beta$ (vector, per stakeholder $j$) | **Dual variable(s) for expectation constraint** -- Lagrange multipliers associated with matching stakeholder $j$'s predicted outcome $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ to the distribution's expectation. They appear in the dual inside $\beta_j^T \textcolor{green}{\mu_j}(\textcolor{red}{a})$ and $\log Z_j(\beta_j)$. | **Stakeholder requirement weight:** $\beta_j$ captures how strongly I need to **"tilt" stakeholder $j$'s outcome distribution** to meet their expected value $\textcolor{green}{\mu_j}$. Intuitively, $\beta_j$ reflects stakeholder $j$'s *demand level or sensitivity*: if $\beta_j$ is large in some direction, it means the stakeholder has stringent expectations on a certain metric, forcing the entrepreneur's plan to heavily favor outcomes meeting that metric. It's like the "pressure" stakeholder $j$ exerts on the solution.                                                                                  | *Example:* If a **customer** expects a certain product performance (say durability or cost savings), the corresponding $\beta_{\text{cust}}$ will adjust to ensure the probability distribution $p_{\text{cust}}$ places sufficient weight on outcomes where that expectation is met. A higher $\beta_{\text{cust}}$ might mean the startup must **heavily skew its efforts to satisfy the customer's key requirement** (e.g., by allocating R&D to meet a durability standard), since failing that drastically lowers the likelihood of customer adoption.                                                        |     |     |
| $\gamma$ (scalar)                     | **Dual variable for resource constraint** -- shadow price of the total resource $\textcolor{skyblue}{R}$, appears in dual objective as $-\gamma \textcolor{skyblue}{R}$ and in the decision rule for $\textcolor{red}{a^*}$.                                                                                                            | **Resource scarcity price / threshold factor:** $\gamma$ represents the *opportunity cost of a unit of resource*. A higher $\gamma$ means resources (time, cash) are very tight, so each dollar or week must yield a high payoff in uncertainty reduction -- it sets a **threshold for action selection**. In effect, $\gamma$ is how much "likelihood gain" I demand per unit cost. Only actions with information value per cost above $\gamma$ will be chosen. As resources become less scarce (more slack or funding), $\gamma$ drops, lowering the bar for which actions are worth doing.                                | *Example:* Early in the project, with a tiny budget, $\gamma$ is high -- the startup only does the most critical experiment (e.g., a small pilot that addresses the biggest unknown). After raising funds, $\gamma$ falls, and more experiments (like scaling up a prototype or testing secondary features) clear the bar. In the **TAXIE** EV rideshare case, initially $\gamma$ was effectively high, so they tested with just 2 cars (only that limited experiment had a justifiable info-per-cost ratio). With more capital, they could afford a broader rollout of 50 cars to tackle secondary uncertainties. |     |     |

*Table C.1:* **Primal and Dual Variables in Business Terms.** This table links each mathematical variable to an intuitive role in entrepreneurial decision-making, along with concrete examples. For instance, $p$ and $\textcolor{red}{a}$ correspond to the startup's beliefs and action choices (which experiment to run), while the dual variables $\lambda$, $\beta$, $\gamma$ correspond to the underlying "pressures" of the problem: stakeholders' baseline attitudes ($\lambda$), their specific demands ($\beta$), and the scarcity of resources ($\gamma$).

## C.3 The Partition Function $Z_j(\beta_j)$: Normalization and the "Menu" of Outcomes

In the dual formulation, each stakeholder $j$ contributes a term $-\log Z_j(\beta_j)$, where

$$
Z_j(\beta_j) \;=\; \sum_{k} \exp\!\big(\beta_j^T f_{jk}\big)\,,
$$

summing over all possible outcome states $k$ for that stakeholder. This $Z_j(\beta_j)$ is the **partition function**, and its role is to ensure probabilities for stakeholder $j$ are properly normalized when I convert the constraints into a likelihood. In plain terms, $Z_j$ **"accounts for all possible outcomes"** when computing the likelihood of any one outcome.

**Intuition (Menu Analogy):** Imagine stakeholder $j$ has a "menu" of possible outcomes (for example, a customer might either love the product, like it, be neutral, or reject it). The exponentiated term $\exp(\beta_j^T f_{jk})$ can be thought of as the "score" or weight for outcome $k$ given the current dual parameters $\beta_j$. The partition function $Z_j(\beta_j)$ is like summing up the scores of **every item on the menu**. By dividing an individual outcome's score by this total $Z_j$, I get a probability (just as each item's popularity could be expressed as a fraction of all items' combined popularity). In other words, $Z_j$ is the normalizing denominator that makes all the outcome probabilities add up to 1. If stakeholder $j$ has many favorable possible outcomes (or a high uncertainty, meaning many outcomes get moderate weight), $Z_j$ will be larger; if $j$'s requirements and $\beta_j$ strongly favor only a few outcomes, $Z_j$ will be smaller (concentrating probability on those outcomes).

Crucially, the partition function also influences the **likelihood** of satisfying stakeholder $j$. A smaller $Z_j(\beta_j)$ (all else equal) means the probability mass is concentrated on high-scoring outcomes -- effectively, stakeholder $j$'s expectations leave fewer "acceptable" outcomes, but those few are being targeted. A larger $Z_j$ means a wider spread of possible outcomes, implying more uncertainty or more ways things could go (not all of which are good for the venture). In the dual objective, I see $-\log Z_j(\beta_j)$: this term **rewards** the solution when $Z_j$ is lower (since $-\log Z_j$ is higher), i.e. when the outcomes are more narrowly focused on meeting stakeholder $j$'s expectations. Thus, minimizing $Z_j$ (without violating the mean outcome constraint) is equivalent to maximizing the likelihood that stakeholder $j$ ends up satisfied. The partition function is the mathematical vehicle for this normalization: it converts the constraint "meet stakeholder $j$'s expected value $\textcolor{green}{\mu_j}$" into a probabilistic likelihood of success for that stakeholder by considering all possible outcome scenarios consistent with that expectation.

## C.4 Dual Objective as Likelihood Maximization

The dual optimization problem can be interpreted as **maximizing a weighted likelihood** that all stakeholders will be satisfied given the chosen actions. In our formulation, the dual objective is:

$$
\max_{\lambda,\beta,\gamma}\;\;\sum_{j} \textcolor{violet}{w_j}\Big(\lambda_j + \beta_j^T \textcolor{green}{\mu_j}(\textcolor{red}{a_j}) - \log Z_j(\beta_j)\Big)\;-\;\gamma \textcolor{skyblue}{R}\,,
$$

where $\textcolor{violet}{w_j}$ is the weight of stakeholder $j$. Each term $\lambda_j + \beta_j^T \textcolor{green}{\mu_j} - \log Z_j(\beta_j)$ inside the sum is essentially the **log-likelihood for stakeholder $j$** under the optimal distribution (it derives from enforcing that $p_j$ matches the expected outcome $\textcolor{green}{\mu_j}$). Multiplying by $\textcolor{violet}{w_j}$ just scales it by the stakeholder's importance. Summing across $j$ thus accumulates a kind of **"total log-likelihood" that all stakeholders' requirements are met**, up to the weighting. Finally, the term $-\gamma \textcolor{skyblue}{R}$ subtracts the "cost" of using resources $\textcolor{skyblue}{R}$ with shadow price $\gamma$.

This dual can be understood in everyday terms: I are choosing the dual variables (which relate to stakeholder satisfaction criteria and resource tightness) to **maximize the probability of overall venture success** (subject to the resource limit). By strong duality, this is equivalent to the primal goal of minimizing uncertainty. But the dual viewpoint is particularly enlightening for narratives -- it frames the problem as *likelihood maximization*:

* **Plain English interpretation:** I want to make it as **likely as possible** that every stakeholder is happy with the outcome *at the same time*, given I can only spend $\textcolor{skyblue}{R}$ resources. The dual objective captures this by boosting the score when stakeholder $j$'s likelihood of satisfaction increases (through the $-\log Z_j$ term) and penalizing if I use too much resource (through $\gamma \textcolor{skyblue}{R}$). In essence, it's a balancing act: allocate effort (via $\beta_j$ adjustments and picking actions $\textcolor{red}{a}$ that influence $\textcolor{green}{\mu_j}$) such that the *joint likelihood* of satisfying all parties is maximized.

* **Startup scenario example:** Think of a founding team considering their next moves. They might say, "What course of action gives us the **best shot that both the customer and the investor end up happy?**" This is exactly what the dual is asking. Suppose running a pilot project will greatly increase the chance customers love the product and also give investors data to be confident -- that corresponds to increasing the terms inside $\sum_j(\cdot)$ for those stakeholders (higher log-likelihood for each). If the pilot is expensive, $\gamma$ will rise to reflect the cost, but if it's the only way to significantly boost those success probabilities, the trade-off might still be worth it. The dual objective helps formalize this trade-off: an optimal solution would indicate if the likelihood gains (customers + investors being satisfied) per dollar spent are worth the cost. If yes, $\gamma$ adjusts such that the inequality $\textcolor{violet}{w_j}[\lambda_j + \beta_j^T\textcolor{green}{\mu_j}(1) - \log Z_j] > \gamma c_j$ holds for that action, meaning action $j$ (the pilot) is chosen. In practical terms, that inequality is the rule: *"Do action $j$ if its contribution to stakeholder-satisfaction likelihood (left side) exceeds the resource cost threshold (right side)."*

When the dual objective is maximized, it corresponds to a point where **any feasible change would lower the combined likelihood of stakeholder satisfaction (or violate the resource limit)**. This is why I say the dual solution yields a **likelihood-maximizing plan**: it's the set of stakeholder probability distributions and chosen actions such that I couldn't make all-around stakeholder happiness any more probable without more resources. Entrepreneurs intuitively seek this outcome -- they often speak of *de-risking* the venture. In dual terms, de-risking means **increasing the likelihood of success** (for investors, customers, partners, etc.) by reducing uncertainty. For example, by doing a well-chosen pilot test, you reduce investors' uncertainty, which *increases the probability they will invest.* That is literally an increase in the "likelihood term" associated with the investor stakeholder. As uncertainty falls, the dual objective's value (summed log-likelihood) rises, reflecting a more confident, credible venture.

To ground this in a scenario: imagine an early-stage clean-tech startup. Initially, the chance that **customers** will adopt the product might be low because they doubt its reliability; similarly, the **investor** might assign a low chance to the startup hitting cost targets. The entrepreneur can do a targeted experiment, say a prototype demonstration, that convinces both groups (customers see reliability, investor sees cost data). This single action will dramatically increase the likelihood of customer and investor satisfaction (their individual probabilities shoot up). In the dual formulation, $\log Z_{\text{cust}}$ and $\log Z_{\text{inv}}$ drop (since their distributions tighten around "success"), and thus the objective sum increases. The resource cost of the demo enters via $\gamma$, but if the demo is highly informative, the optimal $\gamma$ will adjust such that it is worthwhile to spend that resource. The end result is the **maximum likelihood** configuration: the venture has maximized the weighted log-probability of meeting all stakeholders' expectations, given its budget.

## C.5 Stakeholder Satisfaction as a Weighted Log-Likelihood

I often refer to the dual objective as maximizing the "weighted log-likelihood of all stakeholders being satisfied/accurate." Let's unpack this phrase. Each stakeholder's "satisfaction" essentially means **their internal model of the venture matches the eventual reality**--in other words, the outcome met their expectations. For an investor, being satisfied might mean the company achieved the milestones or traction they expected; for a customer, it means the product performed as promised; for a regulator, it means compliance standards were met. If each stakeholder's expectations are like hypotheses about the venture, then stakeholder $j$ being satisfied is the event that hypothesis is confirmed by results.

The dual formulation gives each stakeholder $j$ a log-likelihood contribution $\mathcal{L}_j = \lambda_j + \beta_j^T\textcolor{green}{\mu_j} - \log Z_j(\beta_j)$. Exponentiating (and ignoring weights $\textcolor{violet}{w_j}$ for a moment), $\exp(\mathcal{L}_j)$ is proportional to the probability that stakeholder $j$'s expectations hold true (since it's essentially the probability of the "successful" outcomes for stakeholder $j$ under the optimized distribution). If I consider all stakeholders at once, a simplifying (though conceptual) view is to imagine the probability that **every** stakeholder is satisfied as roughly the product of the individual probabilities $\prod_j P(\text{stakeholder }j \text{ satisfied})$. Maximizing this joint probability is equivalent to maximizing the sum of logs, $\sum_j \log P(j\text{ satisfied})$. Our dual exactly does a weighted version of this: $\sum_j \textcolor{violet}{w_j} \log P(j\text{ satisfied})$. The weights $\textcolor{violet}{w_j}$ allow the model to emphasize some stakeholders more (perhaps an investor's satisfaction is crucial, so its weight is higher, whereas a minor partner's satisfaction is less critical and might get a lower weight).

In practice, **if one stakeholder is very important**, the solution will allocate actions to boost that stakeholder's likelihood of satisfaction even if it slightly hurts others, reflecting the weighting. The phrase "all stakeholders being satisfied" doesn't mean every stakeholder absolutely must be happy in the end, but that I are considering the combined likelihood (with weights) of satisfying everyone as much as possible. I are effectively maximizing a weighted geometric mean of stakeholder satisfaction probabilities.

Importantly, **stakeholder satisfaction = their model matches reality**. This is captured in the primal by the constraint that each stakeholder's expected value $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ is met by the distribution $p_j$, and in the dual by the terms involving $\beta_j$ and $Z_j$. When the dual objective is high, it means each stakeholder's predicted outcome is likely to occur (their distribution $p_j$ is peaked around the expectation). Thus a high dual objective corresponds to a state where **stakeholders' mental models are accurate** -- they guessed what would happen, and the venture delivers on those guesses. This is exactly what satisfaction means: no nasty surprises, only fulfilled expectations.

From an entrepreneurial perspective, achieving this is gold: it means *every major backer or participant in your venture feels vindicated*. The investor saw the growth they hoped for, the customer got the value they were promised, the team met the technical goals -- all stakeholders' internal narratives align with the venture's actual trajectory. The weighted log-likelihood formulation mathematically encodes this alignment and rewards the entrepreneur for configurations that enhance it.

It's worth noting that **disagreement or misalignment among stakeholders often signals innovation potential**. If stakeholders initially have very different beliefs (for instance, one investor thinks the idea is brilliant while another is skeptical), that indicates a novel, uncertain venture. Research in entrepreneurial finance and strategy has noted that such divergence in beliefs can motivate entrepreneurial action: for example, an overconfident entrepreneur (holding a belief much more optimistic than others) might pursue an idea that common consensus would skip. This "disagreement" can be a predictor of innovation as it means not everyone agrees on the outcome -- in other words, there's uncertainty to exploit. Our model starts with possibly high entropy (un-aligned stakeholder views) and through experiments and coordination, aims to align beliefs (reduce entropy), effectively **turning stakeholder disagreement into agreement via evidence**. Scholars have also observed that misaligned expectations can stall innovation if not addressed: a promising idea might languish if, say, regulators remain unconvinced while entrepreneurs forge ahead. Thus, maximizing the weighted log-likelihood of stakeholder satisfaction isn't just a mathematical exercise -- it corresponds to the very real task of **getting everyone on the same page**. When achieved, it indicates that the venture has resolved most uncertainties to the point that all key players believe in it. The dual optimum, therefore, represents a state of maximal consensus (weighted by importance) grounded in reality, which is precisely when a venture is most likely to succeed.

*(Footnotes: As Eric Van den Steen and others have theorized, a strategic decision is often one about which competent people may disagree -- the presence of differing priors is what gives strategy (and innovation) its significance. And Bernardo & Welch (2001) argue that entrepreneurs' apparent overconfidence (beliefs differing from the crowd) can be what drives them to attempt breakthroughs. However, until those differences in expectation are reconciled by evidence, innovative projects face friction. The framework here can be seen as a way to systematically reconcile those expectations.)*

## C.6 From High $\gamma$ to Low $\gamma$, High $\lambda$ to Low $\lambda$: Increasing Certainty and Decreasing Interdependence

Innovative decision-making often progresses through **phases** -- early on, uncertainty and interdependence are high, and later on they diminish as the venture "finds its groove." In our primal-dual terms, this corresponds to moving **from high to low values of certain dual variables ($\gamma$ and $\lambda$)**.

* **Resource Scarcity ($\gamma$) High to Low:** In the earliest stage of a startup, resources are extremely limited -- the dual variable $\gamma$ starts high, meaning the threshold for taking an action is very stringent. The entrepreneur can only afford experiments that have a huge bang-for-buck in reducing uncertainty. This is the **"nail it" phase** (to use a common phrase), where you focus on the single biggest unknown. For example, in the Segway case (personal transporter innovation), early development funds were tight, so they might have only tackled the most critical question (perhaps technical feasibility) before anything else. As the venture proves aspects of the idea and perhaps raises more capital or generates revenue, the effective $\gamma$ drops. More resources become available, so the criterion for acceptable experiments eases. The startup enters a growth or **"scale it" phase** -- $\gamma$ now low -- where it can pursue second-order questions and optimizations (additional features, broader tests) that earlier would have been tabled. In short, **high $\gamma$** = extremely selective, only sure-win moves; **low $\gamma$** = can take moderate-risk or exploratory moves because resources allow. This trajectory from high to low $\gamma$ reflects *increasing certainty about the venture's core viability* (hence investors or revenues are providing slack) and thus the venture is less bottlenecked by each dollar.

* **Stakeholder Alignment ($\lambda$) High to Low:** Early on, stakeholders are not on the same page. One way to think of $\lambda_j$ (from each stakeholder's normalization constraint) is as a measure of how much "baseline adjustment" was needed to calibrate that stakeholder's probability distribution. In an unaligned situation, some stakeholders might effectively have very low prior likelihood to be satisfied -- requiring a large $\lambda_j$ correction upward once evidence starts coming in (or vice versa). **High $|\lambda|$** in the beginning can indicate that, without evidence, stakeholders either wildly overestimate or underestimate the chances of success (differing priors). As the entrepreneur gathers data and demonstrates progress, stakeholders update their models. The need for a large offset $\lambda_j$ diminishes; stakeholders begin to share a more common expectation grounded in reality. Thus **$\lambda$ values tend toward zero or a moderate level** as alignment is achieved. In our context "from high to low $\lambda$" means moving from a state where stakeholders had strongly different initial biases (requiring significant adjustment) to a state where stakeholders have been calibrated and their beliefs are close to the truth (minimal bias). Essentially, the venture goes from a **heterogeneous belief state** to a more **consensus belief state**. For instance, if an investor initially thought the market size was tiny (low prior) while the founder thought it was huge, the truth might be somewhere in between -- early on, the dual might need a large $\lambda_{\text{inv}}$ to satisfy the investor's constraint once some evidence is shown. Later, both founder and investor converge on a similar view of the market, so $\lambda_{\text{inv}}$ can relax. Lower $\lambda$ indicates less disagreement between stakeholder expectations and the achieved outcomes; it marks **increasing certainty and trust** among the players.

* **Environment: From Dynamic to Static Expected Outcomes:** In early stages, the expected outcomes $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ for each stakeholder $j$ are highly context-dependent, stochastic or rapidly changing: one action can have unpredictable ripple effects across stakeholders. For example, when **Segway** was first introduced, an action like a public launch could cause significant changes in $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ for multiple stakeholders simultaneously in unpredictable ways -- media hype, government regulatory responses, consumer curiosity or backlash -- a highly dynamic, coupled system. Similarly, our material startup (e.g. a sustainable cement venture "Sublime Systems") in its pilot phase faced dynamic interactions: getting a test facility on board (action $\textcolor{red}{a_1}=1$) could suddenly change the expected outcomes $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ for customer interest and investor commitment in nonlinear ways (perhaps the expected values for two stakeholders jump significantly after one breakthrough). 

  Over time, once the venture has "tipped" into wider acceptance (e.g., the expected outcomes $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ for most key stakeholders are sufficiently high), the system's evolution becomes more **static or predictable**. In later stages, $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ might respond in more deterministic ways to actions: for a mature product, doing a standard scale-up (action) leads to a fairly predictable result (expected outcomes change smoothly, e.g. sales grow in a known pattern). The interdependence between stakeholders decreases -- by then, each stakeholder has mostly committed, and their expected outcomes $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ are not so contingent on one another at every step. In the Segway story, after initial hurdles, if it had gained regulatory approval in major cities and some consumer adoption, further actions like marketing would have had straightforward effects on $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ (more sales, basically a traditional scenario). For the cement startup, once the testing authority, an eco-builder, and a major investor all have high $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ values (full acceptance), the next state transitions (like expanding production) don't involve one stakeholder's expected outcome dramatically altering another's stance; the stakeholders' expectations are now set, and the remaining work is executional (static in relative terms).

These transitions--**high $\gamma$ to low $\gamma$, high $\lambda$ to low $\lambda$, dynamic to static expected outcomes**--all reflect the venture moving from a chaotic, uncertain **exploration phase to a more stable exploitation phase**. In doing so, **certainty increases** (I know more about what works, stakeholders have evidence and are confident) and **interdependence decreases** (decisions become more modular as stakeholder commitments firm up).

To make this concrete, consider **Sublime Systems**, the sustainable cement startup example we've used. Initially, it's in "Nail-It" mode with three critical stakeholders: a testing lab (for validating the cement), an eco-conscious builder (customer), and a climate-focused VC (investor). At the very start, $\gamma$ is high -- they maybe only have funds for one major test. They choose the test that will break the biggest uncertainty bottleneck: getting the cement certified by the testing lab (setting $\textcolor{red}{a_1}=1$). At this point, the expected outcomes $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ are dynamic: if the lab test is successful, it drastically reduces the builder's uncertainty (maybe $\mu_{\text{builder}}(\textcolor{red}{a})$ jumps significantly as a result, because the builder was waiting on validation). This is a dynamic chain reaction. Also, initially the lab and builder may not have believed the cement would work (their $\lambda$ adjustments were large when evidence comes). 

Once the lab validation is secured, $\gamma$ drops a bit (they might get a bit more funding or at least they know they don't need to test that again) and now they can do a pilot with an eco-builder (setting $\textcolor{red}{a_2}=1$). The system still has some dynamics (perhaps that success convinces the investor, so $\mu_{\text{investor}}(\textcolor{red}{a})$ increases significantly after $\mu_{\text{builder}}(\textcolor{red}{a})$ does -- another dynamic jump). By the time the expected outcomes for two of the three stakeholders are high, they reach a critical mass (an inflection point). 

Now they enter "Scale-It": $\gamma$ is much lower (they raised a VC round, so more resources), $\lambda$ for all stakeholders is near a stable value (everyone's expectations are aligned that this will work and be profitable), and $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ becomes more predictable. If they invest resources (action $\textcolor{red}{a_3}=1$) to build a full production plant, the outcome is mostly deterministic growth in output and revenue -- not a wild card. The stakeholders are committed, so further actions don't have to juggle delicate interdependencies. In summary, the venture moved from a **highly-coupled, high-uncertainty regime** to a **decoupled, low-uncertainty regime**. The primal-dual model captures this as moving along the dual variables: $\gamma$ and $\lambda$ relaxing, and in the problem structure: $\textcolor{green}{\mu_j}(\textcolor{red}{a})$ effectively becoming more predictable and less interdependent as the expected outcomes for all stakeholders reach satisfactory levels.
## C.7 Prioritizing High-Value Experiments in Resource-Constrained Settings

A recurring theme in this appendix is that entrepreneurs must choose carefully **which experiments to run**, especially when resources are limited. Academic work supports this idea: *not all experiments are equal*, and doing the ones with the greatest information yield or option value first is crucial. Kerr, Nanda, and Rhodes-Kropf (2014) describe entrepreneurship itself as a form of **experimentation under constraints**, noting that only a few experiments will succeed and that **costs and constraints govern how much experimentation can be done and even the trajectory of innovation**. In practical terms, this means a startup should tackle experiments that either validate the venture’s core hypotheses or unlock major stakeholder commitments before spending resources on smaller questions. Their work emphasizes that the distribution of outcomes is “extremely skewed” – most projects fail or give low returns, and a few give huge returns. Therefore, an entrepreneur with one shot (high $\gamma$ early on) should choose an experiment that, if it works, yields a disproportionately large leap in venture progress (for example, proving the technology works *and* that customers want it, in one go).

Our framework’s bottleneck-driven approach (⚡) aligns with this logic. It effectively says: **find the bottleneck uncertainty (the experiment that has the highest ratio of uncertainty reduction to cost) and do that first**. This mirrors the recommendation in *Entrepreneurship as Experimentation* to focus on high “real option” value projects when financing is tight. When resources are constrained, entrepreneurs act like scientists with a very limited supply of lab reagents – they must design experiments that maximize learning per dollar. Oftentimes, this means designing tests that simultaneously address multiple stakeholder concerns (as our multi-stakeholder coordination 🔄 component advises). For instance, instead of testing a product feature in isolation, a startup might do an integrated pilot that tests the technology, gets customer feedback, and provides data to investors in one fell swoop. This consolidated experiment might be costly, but its **information value is enormous**, and if it succeeds it can justify further investment. Conversely, an experiment that yields only marginal insight should be deprioritized when every dollar counts.

One way to formalize this prioritization is through a **stopping rule for experimentation**, derived from balancing the costs of testing with the risks of not testing (false positives vs false negatives). In the user’s proposed “📦 Multiple Hypothesis Testing + Inventory Management” framework, the decision of how many experiments to run can be likened to an optimal order quantity problem balancing two types of errors:

* Type I error (false positive) = launching something that fails (analogous to overstocking inventory that doesn’t sell).
* Type II error (false negative) = failing to pursue something that would have succeeded (analogous to understocking and missing sales).

By assigning a cost to each type of error, one can derive an optimal number of tests $n^*$ that minimizes total expected “error cost”. A simplified quantitative stopping rule from that framework is:

$$
n^* \;=\; \sqrt{\frac{\alpha^2 \,\big(\mu - \phi_{\text{true}}\big)\,\big(\mu/\phi_{\text{true}}\big)}{c^y}}\;-\;\alpha\,,
$$

where each parameter is defined as follows:

* $\mu$ = the prior believed probability of success for the venture/hypothesis (before running new experiments).
* $\phi_{\text{true}}$ = the true probability of success (the actual outcome frequency if I knew it – in practice, I infer this after some testing).
* $\alpha$ = a prior confidence level (the strength of our initial belief, expressed as a multiplier – higher $\alpha$ means I were more confident in $\mu$ and thus require more evidence to change our mind).
* $c^y$ = the cost of one experiment (normalized as a fraction of total resources or in relative terms such that the formula is dimensionless).

This formula comes from equating the marginal benefit of reducing uncertainty with the marginal cost of additional tests, akin to the economic order quantity formula in inventory management. Intuitively, $\alpha^2(\mu - \phi_{\text{true}})$ represents the squared error in our prior belief (weighted by prior strength) – a larger discrepancy between what I believed ($\mu$) and reality ($\phi_{\text{true}}$) increases the desired sample size. The factor $(\mu/\phi_{\text{true}})$ further inflates the required tests if I were overly optimistic ($\mu > \phi_{\text{true}}$) – essentially penalizing “overconfidence” by demanding more evidence. Meanwhile, dividing by $c^y$ means the cheaper the experiment, the more tests I can afford (so I increase $n^\*$ if cost per test is low). Finally, subtracting $\alpha$ accounts for the fact that if I already have strong prior evidence (high $\alpha$), I need fewer new tests beyond what’s implicit in that prior.

**Example – TAXIE case:** TAXIE was an electric taxi startup used in our discussions, which needed to decide how many pilot cars to test. They had a prior belief of $\mu = 0.5$ that the concept would succeed (moderate optimism), but in reality the market success probability $\phi_{\text{true}}$ turned out to be 0.2 (quite low). Their prior confidence was $\alpha = 2$ (meaning the prior was based on limited information, a relatively weak prior). The cost per car test was estimated as $c^y = 0.15$ (perhaps 15% of their initial budget per car). Plugging these into the formula:

$$
n^* = \sqrt{\frac{2^2 \times (0.5 - 0.2) \times (0.5/0.2)}{0.15}}\;-\;2 
= \sqrt{\frac{4 \times 0.3 \times 2.5}{0.15}}\;-\;2 
= \sqrt{20}\;-\;2 
\approx 4.47\;-\;2 \approx 2.47\,.
$$

They should run about $2.47$ experiments – in practice, of course, this means **2 to 3 test cars**. Indeed, TAXIE proceeded with a pilot of 2 cars, which our calculation suggests was near-optimal. Those tests yielded critical information: they confirmed some hypotheses (range was sufficient, drivers earned what was expected, customers were willing to pay a target price) and refuted others (the service wasn’t profitable at small scale). Stopping after 2-3 cars was justified because the incremental learning from a 3rd or 4th car was not worth the cost at that early stage – better to pause and reassess with the data in hand (which is exactly what the startup did).

This stopping rule exemplifies how an entrepreneur can quantitatively plan an experimental campaign. It says: “Run just enough tests such that the expected cost of remaining uncertainty equals the cost of the testing itself.” If you test too little, you risk a Type II error (missing out on a viable venture due to undetected potential, or not realizing a flaw before scaling – costly in hindsight). If you test too much, you risk Type I error or simply waste resources (diminishing returns – you might confirm what you already know while burning cash and time). The formula helps find a sweet spot. In sum, the entrepreneur should prioritize the highest-value experiment (largest $\mu - \phi_{\text{true}}$ impact per cost) and continue testing until the value of information drops off. This approach merges statistical thinking (hypothesis testing) with economic thinking (inventory/resource optimization), ensuring that in a resource-constrained setting, **every experiment is worth it** and the process stops at the right time to either pivot or double-down.

# Appendix D: 

#### Definition (Entrepreneurial decision making model with nonlinear and opportunity dependent objective):
Given rational matrices $A_t$ ($N \times M$) and $R_t$ ($N \times P$), rational vectors $b_t$ ($M$) and $c_t$ ($P$) for $t \in 1, \ldots, T$, a set of opportunity states $\textcolor{blue}{\Omega} = {\textcolor{blue}{\omega_1}, \ldots, \textcolor{blue}{\omega_Q}}$, a non-additive uncertainty function $\textcolor{blue}{U}: \mathbb{R}^{P \times T} \times \textcolor{blue}{\Omega} \rightarrow \mathbb{R}$, and a rational number $L$, does there exist a sequence of integral vectors $x_1, \ldots, x_T$ (each of length $N$) such that $A_tx_t \leq b_t$ for all $t$, and $\textcolor{blue}{U}({R_tx_t - c_t}_{t=1}^T, \textcolor{blue}{\omega}) \leq L$ for some $\textcolor{blue}{\omega} \in \textcolor{blue}{\Omega}$, where $\textcolor{blue}{U}$ is non-additive in its first argument and represents uncertainty to be minimized?

#### Definition 5 (ILP)

Given rational matrix $A$ and rational vector $b$, does $Ax \leq b$ have an integral solution $x$?

#### Definition 6 (0-1 KNAPSACK)

Given integers $a_j$, $j = 1, \ldots, n$, and $K$, is there a subset $S$ of ${1, \ldots, n}$ such that $\sum_{j\in S} a_j = K$?

using https://chatgpt.com/c/681af59b-a76c-8002-b39d-dc10ebc48a83
## Formal Proof: Reduction from 0-1 KNAPSACK to EDM

**Proof.** We first show EDMNO is in NP, then show 0-1 KNAPSACK (BKS) polynomially transforms to EDMNO.

1. EDMNO is in NP: A solution to EDMNO can be verified in polynomial time by checking the constraints $A_tx_t \leq b_t$ for all $t$ and calculating $U({R_tx_t - c_t}_{t=1}^T, \omega)$ for each $\omega \in \Omega$ to compare with $L$, which can be done in $O(NMT Q)$ time.

Given an instance of BKS with items ${1, \ldots, n}$, values $a_j$, and target sum $K$, we construct an EDMNO instance as follows:

- Time periods: $T = {1}$ (single period)
- Decision variables: $x = (x_1, \ldots, x_N)$, where $x_n \in {0, 1}$
- Constraint matrix $A_1$: Identity matrix of size $N \times N$ (so $M = N$)
- Constraint vector $b_1$: $(1, \ldots, 1)$ of length $N$
- Return matrix $R_1$: Identity matrix of size $N \times N$ (so $P = N$)
- Cost vector $c_1$: $(a_1, \ldots, a_N)$ where $a_n$ are the values from 0-1 KNAPSACK
- Opportunity states: $\textcolor{blue}{\Omega} = {\textcolor{blue}{\omega_1}, \textcolor{blue}{\omega_2}}$ (so $Q = 2$)
- Utility function: $\textcolor{blue}{U}(y, \omega) = \begin{cases} \sum_{n=1}^{N} y_n & \text{if } \omega = \textcolor{blue}{\omega_1} \ \sum_{n=1}^{N} y_n^2 & \text{if } \omega = \textcolor{blue}{\omega_2} \end{cases}$, where $y = R_1x_1 - c_1$
- Target utility $L$: Same as the 0-1 KNAPSACK target sum $K$

This construction ensures:

a) **Non-additivity**: The utility function $\textcolor{blue}{U}(x, c, \omega)$ is non-additive because there exist vectors $x, y \in {0, 1}^n$ and states $\textcolor{blue}{\omega_1}, \textcolor{blue}{\omega_2} \in \textcolor{blue}{\Omega}$ such that $\textcolor{blue}{U}(x + y, c, \textcolor{blue}{\omega_1}) = \textcolor{blue}{U}(x, c, \textcolor{blue}{\omega_1}) + \textcolor{blue}{U}(y, c, \textcolor{blue}{\omega_1})$, but $\textcolor{blue}{U}(x + y, c, \textcolor{blue}{\omega_2}) \neq \textcolor{blue}{U}(x, c, \textcolor{blue}{\omega_2}) + \textcolor{blue}{U}(y, c, \textcolor{blue}{\omega_2})$. Specifically, for $x = (1, 0, ..., 0)$ and $y = (0, 1, ..., 0)$:

When $\omega = \textcolor{blue}{\omega_1}$: $\textcolor{blue}{U}(x + y, c, \textcolor{blue}{\omega_1}) = c_1 + c_2 = \textcolor{blue}{U}(x, c, \textcolor{blue}{\omega_1}) + \textcolor{blue}{U}(y, c, \textcolor{blue}{\omega_1})$

When $\omega = \textcolor{blue}{\omega_2}$: $\textcolor{blue}{U}(x + y, c, \textcolor{blue}{\omega_2}) = 0 \neq 0 + 0 = \textcolor{blue}{U}(x, c, \textcolor{blue}{\omega_2}) + \textcolor{blue}{U}(y, c, \textcolor{blue}{\omega_2})$

This demonstrates that the utility function is additive in state $\textcolor{blue}{\omega_1}$ but not in state $\textcolor{blue}{\omega_2}$, thus establishing its overall non-additive nature.

b) **Opportunity-dependence**: The utility function's value explicitly depends on the opportunity state $\textcolor{blue}{\omega}$. For any non-zero vector $x \in {0, 1}^n$ with at least one non-zero $c_j$:

- When $\omega = \textcolor{blue}{\omega_1}$: $\textcolor{blue}{U}(x, c, \textcolor{blue}{\omega_1}) = \sum_{j=1}^{n} c_jx_j \neq 0$
- When $\omega = \textcolor{blue}{\omega_2}$: $\textcolor{blue}{U}(x, c, \textcolor{blue}{\omega_2}) = 0$

This demonstrates that the same input $x$ can yield different utility values depending on the opportunity state $\textcolor{blue}{\omega}$.

**(If)** If the 0-1 KNAPSACK problem has a solution $S$ such that $\sum_{j\in S} c_j = K$, then setting $x_j = 1$ for $j \in S$ and $x_j = 0$ for $j \notin S$ provides a solution to the EDMNO instance, as $\textcolor{blue}{U}({R_1x + c_1}, \textcolor{blue}{\omega_1}) = K = L$.

**(Only if)** If the EDMNO instance has a solution $x$ such that $\textcolor{blue}{U}({R_1x + c_1}, \textcolor{blue}{\omega_1}) = L$, then the set $S = {j : x_j = 1}$ is a solution to the 0-1 KNAPSACK problem, as $\sum_{j\in S} c_j = L = K$.

Therefore, EDMNO is NP-complete.

**Note on Single-Period Simplification**: The EDMNO problem presented here is a single-period simplification of the more general multi-period entrepreneurial decision-making problem, capturing essential elements while allowing for a clear reduction from 0-1 KNAPSACK. The NP-completeness of this single-period version implies that the multi-period version is at least NP-hard.
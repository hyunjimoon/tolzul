# Editorial Feedback on “Perishable Commitment and Dynamic Entrepreneurial Strategy: A Unified Prediction-Prescription Framework”

*Dear Authors,*

Thank you for the opportunity to read this ambitious and thought-provoking manuscript. As an editor in the Operations Management (OM) department at *Management Science*, I am **excited by the novel integration** you propose between entrepreneurial strategy and OM techniques. The paper tackles a *timely and important problem* – how entrepreneurs can balance rapid action with learning under extreme uncertainty and “perishable” opportunities. This *push-pull (prediction-prescription) framework* is a creative idea with potential to contribute to both the entrepreneurship and operations literatures.

In the following, I provide **enthusiastic encouragement** for what I see as the strengths of the work, and then offer **rigorous critique and suggestions** on areas that can be improved. My goal is to help sharpen the manuscript’s theoretical contribution, modeling rigor, clarity of exposition, literature positioning, and overall impact. I appreciate the genuine effort and clear passion that went into this draft; with revisions addressing the points below, I believe it can become a *strong contribution*.

## Strengths of the Manuscript

* **Important Phenomenon:** The paper spotlights a crucial entrepreneurial dilemma – the need to secure stakeholder commitments quickly (before the window closes) despite high uncertainty. This “perishable commitment” challenge is very real (illustrated vividly by Webvan, Better Place, Tesla, etc.) and has not been formally addressed in prior OM models. Framing it as a *degenerate optimization problem* (more decision variables than constraints) is intriguing and captures the messy reality entrepreneurs face.

* **Integration of Prediction and Prescription:** The core contribution – integrating predictive learning with prescriptive action – is compelling. You effectively argue that pure “predictive” approaches (analysis paralysis) and pure “prescriptive” approaches (blind betting) each have fatal flaws in fast-moving environments, and you motivate a *unified framework* that can overcome those flaws. This resonates strongly with recent interests in **prescriptive analytics** and adaptive decision-making in OM. It also aligns with calls in entrepreneurship research for more **evidence-based, iterative strategy** (e.g. the spirit of lean startup experiments). The manuscript’s *push-pull framework* (learning while acting) is conceptually powerful.

* **Modeling Innovation:** The progression of three analytical models (linear stakeholder responses, sigmoid responses, and asymmetric sensitivities) is well-structured. Each extension adds realism and yields additional insights. By reframing the classical **newsvendor problem** from inventory quantity to *product quality under multi-stakeholder uncertainty*, you bring a fresh OM perspective to entrepreneurial strategy. I especially liked the closed-form solutions in the simpler cases (Proposition 1 and 2) – those provide clear intuition (e.g., the *cost-priority principle* and the effect of match value \$V\$ on optimal quality). The asymmetric case (G2) is more complex, but the special-case solutions and comparative statics (e.g., Customer-dominant vs Partner-dominant scenarios) are insightful and help the reader see the impact of different sensitivity parameters. Overall, the modeling work shows **originality** in adapting OM frameworks to a new context.

* **Theoretical Contribution:** You identify relevant theories (stakeholder salience, dynamic capabilities, behavioral decision biases) and position your work as contributing to them. I found it helpful that you connect your framework to **stakeholder theory** (Mitchell et al., 1997) and explicitly discuss the notion of **“perishable commitment”** – which extends ideas of commitment timing from strategy literature (e.g., Ghemawat, 1991) into a new light. The connection to **dynamic capabilities** is also promising: by providing a mathematical foundation for “sensing” (learning) and “seizing” (acting) concurrently, you potentially contribute to the quantitative grounding of dynamic capabilities in entrepreneurial contexts. This is an area where OM tools can enrich strategy theory, and your work moves in that direction.

* **Clarity and Exposition (Overall):** The manuscript is *engagingly written*. The use of vivid metaphors and examples (perishable produce, changing city maps, “48 hours in a day” etc.) makes the complex concepts approachable and emphasizes the intuition behind the models. The Tesla Roadster running example is effective – it gives a real-world anchor to the abstract models and is likely to resonate with readers. The structure of the paper is logical, moving from introduction and literature review into progressively developed models, then into the integrated framework and implications. Despite the technical content, the paper maintains a narrative flow which is commendable.

* **Managerial and Practical Insights:** I appreciate that Section 6 (Managerial Implications) directly translates the analytical findings into clear advice for entrepreneurs, investors, and policymakers. This enhances the paper’s practical relevance. The points about avoiding pure strategies, designing for rapid learning, staging investments by learning milestones, etc., are insightful and consistent with the model’s implications. These implications will make the paper appealing not just to academics but also to thoughtful practitioners.

In summary, the draft has *strong potential*. It addresses a meaningful gap by marrying OM modeling with entrepreneurial strategy needs, and it does so in a thoughtful way. The next steps are about polishing and tightening the manuscript to meet the standards of rigor and clarity for **Management Science**. Below I detail several areas for improvement along with suggestions.

## Major Areas for Improvement and Suggestions

Despite the exciting strengths, there are several areas where the manuscript can be **strengthened to improve its contribution and readability**:

### 1. **Theoretical Framing and Contribution**

**Clarify the “Degenerate Problem” Concept:** The notion that entrepreneurial stakeholder prioritization is “fundamentally degenerate” (more decision variables than constraints) is intriguing, but it needs clearer definition and justification. In the introduction, you use the term “degenerate” metaphorically. To avoid confusion (since “degenerate” has specific meanings in math programming), consider defining precisely what you mean (perhaps in Section 1.1 or 1.2). Is the idea that the problem lacks a well-defined objective due to too many options and too little information? Or that traditional optimization has infinite alternate optima? Strengthening this explanation will help readers appreciate why a new approach is required. Moreover, explicitly highlight **why existing strategic tools fail** here – e.g., how do traditional optimization or NPV calculations break down when variables >> constraints? Making the **theoretical gap** clear will sharpen your contribution.

**Positioning Relative to Dynamic Capabilities:** You mention *dynamic capabilities* (sensing, seizing, reconfiguring) as a framing, but the current draft doesn’t cite the foundational works (e.g., Teece, Pisano & Shuen, 1997). It would be wise to explicitly reference those classic pieces to show you are building on established theory. In particular, highlighting how your *push-pull framework* provides a formal model for the “sensing vs. seizing” trade-off will strengthen the theoretical contribution. One suggestion is to add a sentence in the **Contributions** or **Theory** section noting: *“In dynamic capabilities terms (Teece et al., 1997), our model formalizes how entrepreneurs can simultaneously **sense** (learn) and **seize** (act) opportunities, rather than treating them as separate stages.”* This will situate your work in the strategy literature and signal its broad relevance.

**Entrepreneurship Literature Integration:** The literature review is generally solid, covering uncertainty (Knight, Sarasvathy), stakeholder theory, and OM-for-entrepreneurs. To further enhance it, you might incorporate recent research on *entrepreneurial search and learning*. For example, a **2024 Strategy Science article by Chavda, Gans, and Stern** develops a Bayesian model of entrepreneurial search where founders test their “theories” about the market. Their model finds that optimal search can involve non-intuitive behaviors (e.g., sometimes reverting to a previous strategy after a failure, or continuing to search even after a success) – essentially showing that a **theory-driven, iterative approach** leads to better long-term outcomes. Citing this work (and similar efforts in theory-based entrepreneurship) would reinforce your argument that *structured experimentation* is valuable. It also shows awareness of cutting-edge research at the intersection of strategy and OM (their approach parallels your push-pull ideas by formally balancing experimentation and commitment).

*Recommended addition:* **Chavda, Gans & Stern (2024)** – a forthcoming Strategy Science paper (NBER Working Paper No. 32318) on theory-driven entrepreneurial search. This piece can be referenced when you discuss integrated approaches or in the lit review on uncertainty and learning. I have added an entry for it in your literature review table for convenience (see the end of this feedback for details).

**Citing Foundational OM/Entrepreneurship Works:** In addition to new research, make sure to anchor your contribution in *foundational insights*. For instance, the idea that entrepreneurship involves experimentation and learning from failure has been echoed in economics and management – *Kerr, Nanda & Rhodes-Kropf (2014, JEP)* describe **entrepreneurship as experimentation**, emphasizing that low probabilities of success and unknown outcomes necessitate many “shots on goal” (which is essentially why a combined predict-prescribe approach is needed). You do cite Sarasvathy’s effectuation (effectual logic is very relevant here) and Knight’s uncertainty; that’s great. Consider also referencing *Pich, Loch & De Meyer (2002, Management Science)* – they analyzed **project management under high uncertainty**, distinguishing between planning, learning-by-doing, and selectionism. Their conclusion was that in highly ambiguous situations, **adaptive trial-and-error strategies outperform extensive upfront planning** – a message very aligned with yours. Including such citations would show that your work builds on a lineage of thought spanning OM and entrepreneurship: that in uncertain, fast-changing environments, **flexibility and learning are key**. I have added Pich et al. (2002) to the lit review table as well.

### 2. **Modeling Assumptions and Rigor**

Your models are well crafted; however, there are some points where assumptions and methodological choices should be **better justified or clarified**:

* **Linear vs. Sigmoid Model Assumptions:** The paper moves from a linear response model (G0) to a sigmoid response (G1) for stakeholders. This progression makes sense – linear is a simplification, sigmoid is more realistic for saturation effects. Make sure to clarify the *assumptions underlying each model* and why each is appropriate. For instance, linear \$P\_c(q)=q\$ and \$P\_r(q)=1-q\$ is a stark assumption (stakeholders perfectly inversely related). You might briefly acknowledge that this is a toy model to illustrate the basic tension (customer vs partner) – essentially a zero-sum sensitivity – which you will later relax. When introducing the sigmoid, emphasize that it captures diminishing returns and saturation (“S-shaped response”) which reflect behavioral realities (e.g., stakeholders are indifferent at extremes of quality). If possible, provide an intuitive example: *“For instance, initially increasing battery range from 50 to 100 miles greatly increases customer commitment probability, but going from 300 to 350 miles yields much smaller gains – an S-curve.”* These clarifications will help readers buy into the modeling choices and see their relevance.

* **Asymmetric Response Model (G2) Complexity:** In Proposition 3, the fully asymmetric case yields a complex first-order condition that generally requires numerical solution. You smartly highlight special cases with closed forms (customer-dominant, partner-dominant, etc.). I encourage you to elaborate slightly on how these cases were identified and **what insights they provide** beyond the symmetric case. For example, Case 1 (\$\beta\_c \gg \beta\_r\$) result \$q^\* = \frac{1}{\beta\_r}\ln\frac{C\_o+V}{C\_u}\$ – how does this compare intuitively to earlier results? (It seems to suggest when customers are *extremely* sensitive, the entrepreneur should invest in higher quality, as Tesla did, even if it strains partner feasibility – which matches your Tesla anecdote.) Emphasize these insights in plain language. Also, consider if any **numerical example or figure** could illustrate how \$q^*\$ shifts as \$\beta\_c\$ and \$\beta\_r\$ vary. A small plot or even a sentence like “as \$\beta\_c\$ increases relative to \$\beta\_r\$, the optimal \$q^*\$ monotonically increases, reflecting the higher payoff of pleasing the more sensitive stakeholder” would be useful.

* **“Empirical” vs. **Computational** Analysis:** Section 5 is titled *Empirical Analysis*, but as written it appears to be a **simulation or numerical experiment** rather than empirical data from the field. It’s absolutely fine to use simulations to illustrate your model’s performance (indeed that’s expected for analytical work). However, to avoid confusion for readers (who might expect actual venture data under “empirical”), consider renaming this section to **“Numerical Illustration”** or **“Computational Experiment”**. In this section, ensure you clearly describe how the results (Table 1, Figures 1–2) were obtained. For example, did you simulate an entrepreneur updating \$\beta\_c,\beta\_r\$ over 5 iterations? Are these Monte Carlo simulations or analytical computations of the model? Being transparent about the methodology will enhance the rigor. If possible, report **simulation parameters** (e.g., “we assumed initial \$\beta\$ estimates were 200% off the true values and simulated the integrated policy’s learning curve”). This will help readers (and reviewers) trust the claims like “recovers from 200% error within 5 iterations” and “pure strategies never recover”.

* **Information Gain Term:** The integrated framework introduces a dynamic optimization with an \$E\[L] + \lambda \cdot \text{InfoGain}\$ objective. This is a critical piece (essentially a multi-armed bandit or Bayesian optimal learning formulation). Currently, it’s presented at a high level. I recommend providing a bit more **structure or reference** for this term. For instance, you could specify that \$\text{InfoGain}(q,\Sigma\_t)\$ could be quantified as the expected reduction in parameter uncertainty (e.g. reduction in entropy or variance of \$\Sigma\_t\$) from choosing quality \$q\$. If there is a known formula or a citation for how to weigh information gain in decision-making, citing that would add credibility. Relevant literature from OR on **optimal learning** or **bandit problems** might help (even a brief mention of the classical “exploration vs exploitation” balance would show that your approach has a rigorous foundation). Since Management Science readers include many analytics scholars, being a bit crisper here will prevent criticism. You don’t need to fully derive a Bayesian bandit solution, but indicating that your approach is *consistent with Bayesian optimal control logic* (citing, say, Gittins index or Bertsimas & Mullainathan on bandits, etc.) could be helpful. At minimum, clarify qualitatively: *“We incorporate an information gain term, \$\lambda\$, which can be interpreted as the value (in cost reduction) of learning about stakeholder sensitivities. This encourages exploration when uncertainty is high, and automatically diminishes as information accumulates.”* Such an explanation grounds the framework.

* **Proof Sketches and Robustness:** You provide proof outlines for propositions, which is good. Check that all assumptions for those propositions are stated. For example, in Prop. 4 (Pure Strategy Limitations), you discuss a prediction approach with \$q=0\$ fixed – is that assuming the entrepreneur just waits indefinitely (never prescribes)? Perhaps clarify that this is a boundary scenario to illustrate that pure learning without acting yields suboptimal results even with perfect information eventually. Similarly, Prop. 5 (Integration Superiority) is stated in strong terms (“always achieves \$q^\*\$, maximizes profitability…”). Is this under the assumption of infinite time horizon or sufficient exploration? It might be worth tempering this to *expected* outcomes or within model assumptions. Reviewers might otherwise challenge the absoluteness of “always” and “guarantees.” Specifying conditions (e.g. “under mild regularity conditions of the Bayesian update, the integrated approach converges to the true optimum in probability”) would make it more rigorous. If a full proof is complex, at least cite relevant dynamic programming or Bayesian decision results to support it.

### 3. **Clarity of Exposition and Tone**

Overall the paper reads clearly, but there are a few places where the **academic tone and clarity** can be improved:

* **Balance Engaging Language with Academic Style:** Your writing is refreshingly lively – something we don’t often see in OM papers! I encourage you to keep the analogies and vivid explanations, *but ensure the tone remains professional*. For instance, phrases like “like trying to navigate a city where street names change faster than maps can be printed” paint a picture, which is great. Just be cautious not to overdo metaphors where a direct statement would suffice. Some informal elements should be removed in revision: e.g., the emoji “😅” and the parenthetical quip “(if they will)” in your contribution #3 should be deleted to maintain a formal tone. Similarly, internal notes such as “🚨update reference🚨” need to be resolved – presumably you intend to replace the Arrow et al. (1951) citation with a more appropriate one for the newsvendor context (perhaps the standard Arrow, Harris & Marschak reference is fine, or add a modern newsvendor reference like Petruzzi & Dada, 1999 which you already cite). Make sure all such placeholder text is cleaned up.

* **Introduction and Contribution Section:** The introduction is currently quite long (which is okay) and rich in detail. One suggestion is to ensure the *core research question and gap* are crystal clear by the end of Section 1.1 or 1.2. You describe the challenge well; just verify that a reader cannot miss **what this paper is adding**. Perhaps explicitly state: *“We address the unanswered question: *How can entrepreneurs optimally sequence and integrate learning and quality investment decisions when facing perishable stakeholder commitment?*”* A sentence like this can frame the rest. In Section 1.3 (Research Contributions), you list three contributions. These are on point. To strengthen them, consider: (i) Re-check the reference in Contribution 1 – as noted, Arrow et al. (1951) is indeed a classic source for newsvendor, but your note suggests you might cite something else; ensure it’s properly cited. (ii) In Contribution 3, you mention “if they will 😅” – remove that, and instead perhaps cite something like Fine (1998) *Clockspeed* to support the idea of “48 hours in a day” (Fine used the term “clockspeed” to describe industry pace – you’ve already alluded to that concept). Aligning your phrasing with academic references will lend authority to the claims.

* **Literature Review Section:** The lit review is well structured into subsections. One minor point: you might add a short **transition paragraph** at the end of Section 2 that summarizes the gap. E.g., *“In summary, prior research highlights the need for integrated decision approaches (prediction + action) in entrepreneurship, but existing OM models and entrepreneurship theories have yet to provide a unified framework. We next develop such a framework, beginning with base models and building toward integration.”* This will ensure the reader sees how the literature leads into your model development in Section 3.

* **Figures and Tables Presentation:** Ensure that the figures and tables are properly introduced and labeled. For example, Table 1 is referenced as a comparison of approaches. Make sure in the text you describe each metric in the table (Effectiveness, Accuracy, etc.) so that a reader understands the check marks and percentages without confusion. For the figures (cost impact of initial β errors, value of information over time), when you include them, provide clear captions. Right now the bracketed notes \[e.g., “Figure 1: ... \[Analysis shows ...]”] might be placeholders – these should be replaced with actual figure captions and discussed in the text. Also verify that the **Tesla parameters** used (e.g. \$\beta\_r \ll \beta\_c\$, \$C\_u=1, C\_o=V=2\$) are clearly stated in the text before Table 1, so the reader knows the context of the simulation.

* **Terminology Consistency:** A few terms could be defined more explicitly. For instance, *“prescription effectiveness”* and *“prescription profitability”* are introduced as definitions – make sure these are motivated. Why these measures? Are they analogous to concepts like optimality and regret in optimization? A brief rationale will help. Also, when you say “robustness” in the table, clarify robustness to what (likely parameter mis-specification or environmental change). Given the interdisciplinary audience, even terms like “newsvendor” could be footnoted when first used (some entrepreneurship readers might not know the newsvendor model; a one-line explanation would help).

* **Minor Edits:** Lastly, there are some minor editorial issues to fix: remove colloquial asides (e.g., “(essentially applying OM scaling principles to entrepreneurship)” might be better as “(analogous to OM scaling principles)” in the lit review table), check for any missing reference years or typos (I noticed Fisher et al., 2016 in text vs 2017 in refs – ensure consistency), and update any outdated placeholders in references. These are small things but important for a polished submission.

### 4. **Fit with OM, Behavioral Ops, and Entrepreneurship Literatures**

The interdisciplinary nature of your paper is a big selling point, so it’s worth double-checking that you **do justice to all relevant literatures**:

* **Operations Management:** You have effectively drawn from inventory/newsvendor theory and prescriptive analytics. Ensure you also cite key OM works that relate to *sequential decision-making under uncertainty*. For instance, the OM community has studied multi-period learning (e.g., sequential testing in product development, sequential inventory decisions). A classic OM example is the **“sequential experimentation”** approach in product design (Thomke & Bell, 2001, *Management Science*), where firms decide how often to test prototypes – conceptually similar to your entrepreneur deciding how often to “experiment” with quality levels. While you need not delve deeply into that, a passing reference could show OM readers that you’re building on established methods of incorporating learning into operations decisions. I have added a couple such references in the literature table (e.g., Thomke & Bell 2001 for experimentation in NPD).

* **Entrepreneurial Modeling:** Highlight that your approach complements **entrepreneurial finance and real-options thinking**. Entrepreneurs often stage investments (as you note in implications for investors). Indeed, the notion of treating strategic decisions as real options (McGrath, 1999) is related to what you model (each quality investment is an information-generating option). Emphasizing this connection in the introduction or lit review might strengthen the appeal to entrepreneurship scholars by linking to well-known concepts (real options, experimentation, effectuation). You do mention Sarasvathy’s effectuation (which is great). Perhaps also mention real-options reasoning as another perspective that your model formalizes (e.g., instead of a binary “invest or abandon” option, you continuously invest in quality while keeping the option to pivot as learning occurs – a form of dynamic option exercise).

* **Behavioral Operations:** Given you cite works on biases (Busenitz & Barney, Zhang et al. 2024), consider explicitly framing your integrated strategy as a way to *mitigate decision biases*. In other words, one could argue that a structured predict-prescribe approach helps avoid the pitfalls of overconfidence or “analysis paralysis” by balancing the two. There’s a rich behavioral OM literature on how decision-makers deviate from optimal policies (for example, the **newsvendor bias** where people tend to order too conservatively or aggressively relative to the optimum). In fact, Schweitzer & Cachon (2000) found that even with known probabilities, decision-makers often **anchor toward average demand** rather than the optimal stock level, due to loss aversion and mis-estimation – essentially a **bias in a single-period inventory decision**. Entrepreneurs face similar biases at a larger scale. Citing such works (I’ve added Schweitzer & Cachon, 2000 to the lit table) can bolster your argument that a more algorithmic approach is valuable. It situates your work within **behavioral operations** by suggesting that the push-pull framework could help correct for human biases (by systematically incorporating data/learning into decisions). If you prefer to keep the focus on normative modeling, that’s fine – but a brief nod to this angle could expand your paper’s appeal.

* **Recent OM-Entrepreneurship Links:** You have already cited Fine et al. (2022) and Joglekar & Lévesque (2013), which is excellent. To ensure currency, double-check if there are any **very recent** OM papers on entrepreneurship (2023–2025) you might have missed. One that comes to mind is the use of **reinforcement learning in OM contexts** (you cite Zhang et al. 2023 MS for dynamic allocation). That’s good, as it shows OM is embracing AI/ML for adaptive decisions, akin to your approach. Another is any recent POM papers on startups or empirical OM in entrepreneurship. If none are directly relevant, no problem – your coverage is already quite comprehensive via the lit review table. Just be prepared in revision to address any reviewer-suggested citations; the groundwork you’ve laid in the lit review table will help tremendously.

*(For your convenience, I have directly inserted entries for the recommended citations in your 🗄️**litrev** table, under the appropriate categories (🟪/🟩/🟧/🟦). I also added a log at the top of that file dated today, noting these updates under my editor role.*)

## Concluding Thoughts

In conclusion, let me stress that I find this work **very promising**. The integration of predictive learning with prescriptive optimization in an entrepreneurial setting is *right on target* for advancing the OM field into new territory. With revision, this paper can make a valuable theoretical contribution and also offer practical guidance to entrepreneurs – a combination that is highly attractive.

As you revise, focus on **sharpening the contribution and ensuring the rigor and clarity** of your modeling and exposition. Addressing the points above – especially clarifying the degenerate problem framing, tightening up the integrated model’s description, and polishing the writing – will significantly strengthen the manuscript. I also encourage you to weave in the suggested citations to fortify your literature grounding (both classic and contemporary works will show the breadth of your scholarship).

I want to commend you for tackling a complex, cross-disciplinary problem. The enthusiastic tone of my feedback reflects my belief that this idea is worth pursuing and refining. I offer these critiques in the spirit of **constructive improvement** and I am confident that with careful revision, your paper can meet the high standards of *Management Science*. I look forward to seeing the next iteration. Good luck, and please don’t hesitate to elaborate on any of the suggestions in your revision – the effort will pay off in a clearer and more impactful publication.

*Sincerely,*
*Alex Kim, Department Editor (Operations Management),*
*Management Science*


| Question                        | Key Takeaway                                                                             | Core Code Concept                                                                      |
| ------------------------------- | ---------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- |
| 1a. Distribution of final score | Understanding probabilistic outcomes in sequential dice rolls using a stopping condition | Basic recursive sampling: `generateFrom([])` with stop condition `sum(sequence) >= 10` |
| 1b. Distribution of rolls       | Analyzing length of sequences in recursive processes                                     | Track sequence length: `sequence.length`                                               |
| 1c. Conditional distribution    | Conditional reasoning with stopping criteria                                             | Use condition: `condition(sum(sequence) <= 13)`                                        |
| 2a. Casino dealer sampler       | Implementing Hidden Markov Model (HMM) as recursive generator                            | Track two sequences (coins & faces) with transition prob 0.2 and emission prob 0.2/0.8 |
| 2b. Short sequence inference    | Inferring hidden states from short observation sequence                                  | Condition model on faces [H,H,H,H,T,H,H,T] to infer coins                              |
| 2c. Long sequence inference     | Understanding limitations of exact inference                                             | Same as 2b but longer sequence shows enumeration limits                                |
| 2d. Using observe()             | Making inference tractable with likelihood weighting                                     | Replace condition with `observe(Bernoulli(theta[coin]), face=='H')`                    |
| 3a. Parameter sensitivity       | Understanding parameter effects on inference                                             | Test different switching probabilities and coin weights                                |
| 3b. Human data comparison       | Validating model against human judgments                                                 | Plot subject ratings vs model predictions                                              |
| 3c. Parameter learnability      | Identifying hard-to-learn parameters                                                     | Demonstrate with example sequences                                                     |
| 3d. HMM limitations             | Critical analysis of model assumptions                                                   | Discuss scenarios where HMMs fail                                                      |

The homework progresses from:
1. Basic probabilistic programming (Q1)
2. HMM implementation (Q2) 
3. Model validation and criticism (Q3)


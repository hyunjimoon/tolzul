


| dynamic simulation speaks   | stats speaks                                                                                                                                                                                                                                                                                                                                                 | note                                                                                                                                                                                                                                                                                                                        |
| --------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| process noise               | predictor uncertainty: $p(x)$                                                                                                                                                                                                                                                                                                                                | posterior predictive sampling for posterior predictive checks is different from usual posterior predictive sampling discussed in the chapter on posterior predictions in that the original predictors x ¬†are used from https://mc-stan.org/docs/stan-users-guide/simulating-from-the-posterior-predictive-distribution.html |
| measurement noise           | sampling uncertainty: $p(\tilde{y} \mid \theta, x)$                                                                                                                                                                                                                                                                                                          | exception: sampling from urn with black and white balls has uncertainty on the next ball's color but can have zero measurement noise                                                                                                                                                                                        |
| x                           | estimation uncertainty: $p(\theta\mid y, x)$                                                                                                                                                                                                                                                                                                                 |                                                                                                                                                                                                                                                                                                                             |
| baseline sensitivity test   | prior predictive checking: inspect $\tilde{y}$ from $p(\tilde{y})$                                                                                                                                                                                                                                                                                           | conditioning on model structure                                                                                                                                                                                                                                                                                             |
| estimation sensitivity test | posterior predictive checking: compare $\tilde{y}$ from $p(\tilde{y}\mid y)$ with $y^{obs}$                                                                                                                                                                                                                                                                  | conditioning on model structure + observed data                                                                                                                                                                                                                                                                             |
| x                           | posterior predictive uncertainty = sampling uncertainty¬†+¬†estimation uncertainty  $p(\tilde{y} \mid y)=\int \underbrace{p(\tilde{y} \mid \theta)}_{\begin{array}{c}\text { sampling } \\ \text { uncertainty }\end{array}} \cdot \underbrace{p(\theta \mid y)}_{\begin{array}{c}\text { estimation } \\ \text { uncertainty }\end{array}} \mathrm{d} \theta$ |                                                                                                                                                                                                                                                                                                                             |

[^1]: https://mc-stan.org/docs/stan-users-guide/simulating-from-the-posterior-predictive-distribution.html


| Step                               | Theoretical                                                                                                                                                                                                                                                                                                                                                                  | State-Action (Secretary Example)                                                                                                                                                                                                                                             |
| ---------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1. Choose Random (üîµ)              | Nature provides data via random sampling                                                                                                                                                                                                                                                                                                                                     | <font color  = "Green">States (s): Unknown secretary capabilities (digital proficiency, communication skills) </font><br><font color  = "#C0A0C0"> Data (y): Initial resumes, test scores</font><br>$s_{1..k} \sim P(s\mid y)$<br>Actions (a): Unknown past hiring decisions |
| 2. Verify Exchangeability (üîµ‚û°Ô∏èüî¥) | Test if V(s‚ÇÅ) = V(s‚ÇÇ) for value function V                                                                                                                                                                                                                                                                                                                                   | <font color  = "Green">State Check: Do secretaries with similar scores perform similarly?</font><br><font color  = "Red">Action Check: Do similar hiring decisions lead to similar outcomes?</font><br>Example: {Amy, Bob} both at 150 wpm suggests exchangeable states      |
| 3. Represent Ignorance (üíö)        | Discover latent variable P where S‚ÇÅ‚ä•S‚ÇÇ\|P                                                                                                                                                                                                                                                                                                                                    | <font color  = "Green">State Uncertainty: What underlying skills (P) explain performance?</font><br><font color  = "Red">Action Uncertainty: How do different management decisions affect outcomes?</font><br>Example: Digital proficiency might be the true latent state    |
| 4. Make Knowledge (üî¥)             | Convert to s‚ÇÅ,s‚ÇÇ = X\|P<br><br>posterior predictive uncertainty = sampling uncertainty¬†+¬†estimation uncertainty  $p(\tilde{D} \mid D)=\int \underbrace{p(\tilde{D} \mid s)}_{\begin{array}{c}\text { sampling } \\ \text { uncertainty }\end{array}} \cdot \underbrace{p(s \mid D)}_{\begin{array}{c}\text { estimation } \\ \text { uncertainty }\end{array}} \mathrm{d} s$ | State Update: p(s\|·ªπ) - Update beliefs about skills<br>Prediction: p(y\|·ªπ) - Predict future performance<br>Action Selection: p(a\|·ªπ) - Make hiring/assignment decisions                                                                                                      |


| Component   | Classical Secretary Problem | Real-World Implications for Employers |
| ----------- | --------------------------- | ------------------------------------- |
| Data (D)    |                             |                                       |
| State (s)   |                             |                                       |
| Action (a)  |                             |                                       |
| Utility (U) |                             |                                       |


No secretary in entrepreneurship

| Component   | Classical Secretary Problem                                                                                                         | Real-World Implications for Employers                                                                                                                  |
| ----------- | ----------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Data (D)    | ‚Ä¢ Perfect relative ranking between candidates seen so far<br>‚Ä¢ No recall of rejected candidates<br>‚Ä¢ Random order of candidates     | ‚Ä¢ Can only compare current candidate vs. previously seen ones<br>‚Ä¢ Must make immediate yes/no decision<br>‚Ä¢ Can't predict quality of future candidates |
| State (s)   | ‚Ä¢ Fixed number n of total candidates<br>‚Ä¢ Position of current candidate in sequence (i)<br>‚Ä¢ Best candidate seen so far (threshold) | ‚Ä¢ Number of total applications<br>‚Ä¢ Where we are in interview process<br>‚Ä¢ Our current "benchmark" candidate                                           |
| Action (a)  | ‚Ä¢ Only two choices:<br>  - Stop and hire current candidate<br>  - Continue to next candidate<br>‚Ä¢ Once rejected, cannot go back     | ‚Ä¢ Accept/reject decision required after each interview<br>‚Ä¢ No opportunity to reconsider past candidates<br>‚Ä¢ No parallel interviewing allowed         |
| Utility (U) | ‚Ä¢ Binary: 1 if best candidate selected, 0 otherwise<br>‚Ä¢ Only cares about selecting THE best<br>‚Ä¢ No value for second-best          | ‚Ä¢ All-or-nothing reward structure<br>‚Ä¢ No consideration of "good enough"<br>‚Ä¢ Ignores cost of continuing search                                        |

Note: The classical problem makes several unrealistic assumptions:
1. Fixed candidate quality (doesn't account for training/growth)
2. Perfect ranking ability (ignores uncertainty in evaluation)
3. Binary utility (doesn't value "good enough" candidates)
4. No consideration of search costs
5. Assumes complete independence between observations

Would you like me to elaborate on how any of these components map to real-world hiring decisions?
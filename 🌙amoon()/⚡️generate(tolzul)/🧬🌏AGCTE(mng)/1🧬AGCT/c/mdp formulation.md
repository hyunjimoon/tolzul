


### 2. mdp formulation (using reinforcement learning and optimal stopping) 


|                              | <mark class  = "green"> 👁️state</mark>                                                                                                                                                                                      | <mark class  = "red">👮🏻policy</mark>, learning alg, bellman eq                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | <mark class  = "orange">🤜action</mark>                                                                                                                                 | <mark class  = "purple"> 👀🤜transition</mark>                                                     | <mark class  = "yellow">💰reward</mark>, obj (max long term expected rwd)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | 🖼️diagram                                | (timestep, horizon, $\gamma$); H=1/1-$\gamma$ |
| ---------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------- | --------------------------------------------- |
| Market-Product Pivot MDP     | (m, p, o, u, e)<br><br>m: current market<br><br>p: current product<br><br>o: optimism (mean of prediction for evaluation)<br><br>u: uncertainty (sd of prediction for evaluation)<br><br>e: remaining experiment opportunity | π(s) -> a<br>  - s: current state (m, p, o, u, e)<br>  - a: action to take (change_market or change_product)<br><br>- V(s) = max_a Q(s, a), where:<br>  - s: current state (m, p, o, u, e)<br>  - a: action (change_market or change_product)<br>  - Q(s, a): action-value function, representing the expected cumulative reward starting from state s and taking action a, following the optimal policy thereafter.<br><br>V(s) = max_a [r(s, a) + γ * sum_{s'} T(s, a, s') * V(s')], where:<br>  - s: current state (m, p, o, u, e)<br>  - a: action (change_market or change_product)<br>  - r(s, a): immediate reward for taking action a in state s<br>  - γ: discount factor (0 ≤ γ ≤ 1)<br>  - s': next state (m', p', o', c')<br>  - T(s, a, s'): state transition probability from s to s' when taking action a<br> | (change_market, change_product)                                                                                                                                         | T(s, a, s') = P(s' \| s, a)<br><br><br>s: (m, p, o, u, e)<br>a: action<br>s': (m', p', o', u', e') | r(s, a) = customer review(m, p)<br>Observed customer review for current market and product<br><br>π* =$\underset{\pi}{argmax} E[\sum_{t=0}^∞ γ^t * r(s_t, a_t) \| π]$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | ![[Pasted image 20240428153517.png\|500]] |                                               |
| e2a, a2                      | 👮🏻2👮🏻(👁️,  $\epsilon^a$)<br>🕘<br>update 👮🏻                                                                                                                                                                           | 👮🏻2🌏(👁️) =🤜<br>🕡                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | 🌏2🌏(👁️,🤜)=👁️'<br>🕞<br>update 👁️                                                                                                                                  | 🌏2👮🏻(👁️,🤜, 👁️')=💰<br>🕒                                                                     | <mark class  = "yellow">💰</mark>(<mark class  = "green"> 👁️</mark>,<br>  <mark class  = "purple"><mark class  = "purple"> 👀🤜</mark></mark>(<mark class  = "green"> 👁️</mark>, <br>       <mark class  = "orange">🤜</mark>(=<mark class  = "red">👮🏻</mark>(<mark class  = "green"> 👁️</mark>,  $\epsilon^a$))<br>     , $\epsilon^e$)<br>)<br><mark class  = "yellow">reward</mark>(<mark class  = "green"> state</mark>,<br>  <mark class  = "purple"><mark class  = "purple"> transition</mark></mark>(<mark class  = "green"> state</mark>, <br>       <mark class  = "orange">action</mark>=<mark class  = "red">policy</mark>(<mark class  = "green"> state</mark>,  $\epsilon^a$)<br>     , $\epsilon^e$)<br>) |                                           |                                               |
| 🛑parking (optimal stopping) | $\begin{aligned} & \{(0, T),(O, A) \\ & (1, T),(1, A) ,..., (C, A) \\ & (C, T), leave, park \}\end{aligned}$                                                                                                                 | <mark class  = "blue"> Q2.reward = avg time in system?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | $\left\{\begin{array}{l}(\text { park, continue) if } s=(\cdot, A) \\ (\text { continue) if } s=(\cdot, T) \text {, } \\ \text { do nothing } o. w\}\end{array}\right.$ |                                                                                                    | ![[Pasted image 20240429083718.png\|300]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | ![[Pasted image 20240429083741.png\|300]] |                                               |

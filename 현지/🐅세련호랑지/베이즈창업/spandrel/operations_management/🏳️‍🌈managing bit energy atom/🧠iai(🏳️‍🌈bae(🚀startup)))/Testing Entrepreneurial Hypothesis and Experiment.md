
## 1. Testing Entrepreneurial Hypothesis and Experiment 

Entrepreneurs test hypotheses about value creation and capture from their ideas. However, due to high complexity and dynamics of startup operations, crystallizing hypothesis (what) and experiment (how) are challenging. Rent the Runway's founders Jennifer Hyman and Jennifer Fleiss were one of the few who tested key value creation hypotheses, in a systematic, rapid, and cost-effective manner. Critical hypothesis of their business were (1) college students and young professionals would find renting previously worn designer gowns superior to purchasing those dresses new, (2) dresses would, in most cases, be returned by customers in an acceptable condition such that after dry cleaning, they could be rented again, and (3) leading designers would not only be amenable to their dresses being rented but also would partner with a young startup to enable this new avenue. Before fully committing to their idea, the founders sought insights from renowned designers, leading them to pivot from working directly with designers to becoming a new distribution channel for them. They also conducted targeted experiments at universities, with the constructive feedback guiding their strategic direction and validating their idea's worth.

With the purpose of supplying testing tools for entrepreneurs, we apply Bayesian workflow (BW) to add structure to entrepreneurs testing. BW introduces how to build statistical model from ground zero, adding inference, and checking/improvement, along with the comparison of diﬀerent models, not just for the purpose of model choice or model averaging but more importantly to better understand these models. 

 We start by defining optimality measure of experiment $\theta$ and hypothesis $\phi$ testing as:
$$\mathcal{O}(\theta, \phi)=\frac{1}{\operatorname {ValidApproxBiasCost(\phi)} + \operatorname{ValidStatBiasCost(\phi, N)}} \times \frac{1}{\operatorname{VerifApproxBiasCost(\theta|\phi) + \operatorname {VerifConvgCost}}(\theta|\phi, M)} \times \frac{1}{\operatorname{OpportunityCost}(\theta, \phi, N, M)} \; (1)$$

(1) starts from a heuristic measure, Criticality X Fidelity / Opportunity Cost, introduced in 15.911, Entrepreneurial Strategy by Scott Stern. Each components are defined as "how much does the ideal version of this test (measured accurately and at low cost) meaningfully reduce uncertainty surrounding the core value creation and capture hypotheses? (Criticality)",  "Is there a (reasonable cost) test with a reasonable level of accuracy and precision? (Fidelity)",  "What are the resource, time, and strategic costs of an experiment? (How much) is there a tradeoff between faster, better, and cheaper? (Opportunity cost)".  

Connecting this with verification and validation developed in simulation[^1], product management[^2], software development [^3], scientific theory[^4] literature, criticality is validation test asking "are we making the right product?" whereas Fidelity is verification test asking "are we making the product right given that (or sometimes before knowing) we are making the right product?". Optimal testing is characterized with critical hypothesis, high fidelity, low opportunity. Statistical, approximation, optimization bias as three components of inductive bias from machine learning [^5]  literature is useful to capture the tradeoff between the three, which is why we frame hypothesis criticality and fidelity as bias. Entrepreneurs take action to decrease associated cost. Table 1 introduces the definition of the costs.  

To test a pair of experiment and hypothesis, we can use conditional probability $p(\theta, \phi) = p(\phi) p(\theta|\phi)$. In other words, hypothesis $\phi$ and experiment $\theta$ joint distribution is sequentially tested. The first term of (1) is related to pure hypothesis $p(\phi)$ and second  term is related to experiment conditional on hypothesis  $p(\theta|\phi)$. Interpretation is, given that we have set the critical hypothesis for business, how faithful is the experiment to answer the hypothesis? Testing can also happen in $p(\theta) p(\phi|\theta)$ sequence. $p(\phi|\theta)$ means given that we have a faithful experiment to test any hypothesis, what is the critical hypothesis to ask? Both works, but let's focus on a more natural testing procedure, which first nail hypothesis then move on to experiment.

The first component of criticality or validation is $\operatorname{ValidStatBiasCost(\phi, N)}$. It is from statistical bias caused by approximating utility of beachhead customer population with that of N sampled customers. The second is $\operatorname{ValidApproxBiasCost(\phi)}$ which is from approximation bias caused by approximating utility with testing hypothesis $\phi$. 

The first component of fidelity or verification is $\operatorname{VerifApproxBiasCost(\theta|\phi)}$ which is from approximation bias caused by approximate testing hypothesis $\phi$ with experiment $\theta$. The second is $\operatorname{VerifConvgBiasCost(\theta|\phi, M)}$ induced from optimization bias.  This is due to limited resource (represented as time $M$) early stops experiment $\theta$ to test $\phi$ before reaching to the optimal. Increasing the M decreases the $\operatorname{VerifConvgBiasCost(\theta|\phi, M)}$, but increases $\operatorname{OpportunityCost(\theta, \phi, N, M)}$ capturing the second tradeoff.  Decomposition of $\operatorname{VerifConvgBiasCost(\theta|\phi, M)}$ and $\operatorname{VerifApproxBiasCost(\theta|\phi)}$ builds on the two distinct phases of iterative simulation: initial mixing of sequences towards the target distribution, often likened to "learning" or information propagation from the model to inferences, and the subsequent movement within that target distribution. Uncertainty of the first phase is epistemic and second is aleatoric. The first phase can represent a current state of knowledge, especially in scenarios where new information is being acquired or when tracking a changing process, while the second phase can be interpreted directly as inherent uncertainty of model parameter or time variability. An example of this is the study of radon gas exposure[^6], where high uncertainty in home radon levels was observed, even conditional on geographic data, and these levels were known to fluctuate over time[^7].  

$\operatorname{OpportunityCost}(\theta, \phi, N, M)$is a function of $\theta, \phi$ and is a resource, time, and strategic costs of an experiment $\theta$ to test hypothesis $\phi$. Notice the first two costs are closer to demand side and last three costs are closer to supply side. 

Increasing the N decreases the $\operatorname{ValidStatBiasCost(\phi, N)}$, but increases $\operatorname{OpportunityCost(\theta, \phi, N, M)}$ capturing the first tradeoff.  Increasing the M decreases the $\operatorname{VerifConvgBiasCost(\theta|\phi, M)}$, but increases $\operatorname{OpportunityCost(\theta, \phi, N, M)}$ capturing the second tradeoff.  Less specified hypothesis $\phi$ on customer, technology, organization, competition may increase $\operatorname{VerifConvgBiasCost(\theta|\phi, M)}$, but generality of the test result may decrease  $\operatorname{OpportunityCost(\theta, \phi, N, M)}$ capturing the third tradeoff. 


Table 1: Definition of Costs associated with Entrepreneurial Experiment $\theta$ to Test Hypothesis $\phi$

| -                   | def (related concept in E-strategy)                                                                                                                                         |
| ------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ValidApproxBiasCost($\theta$) | Cost of approximation bias caused by approximating utility with testing hypothesis $\phi$                                                                                                                                                                              |
| ValidStatBiasCost($\theta, N$)   | Cost of statistical bias caused by approximating utility of beachhead customer population with that of N sampled customers |
| VerifApproxBiasCost($\theta$ \| $\phi$) | Cost of approximation bias caused by approximate testing hypothesis $\phi$ with designed experiment $\theta$                 |
| VerifConvgBiasCost($\theta$\| $\phi, M$)  | Cost of optimization bias caused by limited resource (represented as time $M$) early stops experiment $\theta$ to test $\phi$ before reaching to the optimal         |
| OpportunityCost($\theta, \phi, N, M$)     | Resource, time, and strategic costs of an experiment $\theta$ to test hypothesis $\phi$                                                                                                                       |


---



Table 2 presents actions to lower cost component from optimality measure of experiment $\theta$ and hypothesis $\phi$ testing,.

Table 2: Actions to Lower Costs with Examples

| -                   | action to lower Entrepreneurial testing cost                           | example from Rent the Runway                                                                                                                                                                                                                                                                                                                                                            |
| ------------------- | ---------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ValidApproxBiasCost($\theta$)                     |    refine and narrow down the hypothesis based on market research and feedback                                                                    |   After conducting initial market research, Rent the Runway realized that their hypothesis about the appeal of renting designer dresses was more applicable to certain segments, such as young professionals attending formal events. This refinement helped in reducing the approximation bias.                                                                                                                                                                                                                                                                                                                                                                                      |
| ValidStatBiasCost($\theta, N$)   | increase testing sample                                                | Initially, Rent the Runway conducted a small pilot trial by inviting 100 students from a single university. After observing promising results, they expanded the trial to include 1000 students from multiple Ivy League universities to gather more comprehensive data.                                                                                                                |
| VerifApproxBiasCost($\theta$ \| $\phi$) | specialize customer segment                                             | Initially targeting a broad audience of women, Rent the Runway refined their target segment to young professionals attending formal events. They collaborated with designers to curate a collection specifically appealing to this segment, ensuring the dresses matched current fashion trends and preferences of young women in Ivy League universities.                              |
| VerifConvgBiasCost($\theta$\| $\phi, M$)  | increase experiment time or resource                                   | Rent the Runway initially offered a limited collection of 130 dresses for a single event. To optimize their offerings and understand customer preferences better, they expanded their collection to 1000 dresses and extended the rental period. They also introduced options for multiple events, allowing customers to rent for occasions like weddings, galas, and corporate events. |
| OpportunityCost($\theta, \phi, N, M$)      | design experiments with low upfront costs utilizing reachable resource | Instead of immediately investing in a large inventory, Rent the Runway initially collaborated with local designers and fashion schools in Boston. They borrowed dresses for their trials, reducing upfront costs. This allowed them to test the market demand without a significant initial investment.                                                                                 |

These examples provide a more in-depth look into the strategic decisions Rent the Runway might have made during its early stages, showcasing the trade-offs and considerations in entrepreneurial testing.


 ---


## 2. Bayesian workflow to Entrepreneurial testing (tbc)

|           |                            | Bayesian workflow                                                        | Entrepreneurial testing                                                                   | example from Rent the Runway                                                                                        |                                                                                                             |
| --------- | -------------------------- | ------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- |
| generator | $g(\phi, \theta)$          | Function that generates data based on parameters                         | Mechanism that produces outcomes based on business model features                         | Mechanism through which gown rental demand is generated based on business strategies                                |                                                                                                             |
|           | $p(\phi)$                  | Prior distribution of strategic choices                                  | Initial assumptions or beliefs about strategic choices                                    | Initial belief about the target market segment (e.g., young professionals)                                          |                                                                                                             |
|           | $p(\theta                  \| \phi)$                                                                   | Conditional distribution of product given strategic choice                                | Probability distribution of product offerings given a strategic choice                                              | Probability distribution of gown types/styles offered given the target market segment                       |
|           | $p(y                       \| \theta, \phi)$                                                           | Likelihood of observing data given product and strategic choice                           | Probability of observing certain business outcomes given product and strategic choice                               | Probability of specific rental patterns given the gown offerings and target market segment                  |
| joint     | $p(\theta, \phi, y)$       | Joint distribution of strategic choice, product, and observables         | Combined view of strategic choices, product offerings, and observed outcomes              | Combined view of target market segment, gown offerings, and actual rental patterns                                  |                                                                                                             |
| estimator | $\hat{\theta}, \hat{\phi}$ | Estimated values of product and strategic choice parameters              | Estimated values of business model features based on observed data                        | Estimated optimal gown offerings and target market segment based on observed rental data                            |                                                                                                             |
|           | $p(\theta                  \| \phi, y)$                                                                | Conditional distribution of product given strategic choice and observed data              | Updated probability distribution of product offerings given strategic choice and observed outcomes                  | Updated probability distribution of gown offerings given observed rental patterns and target market segment |
|           | $p_A(\theta \|\phi, y)$    | Approximate representation of conditional distribution by approximator A | Approximate understanding of product offerings based on limited data and strategic choice | Preliminary understanding of optimal gown offerings based on initial feedback and target market segment             |                                                                                                             |
|           | $p^*(y \| \theta, \phi)$                                                           | True data-generating distribution given product and strategic choice                      | True demand or market behavior given product offerings and strategic choice                                         | Actual demand for gown rentals given the gown offerings and target market segment                           |
|           | $t(y), u(y)$               | Testing function and utility function based on observed data             | Proxy measures of business success or profitability based on observed outcomes            | Proxy measures like customer satisfaction, repeat rentals, and customer referrals based on observed rental patterns |                                                                                                             |

This table integrates the Bayesian workflow with the entrepreneurial testing process, drawing parallels between the two and providing examples from Rent the Runway's business model and strategies. Fig1 shows, on its left, three major diagnostics (prior predictive check, simulation-based calibration[^8], posterior predictive checks) in red. The right is real life examples of iterative customer testing and design.

Fig1. Three diagnostics and its application to entrepreneurial testing 
![[Pasted image 20230930001056.png]]

$\text{VerifConvgBiasCost}(\theta|\phi, M)$


Reference

[^1]: Law, A. M., Kelton, W. D., & Kelton, W. D. (2007). _Simulation modeling and analysis_ (Vol. 3). New York: Mcgraw-hill.
[^2]: Ulrich, K. T., Eppinger, S. D., & Yang, M. C. (2008). _Product design and development_ (Vol. 4, pp. 1-3). Boston: McGraw-Hill higher education.
[^3]:  Adrion, W. R., Branstad, M. A., & Cherniavsky, J. C. (1982). Validation, verification, and testing of computer software. _ACM Computing Surveys (CSUR)_, _14_(2), 159-192.
		Boehm, B. W. (1988). A spiral model of software development and enhancement. _Computer_, _21_(5), 61-72.
		Boehm, B. W., & Papaccio, P. N. (1988). Understanding and controlling software costs. _IEEE transactions on software engineering_, _14_(10), 1462-1477.
[^4]: Box, G. E., & Youle, P. V. (1955). The exploration and exploitation of response surfaces: an example of the link between the fitted surface and the basic mechanism of the system. _Biometrics_, _11_(3), 287-323.
[^5]: Mohri, M., Rostamizadeh, A., & Talwalkar, A. (2018). _Foundations of machine learning_. MIT press.
Bronstein, M. M., Bruna, J., Cohen, T., & Veličković, P. (2021). Geometric deep learning: Grids, groups, graphs, geodesics, and gauges. _arXiv preprint arXiv:2104.13478_.
[^6]: Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (1995). _Bayesian data analysis_. Chapman and Hall/CRC.
[^7]: Gelman, A. (2004). Parameterization and Bayesian modeling. _Journal of the American Statistical Association_, _99_(466), 537-545.
[^8]: Modrák, M., Moon, A. H., Kim, S., Bürkner, P., Huurre, N., Faltejsková, K., ... & Vehtari, A. (2022). Simulation-based calibration checking for Bayesian computation: The choice of test quantities shapes sensitivity. _arXiv preprint arXiv:2211.02383_.
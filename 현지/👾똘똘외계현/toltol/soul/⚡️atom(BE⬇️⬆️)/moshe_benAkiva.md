2025-05-23
mail advocating students so that they can get a better grade

> Dear Professor [Name],
Having completed this semester's grade recommendations, I want to share how grading approaches can impact your goal of promoting discrete choice theory adoption. Perhaps for your future classes.
Three concerns:
**1. Workload Mismatch** - Students complete 6 case studies + 2 exams (more than typical courses from my ~10 MIT modeling courses). Lower grades despite higher workload teaches that deep work isn't rewarded.
**2. Lost Confidence** - Lower grades despite higher workload damage confidence in discrete choice analysis, making students avoid it professionally.
**3. Fewer Practitioners** - Students who lose confidence rarely apply methods later, directly reducing future adoption.
This perspective supports your vision of expanding discrete choice analysis use.

![[Pasted image 20250523091943.png]]

i asked

ðŸ–¼ï¸I'm a TA who just finished grading. 
ðŸ«€Need a short, professional email (~150 words) for the professor about how grading approaches affect his goal of promoting discrete choice theory adoption in future classes. 
ðŸ’¸Should share student perspectives without being confrontational or getting into specific grade details. 
ðŸ“I have experience with 10+ MIT courses for credibility comparison.


**This would have gotten us to the final version in ~3-4 iterations instead of 18.**

----

I sympathize with
p.6
- you mentioned "1.Experimental (proactive)" is impractical or infeasible, but this is very usual in entrepreneurship where previous collected data hints the next experiment. I believe ultimate outcome of every model should be an action that triggers data based on which next action is chosen. Incidentally I don't trust any data collected by others (measurement issues) so my preference is experimental > hypothetical > observational
- 
p.7 what's the use of theory
- From Data-Driven Decision Making to Forward-Looking Causal Reasoning
- "Entrepreneurs as Theorists (modelers)" is aligned with my interest, "distinguishes between experiments to test theories within a given problem and experiments that test whether decision makers have chosen the right problem." -> bayesian calibration
- 

p.32
Calculate ratio of posteriors (Bayes factor)

p.58 
dichotomy on data-driven != theory free,

Structural modeling 

I'm most interested in synthesizing below concepts
- hierarchical bayesian model () synthetic population and aggregate forecasting  (DCA)
- sec. 3.4. Theories as Restrictions of the Space of Parameters

EV â€² ï¿½ V, the negative update of V cannot be much smaller. The extra information provided by the experiment is then limited because the ratio of V to Q will not change much.

bootstrap testing
- "Similar issues arise with the bootstrap, another class of procedures that uses simulation to correct for inferential biases"
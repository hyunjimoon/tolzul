Complex Bayesian models are computationally intensive to perform inference. MCMC by itself is computationally expensive, given the need to draw random samples and calculate gradients. We can think of "scaling" bayesian computation from two perspectives

1. Parallelization
	In order to perform multiple tasks at once, we must assure that the tasks are independant; obviously a task can't depend on another task's result when running parallel. Fortunately, Bayesian inference has lots opportunities for this.
	Take for example, graphical models. "From conditional independence to distributed computation" from [here](https://arxiv.org/pdf/1609.05615.pdf) shows that the conditional probabilities for the posterior distribution can be decomposed into a product of mutually independant conditional distributions. This is, quoting from their paper, "a bottom-up view which deals with combining information across local sources of data and models".
	As typical with many parallelization scenarios(map) the inference problem must be representable as a sum of factors. For example, Stan provides a `reduce_sum` function which can calculate the sum of function applications in parallel. Such methods require clever thought into selecting the right "size" of subproblems(https://en.wikipedia.org/wiki/Amdahl%27s_law and parallelization overhead).
	To sum it up, efficient parallel computation requires the modularization of the inference target into independant subproblems.
	
2. Approximate Computation
	Another perspective is to use an algorithm which approximates the target posterior. Notable methods are the Laplace approximation and variational inference. In general you can assume the running complexity of approximate methods to be lower than that of exact inference, although this is not always the case. Laplace approximation is gated by the approximated distribution always following a normal distribution centered on the mode; this is not sufficient for accurate inference for complex target distributions across the entire distribution.
	Variational Methods, depending on algorithms boast more flexibility and have theoretical(asymptotic) guarantees on convergence. [High-dimensional variational inference](https://arxiv.org/pdf/2103.01085.pdf) pose additional problems, such as finding a suitable variational distribution that's accurate enough and pre-asymptotic bias.
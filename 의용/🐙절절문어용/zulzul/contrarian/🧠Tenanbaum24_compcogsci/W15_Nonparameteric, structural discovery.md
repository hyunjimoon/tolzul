[[josh_tenanbaum]] explains structural constraints, rather than being limitations, actually enable faster learning by drastically reducing the hypothesis space while maintaining enough flexibility for meaningful discovery.

| Example                                         | Initial Space                       | Structural Constraint                                      | Benefit                                                                                   | Key Quote/Point                                                                                                                                                          |
| ----------------------------------------------- | ----------------------------------- | ---------------------------------------------------------- | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Animal Species Classification                   | All possible clusterings of species | Tree structure (hierarchical)                              | Can infer correct structure type with only 20% of data, before knowing exact details      | "able to infer from relatively little data, just about 20% that you should have a tree structure...well before it's able to figure out what the right tree structure is" |
| One-shot Image Learning (Character Recognition) | All possible visual similarities    | Hierarchical motor program structure (strokes, substrokes) | Can recognize new instances with very limited data by leveraging stroke-level constraints | System learns to generalize from just one example by understanding structural primitives                                                                                 |
| Medical Diagnosis Network                       | 521,939+ possible DAGs for 12 nodes | Tripartite structure (risk→disease→symptom)                | Reduces hypothesis space to 131,000, enables learning from much less data                 | "it really cuts down the hypothesis space"                                                                                                                               |
| Visual Program Learning                         | All possible pixel patterns         | Compositional drawing primitives                           | Can learn complex patterns by building up from simple primitives                          | System learns to compose complex drawings from basic elements                                                                                                            |
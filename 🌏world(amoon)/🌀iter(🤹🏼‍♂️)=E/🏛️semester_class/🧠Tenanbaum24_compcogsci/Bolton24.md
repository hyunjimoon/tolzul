2025-03-10

U_I = ‚àí [p‚ÇÄs‚ÇÅ + (1‚àíp‚ÇÄ)(1‚àís‚ÇÇ)]K ‚àí C

U_S = p‚ÇÄs‚ÇÅ(1‚àíŒ±)V + [p‚ÇÄs‚ÇÅ + (1‚àíp‚ÇÄ)(1‚àís‚ÇÇ)]Z + Z (elezabeth holmes style)

scientist should be paid for disproving the technology

| Section/Subsection                                 | üîêResearch Question                                                                        | üß±Literature Brick                                                                                                                                                                                                                           | üîëKey Message                                                                                                                                                                             | üìäEmpirical Evidence/üìêMathematical Formalization                                                                                                                                                              |
| -------------------------------------------------- | ------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1. Introduction                                    | Why are early experiments poor at identifying whether technologies will work at scale?     | ‚Ä¢ High failure rates in pharmaceutical development (Paul et al. 2010)<br>‚Ä¢ Similar poor predictability across industries (Siegmund et al. 2021; Greenwood et al. 2022)                                                                       | üßç‚Äç‚ôÄÔ∏èWhen entrepreneurs control experiment design but investors can't verify design quality, a novel form of moral hazard emerges that impedes learning                                   | ‚Ä¢ <10% of molecules identified in preclinical stage progress to launch<br>‚Ä¢ Billions invested annually in projects that ultimately fail                                                                        |
| 2. Relation to Literature                          | How does this moral hazard differ from other agency problems in innovation financing?      | ‚Ä¢ Principal-agent framework in innovation (Aghion & Bolton 1992; Hellmann 1998)<br>‚Ä¢ Discretion to influence learning (Bergemann & Hege 1998; Cornelli & Yosha 2003)<br>‚Ä¢ Entrepreneurial experimentation literature (Gans, Stern & Wu 2019) | üß≠Unlike standard agency problems resolved through incentive alignment, experiment design moral hazard cannot be mitigated through typical "skin-in-the-game" contracts                   | ‚Ä¢ Standard models focus on diverting funds/effort or window-dressing signals<br>‚Ä¢ This model focuses on manipulation of learning technology itself                                                             |
| 3. Model: Basic Setup                              | How can we model experiment design choices in a principal-agent framework?                 | ‚Ä¢ Medical diagnostic models (sensitivity & specificity)<br>‚Ä¢ Multitasking principal-agent problems (Holmstrom & Milgrom 1991)                                                                                                                | üåèExperiments characterized by sensitivity (true negative rate) and specificity (true positive rate), which entrepreneurs can manipulate                                                  | ‚Ä¢ Two-state venture outcome (success/failure)<br>‚Ä¢ Experiments produce binary signal (pass/fail)<br>‚Ä¢ P(s=P\|v=V) = s‚ÇÅ (specificity)<br>‚Ä¢ P(s=F\|v=0) = s‚ÇÇ (sensitivity)                                       |
| 3.1-3.2 Experiment Structure                       | What is the value of experiments with varying levels of informativeness?                   | ‚Ä¢ Research on experiment design<br>‚Ä¢ Statistical decision theory                                                                                                                                                                             | üó∫Ô∏èWith higher specificity and sensitivity, experiments generate more value from information discovery and reduce need for costly development of unviable ventures                        | ‚Ä¢ Expected payoff: œÄs‚ÇÅ,s‚ÇÇ = p‚ÇÄs‚ÇÅV ‚àí [p‚ÇÄs‚ÇÅ + (1‚àíp‚ÇÄ)(1‚àís‚ÇÇ)]K ‚àí C<br>‚Ä¢ Value increases with both s‚ÇÅ and s‚ÇÇ                                                                                                        |
| 3.3 Solving for Independent Tasks                  | Why do entrepreneurs and investors prefer different experiment designs?                    | ‚Ä¢ Agency costs in learning<br>‚Ä¢ Decision theory with imperfect information                                                                                                                                                                   | üß†Entrepreneurs prefer experiments with higher false positives (maximizing continuation probability) while investors prefer "killer experiments" that accurately identify failures        | ‚Ä¢ Entrepreneur maximizes: p‚ÇÄs‚ÇÅ(1‚àíŒ±)V + [p‚ÇÄs‚ÇÅ + (1‚àíp‚ÇÄ)(1‚àís‚ÇÇ)]Z + Z<br>‚Ä¢ Investor maximizes: p‚ÇÄs‚ÇÅŒ±V ‚àí [p‚ÇÄs‚ÇÅ + (1‚àíp‚ÇÄ)(1‚àís‚ÇÇ)]K ‚àí C<br>‚Ä¢ Entrepreneur always chooses s‚ÇÅ=sÃÑ‚ÇÅ, s‚ÇÇ=s_‚ÇÇ regardless of incentives        |
| 3.4-3.5 Solving for Substitute/Complementary Tasks | How does relationship between sensitivity and specificity affect the moral hazard problem? | ‚Ä¢ Multitasking literature<br>‚Ä¢ Research on experimental design tradeoffs                                                                                                                                                                     | üëìDepending on experiment technology, entrepreneurs might face tradeoffs between sensitivity and specificity, making problem worse when they are substitutes                              | ‚Ä¢ With perfect substitutes (s‚ÇÅ+s‚ÇÇ=Œ∫), conflict is maximized<br>‚Ä¢ With perfect complements (s‚ÇÇ=Œªs‚ÇÅ), higher incentives can align objectives if p‚ÇÄ>Œª(1‚àíp‚ÇÄ)                                                       |
| 4.1-4.2 Market Failure and Inefficiency            | What market inefficiencies arise from this moral hazard?                                   | ‚Ä¢ Market failure literature<br>‚Ä¢ Theory of incomplete contracting                                                                                                                                                                            | üåèMarket completely fails when range of possible sensitivity is too large; otherwise ventures get funded but with inefficiently designed experiments                                      | ‚Ä¢ Market failure if p‚ÇÄsÃÑ‚ÇÅV ‚àí [p‚ÇÄsÃÑ‚ÇÅ + (1‚àíp‚ÇÄ)(1‚àís_‚ÇÇ)]K ‚àí C < 0<br>‚Ä¢ Inefficiency cost proportional to sensitivity range Œîs‚ÇÇ<br>‚Ä¢ Exists threshold Œîs‚ÇÇ* above which market fails                                 |
| 5. Paying for Failed Tests                         | Can contracts resolve the moral hazard by incentivizing failure identification?            | ‚Ä¢ Research on incentive design<br>‚Ä¢ Contracts under asymmetric information                                                                                                                                                                   | ü§úRewarding "proof of failure" can align incentives, but solution is fragile and requires precise calibration to entrepreneur's private benefits                                          | ‚Ä¢ Optimal payment X ‚â• Z to incentivize maximum informativeness<br>‚Ä¢ If X too high, creates reverse incentive for false negatives<br>‚Ä¢ Viability depends on relationship between sensitivity/specificity        |
| 6. Policy Responses                                | What institutional arrangements might overcome this friction?                              | ‚Ä¢ Institutional solutions to market failures<br>‚Ä¢ Third-party validation literature                                                                                                                                                          | üß≠Universities can play crucial role as intermediaries validating experiment design quality, enabling financing for deep tech ventures                                                    | ‚Ä¢ Universities have expertise, equipment, and reputation incentives to maintain credible validation processes<br>‚Ä¢ Value of validated general purpose technologies increases with number of dependent projects |
| 7. Conclusion                                      | What are the implications for financing science-based innovation?                          | ‚Ä¢ Innovation financing literature<br>‚Ä¢ Work on deep tech venture challenges                                                                                                                                                                  | üîëNovel moral hazard in experiment design explains both poor predictability of early experiments and lack of funding for deep tech ventures, requiring new approaches to incentive design | ‚Ä¢ Standard "skin in the game" incentives cannot resolve this moral hazard<br>‚Ä¢ Institutional solutions like university validation may be necessary                                                             |

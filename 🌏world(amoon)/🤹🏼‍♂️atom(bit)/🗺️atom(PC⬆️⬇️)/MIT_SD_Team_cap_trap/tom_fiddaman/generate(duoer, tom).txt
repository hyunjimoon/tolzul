Hey there.

I can you see me? Yeah. Oh, cool. Um How are you?

Good. How are you doing?

Ah, I've been building like a model and my head is exploding

now

is

it an SD model or some other kind of model?

I mean everything is s the model only differences whether I'm doing and Benzema or not right.

Yes true.

Hey, may I walk you through this model, startup pivot? Sure. Your experience and insight will be very helpful. Um, okay. So this is consistent with what I was doing previously about. There is some motivation from outside and whether how this agent startup agent, we're going to process it, and I settled with the word inward pivot an outward pivot, meaning one example is let's say Evie companies started with a rural market, but they realized that in a rural area, there is not enough infrastructure.

So for charging,

so sure, yeah. So you need density Yeah. Yes. So they're learning. Um, yeah. So what I'm odo struggle struggling is there seems to be two mechanisms of learning coming in. First is by external evaluation. And another is by its own choice of pivoting. So, like, it's both a function of what the environment is outside and what I choose to be where I choose to be in.

So So, let's see would you call the just to be sure I understand that would you say the external mechanism is essentially you know, doing things like you know, essentially trying to model the environment to understand how it works to make a choice, whereas the internal is, is just trying to experiment and adapt to whatever works is that the difference?

Maybe, but yeah, yes and no. Yes, in the sense that the first two so the first figure is what I think as external evaluation based learning, and second one is more like outward pivot based learning. And your comment about we need environment model in order to do this is correct, because here how the learning mechanism is this, which is what is observable is to review zero or one. So, we have a sample the valuation and predicted valuation range. So, the rural market in evey company in the rural market expected from three to five range but what it actually got it was one, so the gap one and the average of three to five is four. So oh, sorry, it's one and four and three, so it should interpret how it will we're gonna use this learning in order to update two things in general. First is optimism and second is uncertainty on market over product. So like having both of them as render variable will create degeneracy. So I tend to write this so it's a ratio so that's where all the head exploding concepts coming in. Because once we normalize this, then we need some interpretation about the angle where it's changing, right? It's not it's always relative.

So that created a headache, but yeah, I think so the way I just one other question before you scroll off of your figure in your diamond, thank you there. So the two the purple direction is they realize rural EVs don't work. So they decided to go urban, which is sort of seek a different environment.

And then the green is seek a different technology package that does work in the environment you're in is that right? Yeah.

So that's Yeah, okay. Yeah.

Inward pivot. And this is what I call out pivots. Yep.

So

immigrants to America who choose to change the environment, they are the intrapreneurs. Right.

Um,

Um, yeah. So, um, in order so I guess most of so this is more. There's two high level differences between this internal I think the confusion comes in, I'm using the same word in a different meaning. So please give me a feedback if there's some confusion from there. Like one is inward pivot and another thing is internal, right. So Right.

Yeah.

So I guess. So I'm looking for a word that can differentiate this learning with the next step learning which is there is a state space in like the treasure Korea for pivots, right? Yep. So the timestamp of pivot decision is much larger than this decision. Um, let me let me try to elaborate on that. So this is more fine grained. But every time we update optimism or uncertainty I designed so that the agents update of the belief is operationalized as a choice for either changing the market or a pivot, I mean, the product Yeah, meaning. Yeah, so that was a little hard. Um, so that means if we update this belief, like every week, then every week this market, or product pivot should happen. That's how I connected this different time steps.

Yeah, so but I guess there could be sort of feasibility issues you might be getting information continuously. And updating your perceptions of what's going on continuously, but it might take considerable time to make the internal or external pivot that embodies your response to those things, right.

Yeah, the like the most popular question I get upon, I'm modeling this pivot is this such a discrete event? How can you model this was a simulation.

So

I think the way to do that is instead of like putting in a very continuous way like, for instance, I have an example for that alone. So I think this was a company. Okay, so the title title is tragic dynamics agency.

Path dependency and self organized emergence.

And I'm the company Donalyn has went through several pivots,

for instance, in the bear market liberalisation and Eastern Europe, so they expand market

to New Jersey geographic or markets, fixing their products. And also Oh, this is the same thing. Oh, I don't Oh, they had like two different pivots.

I mean, I know that the word pivot is a little bit limited, but I'm using it as sort of like a change. Like, right so pivot is kind of a strategic change that's, you know, big enough to be interesting. Yep, yep. Yep.

Yeah. Um, so another interesting thing is fixing the market health conscious customers update the product to a health focused food products. So I guess this emoji is outward and this emoji is inward.

So this you can see that customer is fixed and we are adding to our product portfolio helps focus with products because high market uncertainty and a focus on fast growing less volatile segments, yep.

Or this is outward. So fix core product categories, and they focus on emerging markets. And they also had a high investment in r&d and diversified. So like one thing lusher is how different is pivot trajectory of a very established company versus startup, because in terms of pricing, this model, I have like different examples very early stage that is different from Thanos. Do you think in communication wise, this exists examples start examples might be easier.

It might be in the sense that I don't know what's the difference, I guess. The difference is a big company is kind of well capitalized and somewhat diverse. So they can try various experiments without kind of risking the whole company. Whereas when you're a startup, you know, yeah, you don't have enough people to try 10 things and you don't have enough money. So you might try. You know, you get to try one thing, and if you screw up you die.

So one one challenges. Like, this is a long term, and it's more likely they would experience different types of pivots. Yeah, but what I'm doing is just seeing a bunch of early stage startups, right. So I don't know which would be more useful. Just a very like horizontal data versus Right, right.

I guess the then there's another problem, which is the I can't think of the name of the term but it's sort of sort of the equivalent of truncation bias that you only get to observe the successful attempts. The the unsuccessful attempts are harder to see.

So one way to kind of pin off from here is I was focusing on coming up with different different reasonings of for instance, if the hyper parameter market dynamics become more increase, how, what are the reasoning for outward pivot versus inward payments? For instance, as market becomes dynamics startups, fix product and accelerate market change? Because in a hot dynamic markets intrapreneurs Tick was familiar products while exploring new market applications, because it's difficult to assess the potential of new products. So meaning, the like, there were Kinos exploiting around me, so if I somehow change the market. Oh, sorry. Sorry. Sorry. Oh, yeah.

So this is push technology push. And this is the customer pool, right? So so on the left column there, you're saying that you've got a product that sort of works for something and you try to because there's so much turbulence you try to find a an environment where your product is going to succeed?

Yeah. Yeah.

That sort of makes sense.

So this is kind of reminisce and so I wonder how the SD people SD thinking can help me resolve this issue. But the class I'm taking about, I'm sorry. The math or science so this is the first slide and Abdullah the professor was confused at the link weight and the collective intelligence, some literature say this decrease and some literature saying increase. So that was what I like to replicate here. So you can imagine this as one paper that says the more dynamic market is you should stick to your product and change your market versus another paper saying that, no, you should fix your market because their learning is noisy, too noisy if you change your market around so you cannot really have a nice evaluation of your product visibility.

Right? Yeah. So if you're continuously changing the product and the markets changing in some turbulent random way, then you never you never learned. Yeah.

So I was trying to find literature that supports each hypothesis and also for optimism, which is for the reason of degeneracy I defined as new product minus new market over a new product. Yeah.

So when I say new product, this is I have a stent. code that is more concrete and a mean B is a general in general how for every market on average, how is my product average product be accepted? So relief on his average product accepted by average market standard nice by your uncertainty of a product? So that's this an uncertainty is in the end for specific markets. If you imagine there's two distributions that are added to a mean B, which is the market stability allottee and also your confidence on the market or the confidence about the product, right. Got it. So. So this is supplied by the data and this e is the valuation II was the very small star that was on the left here. This zero or one is supplied to here and it started up compares with the its prediction, and learned and update this either. Aiming or a or I'm the sigma.

So that was why in other words, if you get information that's not congruent with your expectations, or your perceptions or whatever, then you either you either sort of move your prior move your update your posterior or in the sense of move the mean or you move, increase the sigma is that right? Yeah.

Yeah. One thing I haven't figured out yet is how to transfer the a mean to other markets. Meaning here I'm saying that it moves to other markets.

So even though I Yeah, Arbor

mark, the a mean still survives right?

Meaning, so this right or in the case of your rural to urban shift, you kind of expect that the mean for the urban market is better because that's why you're making that change. Yeah.

So that means like, in reality, when we get very bad review, our original belief about a mean also decreases,

right.

So I need to somehow add a mean, in here as well, like, for instance, on exponential one, meaning I need to see what's in a model block is what is being inferred. That means zero, that very bad evaluation in a rural market would affect my general belief on average market, accepting my average product so that even though I move to the urban market, my confidence would be very low. Optimism would be lower. That's not Yeah, not included. is exponential. But I guess in order to discuss about this, the pivot, I don't I need to come up with a Markov Decision Process formulation. But that memory of my product acceptance in general, should be memoryless or not, is one big issue now.

Okay, wait a second. So.

So

just put it in a very simple term when I move from rural market to urban markets or restarting a new prior for the market acceptance or do we have some memory that

I see, right?

And that affects how we define this space? Because then we need to, on top of, so currently, I have, I think, five state one is which market you are in and which product you are having and also their mu and sigma for each. And also I need to add the Amundi in general how my product is accepted in the overall market. Right. And by that I think that would really wreck the state diagram. Right?

Yeah, just get the dimensionality gets too high. So I think I understand the, the top state the scale state, and the bottom. The ones in between what is the numeric vector mean?

What are the are those sort of three subscripts essentially, so that this is a yeah, this

or try nary. I guess it's binary, right. It's a sort of a binary string that describes your current strategy.

Um, yeah, thanks for asking. So why have?

Yep, so this was the MDP formulation of that problem. And the current market and current product, the index, that was what was appeared in 11122122. Yeah. So optimism and uncertainty should be state.

Got it. So optimism and uncertainty are sort of the mean and variance of your expectations. Yes. Got it.

Um, expectation is there a better word than expectation?

Pretty Yeah.

Expectations probably bad to us because people Yeah.

Well t have a dual SD people would tend to use perception.

Oh, mean of perception.

Right. Meaning you're sort of the there'd be it's the perceived state of the system. As opposed to the actual state of the system.

Between prediction and perception, which do you recommend in this context?

I might use perception because prediction might be interpreted as a prediction about the future.

But isn't this what we're trying to do based on our perception and we predict with all right,

you aren't you're trying to predict the future outcome of some chain or some trajectory you're on. So prediction might be okay.

Thanks, thanks. Um, yeah, so the action is change market or change product. And the reward is the review that I get and hopefully, this would make sense. So do you think without ignoring the memory between the market and between the product, this for state is enough? Am I missing something?

Well, I could think of lots of things you could add, but for for seems like enough to be interesting. Well, I guess the the fifth state that would be interesting, might be well, I guess there are two, at least two more states that are seem particularly interesting to me. One is how much cash do you have?

Oh, okay. Yeah, exactly. I have cash and I forgot.

Oh, okay. Okay. And then I guess the other would be something like a measure of capacity in some sense.

How much product can you deliver?

Oh, my so does that change over time?

Yes. In the sense that either you have to build factories or you have to you know, commit to relationships with suppliers or something. But I guess, you know, if it's a cloud computing service, it might just be a matter of sort of spinning up more servers on Amazon or something in which case capacity is more or less variable.

I see. So all I see. So that would affect can that be included in the uncertainty about your product? Meaning the more capacity you have another way to think about uncertainty is controllability.

So the more capacity you have, you have less uncertainty on the product, which would somehow not you to change the market rather than a product. Not. That seems like kind of a big leap. I'd probably rather sort of leave capacity out and just assume it's flexible in the first analysis.

Got it. So the reason I tried to formulate this as a MDP is Charlie gave me the piece about connecting optimal stopping with the pivot.

And we can formulate the optimal topping with for instance, a parking problem where you have C parking lots and at each point you should decide if the parking lot is empty, you should decide whether to park or continue.

And the reward is somewhere between the waiting time and the closeness to the entrance.

But

what I was having difficulty was optimal stopping I don't know how to define the reward in an entrepreneur Product Market Fit finding setting

so it's Oh yeah.

Pivoting in started refers to structured course correction designed to test the new fundamental hypothesis about the product, strategy and engine of growth.

So there seems to be I think product pivots ready to pivot and engine of growth pivot. I don't know what engine of growth pivot might mean.

You can you guess, engine of growth.

Pivot

Yeah, it seems like kind of an ambiguous term that.

Yeah, like traversing through a series of potential value creation motifs. That's exactly what the limits to growth is doing right. Nine different scenarios ahead of you.

The Limits to Growth archetype

you mean Um, no, the book itself the book itself.

Gives, like different I think it was 11 or nine scenarios or had Oh, I see. I see. Yeah, yeah.

Was it 11 Or nine? Do you remember?

Um, I don't remember off the top of my head.

Nice. Okay.

I want to say I actually I would have said like 12 or 13.

But, oh, okay. Maybe you're right. Yeah, so there's also like fail fast and fail chip.

So one question I got from my pivot model is is this one idea or just one startup? Meaning, imagine that I have an idea about Evie in rural market and also GPT or in other like manufacturing for instance.

And I have a cup of capacity to build the software needed for both I'm from Ai Robotics Lab, for instance. So, you can interpret this as when I say agent, it can be an idea of a startup versus a startup by itself. You know what I mean?

Yeah, and then this is sort of optimal foraging ideas, kind of an interesting way to put it. Because typically, in a market, you're not the only one foraging there are a bunch of other startups who are exploring the same territory. For the same resources, maybe with different strategies.

So what they're saying is, constraints and pivoting is rarely discussed. So I mean, that is represented as using the experiment opportunity to cash cash.

Okay, yeah. So that part yeah, part of the foraging model also is that there's a cost to time spent changing things as opposed to time spent executing the current strategy.

Can you give me example of a foraging model?

Oh, there there are quite a few in the echos system literature. Buzz hauling was kind of one of the pioneers there was folding Yeah.

Optimal foraging theory was How do you spell

Yeah, Pauling h o l l i n g.

This is just Oh. It's the high level idea. Animal's best foraging strategy. Oh, that's what the optimal optimal optimal stopping comes in. Right? Like whether I should eat this rabbit or not. Right in the hope of finding a more delicious rabbit.

And so I don't know this literature very well. But one of the things hauling worked out was that yeah, there actually there figure two there is those are the howling response curves. Were the amount of prey you can consume is limited by the fact that once you catch something, it takes you some time to eat it. And then it takes some time before you get hungry again. So even if you were infinitely fast at catching rabbits, you wouldn't eat an infinite number of rabbits. Because once you've eaten one at least for a few hours, you're not ready for the next one.

So when the ride sharing system is making MDP for ride matching, they modelled the idle workers.

And it's like the action from the Imagine that your Uber central agency and your action is requesting to this idle workers certain destinations. That's yeah. Oh, yeah.

And, and what's interesting for the state transition was if your action for requests is rejected, then the idle workers they have four seconds gap in order to get the next action. Like, yeah, so one driver even though they keep rejecting cannot appear infinite numbers of time in our state system.

Oh, I see.

So, that is somewhat similar to like, remember, I mentioned this as a factor with direction and speed.

Yeah. And

I'm like, when I was going through the examples, some felt more relevant if I if I connect with speed, and some felt more relevant if I connect with like, I'm like, sorry, for instance. If we have a more experiment opportunity, then I think they would, they would be able to spend more cash on parallel experiment. So like fixed product and increased market change speed, but it's like you you're describing doing parallel experiment as like a round robin. So it's like changing a speed is much faster. Right. But there are some instances where I, it's better to say like, I don't know, I'm a little blabbing because I didn't come up with a good way to differentiate the speed and the direction and vectors length.

So just to distraction for a moment. Is this one of the possible

one of the possible applications of AI that you could do experiments in inexpensively by essentially using you know, GPT or whatever as a as kind of a cheap and fast way to experiment with products, you know, so you give it the prompt you know, you're a you're a parent of two children living in Illinois and you make $63,000 a year, and we have this new kind of yogurt that costs $1.50 for a pint. Would you like that? You know, which is sort of traditional market research except instead of asking actual people that you just ask, sort of this the implicit summary of actual people that's in in the parameters of the neural network. I would guess people have tried that. Is that actually happening?

Yeah, I heard that they are creating the AI versions of a customer into a focus group. Yeah.

Yep.

So AI is just a set of theories and logics.

And if when I was building this supporting reasoning, I use GPT to come up with the reasoning that could support this hypothesis fits. Oh, interesting.

But, um, I guess, even though I'm trying to walk you through whether each makes sense or not the over all message in the end would be the current literature that focusing on one cell is less useful. You need a bigger picture. But we need to first make sure that this each cell makes sense.

Yep.

So yeah, sorry, I just dragged you there.

So imagine this as like one GPT to GPT and three GPT and four GPT and whether we can find a consistent enough GPT to believe on this one cell. That's our goal, if that makes sense. And in terms of that, I'm sorry to just roam around different places, but in terms of vectors, direction and speed. Like for instance, let's say the market is very dynamic. And what I was trying to say was, um, that could first affect the angle a bit depending on some reasoning.

Yeah, or it can also affect how

fast this decisions comes in. Meaning at first this was like time to change market over time to change your product.

So right, whether

we were going to use a what unit we're going to use will affect whether angle or the speed or the length. I think, three should be degenerate. So I'm curious what are the easiest communicable units I can use among the three.

I kind of like the angle and speed idea just in the sense of, you know, one decision you can make is just how fast to adapt in general and then the other decision is, in your adaptation, do you prefer the internal or the external? direction?

But I guess, if you were to specify your internal speed and your external speed that's maybe an equally useful way to think about it.

What do you mean I didn't get your last call? Well, so.

There, so I guess I'm thinking there's sort of two possibilities. It's either Cartesian coordinates or polar coordinates. Exactly. Yeah. And they're, and they're both equally good.

During the space exploration, the Cartesian like coordinate, I mean, the radial coordinate was very helpful.

Oh, yeah, I can see that.

My guess is you. You don't have to worry about that. Initially, because it'll probably become clear at least. Once you start writing more equations. It might be easier as well, so maybe part of the decision then is related to the other, the optimism and uncertainty dimensions.

So those seem more Cartesian to me in a sense, so maybe it's better to just make everything the same.

So Cartesian out of the speed, length, and angle. So it's Cartesian excludes the angle part. Right.

So in other words, I guess the way I'm thinking of Cartesian is you'd have a sort of a speed speed of internal updating and a speed of external pivoting.

I suppose to having a speed of pivoting, and then a sort of a preference between internal versus external.

I see. Yeah, that's very helpful.

Um, did you intentionally differentiate updating and preparing or was it? No, it was just the first time I said update and I should have said that. already. It's for consistency.

I think you're I mean, I tend to observe that trolley and your word choice is much more communicative level than what my word choice because I'm Korean nine, maybe it's thicker. So when you say external instead of inward is this Do you think it's better?

Oh that's interesting.

I think I do kind of like external and internal better. Yep.

I

decided to

have full faith.

In your optimism parameter may be too high.

So was just to make clear that was the difference between this one step learning versus multi step learning, meaning like the sequence of path like for instance, when I say sequence of path, this is more like from this diagram. There could be some events happen and in the end, yes, different actions.

Yeah.

And the learning from this versus to learning from the other. The update is different. But I don't know the approximate language to represent that.

Right.

I mean, this idea of

it's sort of an interesting puzzle. I'm not sure I'm quite answering the question, but it seems like discrete quantization of these experiments is kind of important. At least in some situations, you know, I guess if you have you know, if you're, if your startup is like a food tracker, something then you can you could do more or less continuous experiments, you know, give people more and more hot sauce until they start to complain or something.

But if it's continuous, but it's actually discrete, right, we can

say it's at least well, yeah, so I guess, but you do get, you know, 20 or 30 opportunities to try that experiment each day. Whereas if you're building an Eevee, or a rocket or something and you decide to change the motor, yep, the cycle time to get new information about how the new option is performing might be pretty long.

So that is why like you said, One experiment is normalized to one time unit. So that update of the change or the market or change if the product is according to that unit. Right currency is one experiment, meaning they can say, Oh, my pivot cost me three experiments. Kind of thing.

Yes, right. Yeah, I guess that's kind of how I was thinking is the sequence. Or, yeah, the sequences, how many updates? Do you get in between pivots? Yeah, yeah. And that partly depends. On how costly is a pivot?

Yes, but one thing is one experiment always leads to one pivot. Yeah, maybe I confuse you.

Okay. Okay. Yeah.

So that was why standardization happens in two ways. One is the belief itself. But also in the action itself. We put product pivot as one unit, and Romer liase kind of standardized market pivot according to that, meaning. I know this is a little confusing. Sorry. But um, the decision rule for pivoting the market is you have some expectation range, and if your real review you received is less than your low bar. But if the evaluation you get is between low bar and high bar, then you always do the product pivot. And if you have high bar over evaluation, then you scale and if you run out of cash, then you fail.

I see. I see. Yep.

So sorry to confuse you one more time, but no,

no, that actually that makes much better sense out of the Markov diagram here.

Ah, yes. Can you check whether I'm thinking it right, because what I just explained, I think is one heuristic. So perhaps one reason to use our L is this heuristic can be beaten by like automated decision rules.

Yep.

That's it. I think that makes sense. I, I at least to don't have an immediate objection. So and actually Yeah, sort of the the idea of an envelope of you know below with blow the envelope you fail and above the envelope you grow like crazy with your current strategy makes a lot of sense.

So that's the heuristic that RL is trying to beat right? Yeah, like explanation. And maybe the action chosen by this RM l agent can be like even though you're between this like high bar and low bar you chose not to change your product, but change your market. Yeah.

So yeah, I have a very clear, sorry, I guess there's one possible complication. Which is scaling itself might be kind of entangled with the other dimensions, in the sense that as you scale up, you know, you get lower costs, which as affects your ability. To price into certain markets that might not either be otherwise be effectively and might also require, say, you know, a redesign of the product for better manufacturability or something. So, but I think that's sort of a second order complication that you can introduce later once you get the initial idea. Working.

I see. One difficulty for scale is there is concept like premature scaling, right. So how to disincentivize that is another issue. But that requires to know like, I think it's always ex post. You're too immature to scale. That's how do we know if we were no, we wouldn't have scaled? Right?

Um,

yeah.

Yeah. And they're probably lots of examples, especially like when interest rates were really low.

There are probably a lot of things that got scaled that were actually stupid ideas but but since you know, since Ash was cheap, and everybody's looking for a return, you know, they're thinking they're probably thinking, Oh, well, if we can just get this scaled up, we'll just crush all the competition and make lots of money and scaling in a sense becomes an end and it's an

interesting thing about Reinforcement learning is we can incorporate the interest rate concept through the discount factor.

Yes, right.

Is high interest rates means that our discount factor is slow and usable.

If the discount factor would be low, discount rate would be high. Yes.

Maybe tomorrow $1 is dropping very highly. Right.

If we have a high interest rates, if you have a high interest rate, I mean, so I guess high interest rates implies that your cost of capital is high, which implies that you should only pursue projects that you think are going to generate a higher return.

But I'm a little confused why a high interest rate equals high discount rate.

Oh, so normally, I would just equate the two essentially that your discount rate should be your sort of perceived risk free rate of return or something. But if you're talking about the discount factor, applied to as as a multiplier to some future cash flow. That's basically e to the minus discount rate times

this one.

Right.

So this discount factor that you're describing at minus RT,

oh, wait, no, that's not what I had in mind.

was a little over complicated, but it's Q learning meaning we want to learn the value of a action given a state. Yeah, and this is our prediction. And this is our target that's based on our value, what is the optimal?

So what is R here?

The R is a reward.

Ah, okay.

I've chosen a terrible slide. Let me come come back with this that happens to be the difficult slide of all. Sorry.

This count back. Yeah, something like this.

Okay. So yeah, so I think that's a discount factor, which is the equivalent of Yeah, if the weight you would apply to some future cash reward is e to the minus interest rate times time, or times the horizon that you're looking at. So I so as the discount rate goes up, the discount factor goes down. Think that's how I would interpret this.

So this is interest rate, and this is like T.

Yeah, the time. T is the time of evaluation.

Um, but it's like one step ahead.

So I guess this is like, Oh, right. Yeah.

So if it's just one step ahead, then sort of time drops out and that becomes a dimensionless per step factor. Like compared to like 2% interest rate when you have like 4% interest rate that means your tomorrow reward is less valuable compared to person, right, right. Oh, god, that's so it's inversely proportional. Right. Thanks. Thanks. I guess you may need to go

Yeah, I probably should. I'm very helpful.

Good. Well, yeah, this seems like it's on an interesting track. So like less pissed off like asking for advice. How would what this good language to differentiate this learning versus this learning? Do you have any suggestion?

Let's see. I liked the diamond thing. And I like the sort of the idea of the experiment and the thresholds for scaling and failure. So I, I think, kind of the sequence of the three charts that you have under number two here. Works or at least it worked for me after some coaching. So, so it seems seems like an explainable thing. Oh, well, actually, I noticed one thing with the way they're sitting here though, is the on the left the diamond the purple external pivot is up. And on the right side, the purple is down.

Oh, this one?

Yeah. And for down doesn't necessarily have meaning but it might help to make them the same.

Ah, yeah, yeah. Good. Boy.

Yeah, okay. Yeah, thanks.

But I guess is it do you think if I make this as a 1234 kind of sequence would that be? Yeah, that I think that works.

If you were to leave off one diagram, like what would be among the four

let's see the one I had the most trouble with. Let's see. I guess I like the, the diamond and the sort of causal loop diagram looking one the most. The other two. I like the Markov diagram, but I'm not sure you need it. To kind of explain the sequence

whereas the one with the distributions. You might, you might need that to kind of explain the concept of uncertainty.

So I guess like there's three hierarchy belief of the and experiment, experiment and pivots, right? Yep. So this connects belief update to one experiment. Yeah. Like, and this somehow ties one experiment and how the pivot happens. And this explains a pivot direction, I guess the angle Yep. relate to the belief update? Um, yeah, so the question is, like, if I follow the heuristic rule, how would that affect the pivot angle? Right? Yes.

And how does how does uncertainty affect the choice of pivot angles? Well,

yeah, yes. Yes. So this whole exercise was about pivot angle is the output variable and like, what is the the angle over the DIS parameters are? And I guess Yeah, I just want to order them in the like order of increased timesteps. But I'm having trouble with that. Because you mentioned this is a sequence so perhaps this should come in the end after this because this is still like one pivot segment. Right?

Right. That's true. Then the marker of diagram that's sort of the this the summary overview or the outcome of the components that are in the previous ones.

I guess this is one and two and kind of three. This is like to sequence Yeah, for Okay. Thank you. Very thing.

Yeah.

I love all your comments today. Thanks, Tom.

Sure, have a great week. I

thank you.

Transcribed by https://otter.ai

---
ì„±ì¥:
  - 2025-10-15T15:03:02-04:00
---
Video title: Ambiguity and confirmation bias in reward learning
    
Video URL: https://www.youtube.com/watch?v=Fagr6lo7kNs


   Annì€ ì›ë˜ ì•½ê°„ ë¹„ê´€ì ì¸ ì„±í–¥ì…ë‹ˆë‹¤.  
ì–´ëŠ ë‚  íŒŒí‹°ì— ê°€ëŠ”ë°, ë³„ë¡œ ê¸°ëŒ€ë¥¼ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¼ì´ ì˜ í’€ë¦´ ê±°ë¼ê³  ìƒê°í•˜ì§€ ì•Šì£ .  
ê·¸ë˜ì„œ ë¶„ìœ„ê¸°ë¥¼ í’€ë ¤ê³  ë†ë‹´ì„ í•˜ë‚˜ í•˜ì§€ë§Œ, ì‚¬ëŒë“¤ì´ í¬ê²Œ ì›ƒìŠµë‹ˆë‹¤.  
ê·¸ëŸ°ë° Annì€ ì‚¬ëŒë“¤ì´ ìê¸° _ë¹„ì›ƒê³  ìˆë‹¤_ê³  ëŠë¼ì£ .  
ê²°êµ­ ìƒì²˜ë¥¼ ë°›ê³ , ë‹¤ì‹œëŠ” íŒŒí‹°ì— ê°€ì§€ ì•Šê² ë‹¤ê³  ë§ˆìŒë¨¹ìŠµë‹ˆë‹¤.

ì´ë²ˆì—” Bobì…ë‹ˆë‹¤.  
Bobì€ íƒ€ê³ ë‚œ ë‚™ê´€ì£¼ì˜ìë¼ì„œ, ìƒí™©ì´ ëŒ€ì²´ë¡œ ì˜ í’€ë¦´ ê±°ë¼ê³  ìƒê°í•©ë‹ˆë‹¤.  
ê·¸ë„ íŒŒí‹°ì— ê°€ì„œ ë†ë‹´ì„ í–ˆëŠ”ë°, ëª¨ë‘ê°€ í¬ê²Œ ì›ƒì—ˆìŠµë‹ˆë‹¤.  
Bobì€ â€œì™€, ë‚´ ë†ë‹´ì´ í†µí–ˆë„¤! ë‚´ê°€ ê½¤ ê´œì°®ì–ì•„!â€ë¼ê³  ìƒê°í•˜ê³  ê¸°ë¶„ì´ ì¢‹ì•„ì§‘ë‹ˆë‹¤.  
ë‹¤ìŒì—ë„ ë˜ íŒŒí‹°ì— ê°€ê² ë‹¤ê³  ê²°ì‹¬í•˜ì£ .

ì¦‰, _Ann_ê³¼ _Bob_ì€ ì •í™•íˆ ê°™ì€ ê²½í—˜ì„ í–ˆìŒì—ë„, ì™„ì „íˆ ë‹¤ë¥´ê²Œ í•´ì„í–ˆìŠµë‹ˆë‹¤.  
ì´ê±´ ì—¬ëŸ¬ ì´ìœ ë¡œ ì¤‘ìš”í•©ë‹ˆë‹¤.  
ê·¸ë“¤ì´ ì•ìœ¼ë¡œ ì–´ë–¤ _ìœ„í—˜ì„ ê°ìˆ˜í• ì§€_â€”ì¦‰, ë˜ë‹¤ì‹œ ì‹œë„í• ì§€â€”ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.  
ê·¸ë¦¬ê³  ì´ˆê¸° ê¸°ëŒ€ê°€ ì„œë¡œ ë‹¬ëê¸° ë•Œë¬¸ì—, ê°™ì€ ì‚¬ì‹¤ì„ ê°ì ë‹¤ë¥´ê²Œ ë°›ì•„ë“¤ì˜€ë˜ ê²ë‹ˆë‹¤.

ì´ëŸ° í˜„ìƒì´ ë°”ë¡œ **í™•ì¦ í¸í–¥(confirmation bias)** ì…ë‹ˆë‹¤.  
ì¸í„°ë„·ì—ì„œ â€˜confirmation biasâ€™ë¥¼ ê²€ìƒ‰í•´ ë³´ë©´, ëŒ€ë¶€ë¶„ ì´ëŸ° ê·¸ë¦¼ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ â€”  
â€˜ê°ê´€ì  ì‚¬ì‹¤â€™ê³¼ â€˜ê¸°ì¡´ ì‹ ë…â€™ì„ ê²¹ì³ì„œ ë³¸ ê²°ê³¼ê°€ ê³§ ìš°ë¦¬ê°€ _ë³´ëŠ” ì„¸ê³„_ë¼ëŠ” ëœ»ì´ì£ .

---

í™•ì¦ í¸í–¥ì€ ë³´í†µ ë‚˜ìœ í‰íŒì„ ë“£ìŠµë‹ˆë‹¤.  
ì¸ê°„ ì¶”ë¡ ì—ì„œ ë°œìƒí•˜ëŠ” ê°€ì¥ ìœ ëª…í•˜ê³  ë„ë¦¬ ì•Œë ¤ì§„ ì˜¤ë¥˜ë¡œ ì—¬ê²¨ì§€ê³ ,  
ê³¼í•™Â·ì˜í•™Â·ì •ì¹˜Â·ë²•ë¥  ë“± ì¤‘ìš”í•œ ë¶„ì•¼ì—ì„œì˜ **í¸í˜‘í•¨(closedâ€‘mindedness)** ì˜ ì›ì¸ìœ¼ë¡œ ë¹„íŒë°›ìŠµë‹ˆë‹¤.  
ê·¸ë˜ì„œ ì‚¬ëŒë“¤ì€ â€œí™•ì¦ í¸í–¥ì€ ìœ„í—˜í•˜ê³  ì•…ì„±ì¸ ì˜¤ë¥˜â€ë¼ê³  ìƒê°í•˜ì£ .

í•˜ì§€ë§Œ, ë§Œì•½ ì´ í¸í–¥ì´ _ì ì‘ì (adaptive)_ ì¼ ìˆ˜ ìˆë‹¤ë©´ ì–´ë–¨ê¹Œìš”?  
_í†µê³„ì (Bayesian)_ ê´€ì ì—ì„œ ë³´ë©´, ê·¸ê²ƒì€ ì˜¤íˆë ¤ í•©ë¦¬ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ì¦‰, ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ëª¨í˜¸í•œ ìƒí™©ì— ì§ë©´í–ˆì„ ë•Œ,  
ê¸°ì¡´ ë¯¿ìŒì„ ë°”íƒ•ìœ¼ë¡œ ê·¸ê²ƒì„ í•´ì„í•˜ëŠ” ê²ƒì´ í•©ë¦¬ì ì¼ ê°€ëŠ¥ì„±ì´ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.  
ì»´í“¨í„° ê³¼í•™ì—ì„œëŠ” ì´ë¥¼ â€œê·€ë‚©ì  í¸í–¥(inductive bias)â€ì´ë¼ ë¶€ë¦…ë‹ˆë‹¤ â€”  
í•™ìŠµ ê³¼ì •ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‹œì‘í•˜ê²Œ ë„ì™€ì£¼ëŠ” ì¼ì¢…ì˜ â€˜ì‚¬ì „ ë°©í–¥ì„±â€™ì´ë¼ëŠ” ëœ»ì´ì£ .

---

ê·¸ë˜ì„œ ìš°ë¦¬ëŠ” _í™•ì¦ í¸í–¥ì´ ì‹¤ì œë¡œ ì ì‘ì ì¼ ìˆ˜ ìˆëŠ”ê°€_ë¥¼ ì‚´í´ë´¤ìŠµë‹ˆë‹¤.  
ì´ ì£¼ì œëŠ” ì—¬ëŸ¬ ì˜ì—­ì—ì„œ ì´ë¯¸ ë‹¤ë¤„ì¡ŒëŠ”ë°,  
ì˜ˆì»¨ëŒ€ ì‚¬ëŒë“¤ì´ ìì‹ ì´ ì´ë¯¸ ê°€ì§„ ê°€ì„¤ì„ í™•ì¦í•˜ëŠ” ì •ë³´ë¥¼ ë” ì°¾ì•„ë³´ëŠ” ì •ë³´íƒìƒ‰ ê³¼ì •,  
ë˜ëŠ” _ì§€ê°(perception)_ ê³¼ì •ì—ì„œ ì• ë§¤í•œ ìê·¹ì„ ê¸°ì¡´ ì‹ ë…ì— ë”°ë¼ ì–´ë–»ê²Œ í•´ì„í•˜ëŠ”ê°€ ë“±ì´ ìˆìŠµë‹ˆë‹¤.

í•˜ì§€ë§Œ **ë³´ìƒ í”¼ë“œë°±(reward feedback)** ì²˜ë¦¬ì—ì„œì˜ í™•ì¦ í¸í–¥ ì—°êµ¬ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì ì—ˆìŠµë‹ˆë‹¤.  
íŠ¹íˆ, ìš°ë¦¬ê°€ ì§‘ì¤‘í•œ ê²ƒì€ **ì„ íƒí•œ í–‰ë™ì˜ ê²°ê³¼ì™€ ì„ íƒí•˜ì§€ ì•Šì€ í–‰ë™ì˜ ë¹„êµ(ì„ íƒí™•ì¸ ë¹„ëŒ€ì¹­, choiceâ€‘confirming asymmetry)** ê°€ ì•„ë‹ˆë¼,  
ê·¸ëƒ¥ **ì• ë§¤í•œ ê²°ê³¼ ê·¸ ìì²´ë¥¼ ì–´ë–»ê²Œ í‰ê°€í•˜ëŠëƒ**ì˜€ìŠµë‹ˆë‹¤.  
ì¦‰, _Ann_ê³¼ _Bob_ì˜ ì‚¬ë¡€ì²˜ëŸ¼, ë™ì¼í•œ ì‚¬ê±´ì„ ë‚™ê´€ì ì´ê±°ë‚˜ ë¹„ê´€ì ìœ¼ë¡œ í•´ì„í•˜ëŠ” í˜„ìƒì„ ê´€ì°°í–ˆìŠµë‹ˆë‹¤.

---

ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” ë‘ ê°€ì§€ ëª©í‘œë¥¼ ê°–ìŠµë‹ˆë‹¤.

1. ì• ë§¤í•œ ê¸ì •ì  ê²°ê³¼ë¥¼ í•´ì„í•˜ëŠ” ë°©ì‹ì´ í™•ì¦ í¸í–¥ì„ ë°˜ì˜í•œë‹¤ë©´, ê·¸ê²ƒì´ **ì ì‘ì  ê¸°ëŠ¥ì„ ê°–ëŠ”ê°€**?
2. ì´ëŸ¬í•œ í¸í–¥ì´ **ê°œì¸ì˜ ë‚™ê´€ì  ì„±í–¥(optimistic disposition)** ê³¼ ì—°ê²°ë˜ëŠ”ê°€?

ì´ í˜„ìƒì€ ì—¬ëŸ¬ ê¸°ì¡´ ì—°êµ¬ì™€ ë§ë‹¿ì•„ ìˆìŠµë‹ˆë‹¤.  
ìš°ë¦¬ê°€ ì£¼ëª©í•œ ê²ƒì€ **ì •ì„œì  ë¶ˆí™•ì‹¤ì„±(valence ambiguity)** â€”  
ê²°ê³¼ì˜ â€˜í¬ê¸°â€™ëŠ” ì•Œì§€ë§Œ, ê·¸ê²ƒì´ _ì¢‹ì€ì§€ ë‚˜ìœì§€_ëŠ” ëª¨ë¥´ëŠ” ìƒí™©ì…ë‹ˆë‹¤.  
ë‹¤ì‹œ ë§í•´, íŒŒí‹°ì—ì„œ ì‚¬ëŒë“¤ì´ ì›ƒì—ˆëŠ”ë°, ê·¸ê²Œ _ë¹„ì›ƒìŒ_ì¸ì§€ _ê³µê°ì˜ ì›ƒìŒ_ì¸ì§€ ëª¨ë¥´ëŠ” ìƒí™©ê³¼ ê°™ì£ .

---

ì´ì™€ ê´€ë ¨í•˜ì—¬, ë‡ŒëŠ” ë³´ìƒì˜ í¬ê¸°(ê°•ë„)ì™€ ì •ì„œì  ë°©í–¥(ì¢‹ìŒ/ë‚˜ì¨)ì„ ë”°ë¡œ ì¸ì½”ë”©í•œë‹¤ëŠ” ì‹ ê²½ê³¼í•™ ì—°êµ¬ê°€ ìˆìŠµë‹ˆë‹¤.  
ì„ìƒì ìœ¼ë¡œë„, ì• ë§¤í•œ ì •ì„œ ìê·¹(ì˜ˆ: ë†€ë€ ì–¼êµ´)ì´ _ê¸°ìœ ë†€ëŒì¸ì§€, ë†€ë¼ìš´ ë¶ˆí–‰ì¸ì§€_ë¥¼ ì–´ë–»ê²Œ í•´ì„í•˜ëŠ”ì§€ê°€  
ë¶ˆì•ˆì´ë‚˜ ìš°ìš¸ ê°™ì€ ì„ìƒì  íŠ¹ì„±ê³¼ ì—°ê²°ëœë‹¤ëŠ” ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.  
ë¶ˆì•ˆí•œ ì‚¬ëŒë“¤ì€ ì¼ë°˜ì ìœ¼ë¡œ **ë¶€ì •ì  í•´ì„ í¸í–¥(negative interpretation bias)** ì„ ë³´ì…ë‹ˆë‹¤ â€”  
ì¦‰, ì• ë§¤í•œ ìê·¹ì„ ë” ë¶€ì •ì ìœ¼ë¡œ í•´ì„í•˜ëŠ” ê²½í–¥ì´ ìˆì£ .

---

ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” ë‘ ê°€ì§€ ê¸°ì—¬ë¥¼ í•©ë‹ˆë‹¤.

1. **ì •ì„œì  ë¶ˆí™•ì‹¤ì„±(valence ambiguity)ì„ í¬í•¨í•˜ëŠ” ìƒˆë¡œìš´ ë‹¤ì¤‘ì„ íƒ ê³¼ì œ (multiâ€‘armed bandit task)** ë¥¼ ì„¤ê³„í–ˆìŠµë‹ˆë‹¤.
2. **ë² ì´ì§€ì•ˆ í•™ìŠµ ëª¨ë¸**ì„ ìƒˆë¡œ êµ¬ì¶•í•˜ì—¬, ì´ëŸ° ìƒí™©ì—ì„œ ì¸ê°„ì´ ì–´ë–»ê²Œ í•™ìŠµí•˜ëŠ”ì§€ ê³„ì‚°ì ìœ¼ë¡œ ì„¤ëª…í–ˆìŠµë‹ˆë‹¤.

ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‚¬ê³ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.  
í•œ ê²°ê³¼ì˜ ì¼ë¶€ ì •ë³´(ì˜ˆ: í¬ê¸°)ëŠ” ì•Œì§€ë§Œ, ë‚˜ë¨¸ì§€(ì •ì„œì  ê°€ì¹˜)ëŠ” ëª¨ë¥¼ ë•Œ,  
ì‚¬ì „ ë¯¿ìŒ(prior belief)ì„ í™œìš©í•´ ê·¸ â€˜ë¹ˆì¹¸â€™ì„ ë² ì´ì§€ì•ˆ ë°©ì‹ìœ¼ë¡œ ì¶”ì •í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.

---

### ğŸª™ ì‹¤í—˜ ê°œìš”: â€œí™©ê¸ˆ ì±„êµ´ì ê³¼ì œâ€

ì°¸ê°€ìë“¤ì€ ì„œë¶€ ì‹œëŒ€ì˜ ê¸ˆê´‘ ì±„êµ´ìë¡œ ì„¤ì •ë©ë‹ˆë‹¤.  
ë‘ ê°œì˜ ê¸ˆê´‘ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ ì±„êµ´ì„ í•˜ë©´, ë³´ìƒì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.  
ì˜ˆë¥¼ ë“¤ì–´ ì™¼ìª½ ê¸ˆê´‘ì„ ì„ íƒí–ˆë”ë‹ˆ **+10**ì´ë¼ëŠ” ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤ë©´, ì´ëŠ” â€œê¸ˆ 10ë‹¨ìœ„â€ë¥¼ ì–»ì—ˆë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.  
ë˜ ë‹¤ë¥¸ ê¸ˆê´‘ì„ íƒí–ˆì„ ê²½ìš°ì˜ _ë°˜ì‚¬ì‹¤ì  ê²°ê³¼(counterfactual outcome)_ ë„ í•¨ê»˜ ë³´ì—¬ì¤ë‹ˆë‹¤.  
ì˜ˆë¥¼ ë“¤ì–´ â€œë‹¤ë¥¸ ê¸ˆê´‘ì„ íƒí–ˆìœ¼ë©´ âˆ’11ì ì„ ì–»ì—ˆì„ ê²ƒì´ë‹¤â€ë¼ê³  í•˜ì£ .

ì´ë•Œ ì°¸ê°€ìë“¤ì€ ì—¬ëŸ¬ ì‹œë„ë¥¼ ë°˜ë³µí•˜ë©´ì„œ ì–´ë–¤ ê¸ˆê´‘ì´ í‰ê· ì ìœ¼ë¡œ ë” ìœ ë¦¬í•œì§€ í•™ìŠµí•©ë‹ˆë‹¤.  
ì—¬ê¸°ê¹Œì§€ëŠ” ì¼ë°˜ì ì¸ ê°•í™”í•™ìŠµ(paradigm) ì ˆì°¨ì…ë‹ˆë‹¤.

---

í•˜ì§€ë§Œ ì¼ë¶€ ì‹œë„ì—ì„œëŠ” **ì• ë§¤í•œ ê²°ê³¼(ëª¨í˜¸í•œ ê´‘ì„, dirty ore)** ê°€ ë“±ì¥í•©ë‹ˆë‹¤.  
ì˜ˆë¥¼ ë“¤ì–´ â€œ6ë‹¨ìœ„ì˜ ë¬´ì–¸ê°€ë¥¼ ì–»ì—ˆë‹¤â€ëŠ” ì •ë³´ëŠ” ì£¼ì–´ì§€ì§€ë§Œ, ê·¸ê²ƒì´ ê¸ˆì¸ì§€ ëŒì¸ì§€ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  
ê²Œì„ì´ ëë‚˜ë©´ ì‹¤ì œë¡œ ì–´ë–¤ ê²ƒì´ì—ˆëŠ”ì§€ê°€ ê²°ì‚°ë˜ì–´ ë³´ìƒì— ë°˜ì˜ë˜ì§€ë§Œ, í•™ìŠµ ê³¼ì •ì—ì„œëŠ” ì•Œë ¤ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.  
ê·¸ë˜ì„œ ì°¸ê°€ìëŠ” **ìì‹ ì˜ ì‚¬ì „ ë¯¿ìŒê³¼ í˜„ì¬ê¹Œì§€ì˜ ì •ë³´**ë¥¼ ë°”íƒ•ìœ¼ë¡œ  
ì´ ê²°ê³¼ê°€ _ê¸ˆì¸ì§€ ëŒì¸ì§€_ ì¶”ì •í•´ì•¼ í•©ë‹ˆë‹¤.

ì´ë•Œë„ â€œë‹¤ë¥¸ ê¸ˆê´‘ì„ ê³¨ëìœ¼ë©´ ë¬´ì—‡ì„ ì–»ì—ˆì„ê¹Œ?â€ í•˜ëŠ” ë°˜ì‚¬ì‹¤ì  ì •ë³´ëŠ” ê°™ì´ ë³´ì…ë‹ˆë‹¤.

---

ì°¸ê°€ìì˜ **ì‚¬ì „ ë¯¿ìŒ**ì„ ìœ ë„í•˜ê¸° ìœ„í•´, ê° ë¸”ë¡ ì‹œì‘ ì‹œì—ëŠ” **ê°€ìƒ ìˆ ì§‘(saloon)** ì¥ë©´ì´ ë‚˜ì˜µë‹ˆë‹¤.  
ê·¸ê³³ì—ì„œ ì¹´ìš°ë³´ì´ê°€ ì´ë ‡ê²Œ ë§í•˜ì£ :

- â€œì´ ì§€ì—­ì—” ê¸ˆì´ ì•„ì£¼ ë§ëŒ€!â€ (ê¸ì •ì  ì¡°ê±´)
- â€œì´ ì§€ì—­ì€ ê±°ì˜ ëŒë¿ì´ë¼ë„¤.â€ (ë¶€ì •ì  ì¡°ê±´)
- â€œëª¨ë¥´ê² ì–´, ì˜ ëª¨ë¥´ê² ë„¤.â€ (ì¤‘ë¦½ ì¡°ê±´)

ì¦‰, ì‹¤ì œ í™•ë¥ ì€ ë°”ê¾¸ì§€ ì•Šê³  ë‹¨ì§€ **ê¸°ëŒ€(prior)** ë§Œ ì¡°ì‘í•˜ëŠ” ê²ë‹ˆë‹¤.  
ì‹¤ì œ í™˜ê²½ì€ í•­ìƒ í•œ ê¸ˆê´‘ì´ í‰ê·  +10, ë‹¤ë¥¸ ìª½ì´ í‰ê·  âˆ’10ìœ¼ë¡œ ê³ ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

### âš™ï¸ ëª¨ë¸ë§

ì´ ì—°êµ¬ëŠ” **ë² ì´ì§€ì•ˆ ê°•í™”í•™ìŠµ(Bayesian reinforcement learning)** ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.  
ê¸°ë³¸ì´ ë˜ëŠ” _Rescorlaâ€‘Wagner ëª¨ë¸_ì€ â€˜ë³´ìƒì˜ˆì¸¡ì˜¤ì°¨(reward prediction error)â€™ì— ë”°ë¼ ë³´ìƒ ì¶”ì •ì¹˜ë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤.  
ë² ì´ì§€ì•ˆ ë²„ì „ì—ì„œëŠ” ì´ ê°±ì‹  í¬ê¸°(í•™ìŠµë¥ )ê°€ ë¶ˆí™•ì‹¤ì„±ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì¡°ì •ë©ë‹ˆë‹¤.  
ì¦‰, ì‚¬ì „ ë¯¿ìŒì´ ëª¨í˜¸í• ìˆ˜ë¡ ì‹¤ì œ ë°ì´í„°ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë‘ëŠ” ì‹ì´ì£ .

í•˜ì§€ë§Œ ìš°ë¦¬ ê³¼ì œì—ì„œëŠ” **ì• ë§¤í•œ ê²°ê³¼**ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.  
ì˜ˆë¥¼ ë“¤ì–´ â€œë”ëŸ¬ìš´ ê´‘ì„ 10ë‹¨ìœ„â€ë¼ëŠ” ê²°ê³¼ë¥¼ ë°›ì•˜ì„ ë•Œ,  
í”ŒëŸ¬ìŠ¤ì¸ì§€ ë§ˆì´ë„ˆìŠ¤ì¸ì§€ í™•ì‹¤íˆ ëª¨ë¥´ëŠ” ê²½ìš°,  
ëª¨ë¸ì€ ê·¸ ê²°ê³¼ë¥¼ ë² ì´ì§€ì•ˆ í‰ê· ì¹˜(ì˜ˆìƒ ë³´ìƒ)ë¡œ ë³´ì •(impute)í•©ë‹ˆë‹¤.  
ì¦‰, ê¸°ì¡´ ì‹ ë…ì´ ê¸ì •ì ì´ë©´ ê·¸ ê²°ê³¼ë¥¼ ì¢€ ë” +10 ìª½ìœ¼ë¡œ,  
ë¹„ê´€ì ì´ë©´ âˆ’10 ìª½ìœ¼ë¡œ í•´ì„í•˜ë„ë¡ í•©ë‹ˆë‹¤.

ë˜, ê·¸ëŸ¬í•œ ë¶ˆí™•ì‹¤ì„±ì„ ë°˜ì˜í•´ **ì¶”ê°€ì ì¸ ë¶„ì‚°(uncertainty)** ì„ ê³„ì‚°ì— í¬í•¨ì‹œí‚µë‹ˆë‹¤.  
50ëŒ€50ìœ¼ë¡œ ëª¨í˜¸í• ìˆ˜ë¡ ë¶ˆí™•ì‹¤ì„±ì´ ì»¤ì§€ê³ , ê²°ê³¼ì˜ í¬ê¸°ê°€ í´ìˆ˜ë¡ ê·¸ ì˜í–¥ë„ ì»¤ì§‘ë‹ˆë‹¤.  
ìˆ˜í•™ì ìœ¼ë¡œëŠ” ê³„ì‚° í¸ì˜ë¥¼ ìœ„í•´ â€œê°€ìš°ì‹œì•ˆ ê·¼ì‚¬(assumed density filtering)â€ë¥¼ ì ìš©í–ˆìŠµë‹ˆë‹¤.

---

### ğŸ“Š ê²°ê³¼ ìš”ì•½

- ì°¸ê°€ìë“¤ì€ ì‹¤ì œë¡œ í•™ìŠµì„ ì˜ í–ˆê³ , ëª¨ë¸ì´ í•™ìŠµê³¡ì„ ì„ ì˜ ì˜ˆì¸¡í–ˆìŠµë‹ˆë‹¤.
- â€œì´ ê²°ê³¼ê°€ ê¸ˆì´ì—ˆì„ê¹Œ ëŒì´ì—ˆì„ê¹Œ?â€ ë¼ëŠ” **ì‹ ë… ë³´ê³ (stated belief)** ë¥¼ ë³´ë©´,
    - â€œê¸ˆì´ ë§ì€ ì§€ì—­â€ì´ë¼ê³  ë“¤ì€ ì¡°ê±´ì—ì„œëŠ” ê¸ˆìœ¼ë¡œ í•´ì„í•˜ëŠ” ë¹„ìœ¨ì´ ë†’ì•˜ìŠµë‹ˆë‹¤.
    - â€œëŒì´ ë§ì€ ì§€ì—­â€ ì¡°ê±´ì—ì„œëŠ” ë°˜ëŒ€ë¡œ ë‚®ì•˜ìŠµë‹ˆë‹¤.
    - ì¤‘ë¦½ ì¡°ê±´ì€ ëŒ€ì²´ë¡œ ê¸ˆ ì¡°ê±´ì— ê°€ê¹Œì› ìŠµë‹ˆë‹¤.
    - ë² ì´ì§€ì•ˆ ëª¨ë¸ì€ ì´ëŸ° ì¡°ê±´ ê°„ ì‹ ë… ì°¨ì´ë¥¼ ì •í™•íˆ ì¬í˜„í–ˆìŠµë‹ˆë‹¤.

---

ë” í¥ë¯¸ë¡œìš´ ê²ƒì€,  
**ì¤‘ë¦½ ì¡°ê±´ì˜ ì‹ ë… ê³¡ì„ **ì€ ì‹¤ì œ ê¸ˆì˜ í™•ë¥ ê³¼ ê±°ì˜ ì¼ì¹˜í–ˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤.  
ì¦‰, ì¡°ì‘ìœ¼ë¡œ ê¸Â·ë¶€ì • ê¸°ëŒ€ë¥¼ ì¤¬ì„ ë•ŒëŠ” ì´ˆë°˜ì—ëŠ” í¸í–¥ì´ ìˆì—ˆìœ¼ë‚˜,  
í•™ìŠµì´ ì§„í–‰ë¨ì— ë”°ë¼ ì ì°¨ ì‹¤ì œ í™•ë¥ ì— ê·¼ì ‘í•´ ê°”ìŠµë‹ˆë‹¤.  
ì´ê²ƒì€ â€œì´ˆê¸° ë‚™ê´€/ë¹„ê´€ì  ë¯¿ìŒ â†’ ê²½í—˜ ë°ì´í„°ë¡œ ì ì°¨ êµì •â€ì´ë¼ëŠ”  
í™•ì¦ í¸í–¥ì˜ _ì ì‘ì _ ì‘ë™ ë°©ì‹ì„ ì˜ ë³´ì—¬ì¤ë‹ˆë‹¤.

---

### ğŸŒ ê°œì¸ì°¨ì™€ ë‚™ê´€ì„±

ì´ì œ ê°œì¸ì°¨ë¥¼ ì‚´í´ë´¤ìŠµë‹ˆë‹¤.  
ì°¸ê°€ìë“¤ì˜ **ë‚™ê´€ì„±(optimism)** ì€ _Life Orientation Test (LOTâ€‘R)_ ë¡œ ì¸¡ì •í–ˆìŠµë‹ˆë‹¤.  
ì´ ì ìˆ˜ëŠ” í–‰ë³µê°, ê±´ê°• ë“±ê³¼ë„ ë°€ì ‘í•˜ê²Œ ì—°ê´€ëœ ì‹¬ë¦¬ì²™ë„ì…ë‹ˆë‹¤.

ë¶„ì„ ê²°ê³¼, ë‚™ê´€ì„±ì´ ë†’ì€ ì‚¬ëŒì¼ìˆ˜ë¡  
**ì• ë§¤í•œ ê²°ê³¼ë¥¼ â€œê¸ˆì¼ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤â€** ê³  í•´ì„í–ˆìŠµë‹ˆë‹¤.  
í•˜ì§€ë§Œ ê°ê´€ì  ì •í™•ì„±ì—ì„œëŠ” ì°¨ì´ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤.  
ì¦‰, _ë‚™ê´€ì ì¸ ì‚¬ëŒë“¤ì€ ë™ì¼í•œ ì• ë§¤í•œ ì •ë³´ë¥¼ ë” ê¸ì •ì ìœ¼ë¡œ í•´ì„í–ˆë‹¤_ëŠ” ê²ƒì…ë‹ˆë‹¤.

---

### ğŸ§­ ê²°ë¡ 

1. **ì •ì„œì  ë¶ˆí™•ì‹¤ì„± í•˜ì—ì„œì˜ í•™ìŠµ ê³¼ì œì™€ ê³„ì‚° ëª¨ë¸**ì„ ì œì‹œí•¨.
2. **í™•ì¦ í¸í–¥ì´ ë‹¨ìˆœíˆ ì˜¤ë¥˜ê°€ ì•„ë‹ˆë¼, ì ì‘ì  ì—­í• ì„ í•  ìˆ˜ ìˆìŒ**ì„ ë³´ì„.
    - ë² ì´ì§€ì•ˆ ëª¨ë¸ì€ ì°¸ê°€ìì˜ ì‹¤ì œ ì‹ ë… ë³€í™”ë¥¼ ì˜ ì„¤ëª…í•¨.
    - ì‹œê°„ ê²½ê³¼ì— ë”°ë¼ ì‚¬ì „ ì‹ ë…ê³¼ ì‹¤ì œ ê²½í—˜ì´ ì¼ì¹˜í•´ê°.
3. **ë‚™ê´€ì  ì„±í–¥ì€ ê¸ì •ì  í•´ì„ì˜ ê°•ë„ì™€ ìƒê´€**ì´ ìˆìŒ.

ì¦‰, ë‚™ê´€ì£¼ì˜ëŠ” ì¼ì¢…ì˜ **â€œì‚¬ì „ í™•ë¥ (prior)â€** ë¡œ ì‘ìš©í•´,  
ëª¨í˜¸í•œ ê²½í—˜ì„ ë” ê¸ì •ì ìœ¼ë¡œ í•´ì„í•˜ê²Œ ë§Œë“¤ê³ ,  
ì´ëŠ” ê³§ í•™ìŠµê³¼ í–‰ë™ ì„ íƒì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë”°ë¼ì„œ, í™•ì¦ í¸í–¥ì€ ì™„ì „íˆ ë¹„í•©ë¦¬ì ì¸ ì˜¤ë¥˜ê°€ ì•„ë‹ˆë¼  
â€œë² ì´ì§€ì•ˆì  í•™ìŠµì´ ì‘ë™í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ í˜•íƒœâ€ì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.  
ìš°ë¦¬ ì‹¤í—˜ê³¼ ëª¨ë¸ì€ ì´ ê°€ì„¤ì„ íƒìƒ‰í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ í‹€ì„ ì œê³µí•©ë‹ˆë‹¤.

as you mentioned this has worked with the Sam gershman and Haley Dorfman who is now a postdoc with Liz Phelps at Harvard so let's see if I can move my slides meet and and is going to a party and she is a little pessimistic by nature and so she doesn't expect things to generally go well but she decides to tell a joke and everybody laughs and they laugh and things very cruelly at her and Anna's sad and she decides to never go to another party again meet Bob goes to a party Bob is kind of optimistic by Nature so he thinks that things generally go fairly well so he decides to tell a joke and everybody laughs and Bob thinks wow they're laughing at my joke Bob is cool I love this and I'm going to the next party again now Ann and Bob basically had the exact same experience they saw the same data and yet they interpreted that in totally different ways this is important for a number of reasons right it clearly affects their propensity to take risks in the future it affects whether they're going to go out and have that experience again and possibly disconfirm their initial beliefs but because they had these different expectations to begin with they end up interpreting that data in different ways now what happens here is basically a confirmation bias and if you Google confirmation bias you'll see a lot of figures that look like this where it means what you see is basically the intersection between the objective facts and what confirms your prior beliefs here so confirmation bias it gets a very bad rap some say it's the best known and most widely accepted notion of inferential error to come out of the literature on human reasoning and it's been blamed for closed-mindedness in Fields as hopefully important and Broad as science medicine politics law so people people hate confirmation bias right they think this is this terrible nefarious pernicious kind of bias that we should never have but what if confirmation bias could actually be adaptive what if it could have some useful value to it and if you think of it from a statistical perspective from a Bayesian perspective it could actually make sense that is to say when you're faced with some uncertain or ambiguous cities it makes sense that you should interpret those in light of your prior beliefs so if you think of it in computer science terms they might call it an inductive bias right something that helps you to jump start your learning process so we have some reason to think that actually it could be adaptive and we've seen this in a few different domains so far some have studied confirmation bias that might be adaptive in the way we acquire information that is do we seek out information that confirms our pre-existing hypotheses or in the interpretation of perceptual data so when you have ambiguous perceptual stimuli how do we interpret those given our prior beliefs uh we're looking at the processing of reward feedback now so far there's only been a little work on what are called Choice confirming asymmetries and so that reflects how people seem to place greater weight on positive outcomes for actions that they chose and less weight on positive outcomes for actions that they didn't shoot so the sort of counterfactual outcomes here we're looking at something different we're looking at how you appraise these ambiguous outcomes themselves uh irrespective of whether that's what you chose or what you didn't choose so more like our Ann Bob situation to begin with and we're going to provide two things here we're going to have a new model and we're going to have a new task so we have two goals here first we want to figure out is the way that we interpret ambiguous rewarding outcomes if that's confirmation biased is that potentially adaptive and second can we connect these biases to individual differences and in particular we'll look at differences in one's optimistic disposition now this relates to a number of literatures and we're particularly looking at a setting where you have what we call valence ambiguity and that means the magnitude of the outcome is something that you know but you're not sure about the valence you don't know whether it was good or bad and this is just like that and Bob situation where you saw uh there was some response some event that happened where everybody left but you weren't sure whether that was in a good way or a bad way and so this links with a few different literatures uh one that has to do with the way that we encode valence and magnitude perhaps separately in the brain uh also there's there's neuroscientific work uh and clinical work on the way that we process ambiguous rewards and Valence ambiguity in particular has been studied in the context of emotion processing so if uh I show you a face of somebody who's surprised was that a good surprise or a bad surprise right were they surprised because of some positive experience or a negative experience and the way that we interpret ambiguous outcomes has also been linked to uh clinical traits and clinical outcomes so for example people who are anxious tend to have what's called a negative interpretation bias where they tend to read into these negative stimuli negative faces negative experience or ambiguous stimuli experiences in a more negative fashion so we have two contributions here first is we are providing a new uh a multi-armed bandit task a new experimental Paradigm uh to incorporate valence ambiguity and second we're proposing a new Basin computational model of how you maybe should learn under this valence ambiguity and it captures this idea that you have almost a Bayesian missing data imputation that is to say if you know part of something like the magnitude of some outcome and you have some prior beliefs you should use that to actually guide your assessment of what the valence is so the way that you fill in the blanks should be consistent with uh Bayes and statistical principles here so in our experimental Paradigm we turn to the wild west as we've done before in a previous paper and in this task people are in the role of gold miners in the wild west this is a very uh an interesting way of presenting a classic multi-armed Bandit Paradigm that's been used in a number of different fields here so participants are in the role of this minor where they have two different gold mines that they can choose to dig from so in a given trial they have to pick one of these once they pick one they get an outcome here so I picked the one on the left and we show them you got a reward of plus 10 which translates into a positive amount of money for them and we show that here as you got 10 units of gold so gold is good we also show them the counter factual outcome here so that's in this case if you picked the other mind you would have gotten minus 11 points we did this so that we can shut off any exploration exploitation and just focus on interpretation of these outcomes and learning here so you took the action you got the outcome and then you go back through this again and again right classic reinforcement learning type approach so far that's pretty standard here's the modification we're making on some trials when you dig you get something that looks like this and this is dirty ore it's an ambiguous outcome where you know that this was six units of something but you don't know whether it was gold or rocks because it's covered in dirt and you'll still get paid at the end of the task based on whether it was in fact gold or rocks but you will not be told which of those it is and that means you have to make your best guess based on any information you have to date any prior uh pre-existing beliefs as well as the magnitude of what's given to you here and again you get the counter factual outcome it was about 50 of the trials where we give them these ambiguous outcomes and always for the option that they chose and then we asked them do you think that this was Rockstar gold so we had a stated belief question here and that tells us more specifically what actually were your beliefs about this ambiguous stimulus now in order to uh try and influence their prior beliefs going into a particular round we started off each block by putting them into this sort of virtual salute and in the saloon they encountered a cowboy who told them that he'd heard a rumor that maybe there's a lot of gold in this terrain right it might be a very rich environment or he said well I hear a rumor that there were a lot of rocks not really a great place or he didn't really hear anything he's not really sure here so this is a neutral condition so we can try and influence them a bit to say it's a rich a poor or a neutral environment we didn't actually change the reward statistics here it was always the case that one mine had an average value of plus 10 when if the other ones had a value of -10 and then there was just some common noise across the actual outcome that they would receive in any given round so we held the context itself or the environment fixed but we just tried to change their pre-existing beliefs a little bit so just to reiterate we said that uh in each block first they were in the saloon they were given some pre-existing belief a little bit then they were given a choice if the minds to dig from they got the feedback and made a judgment about whether they thought the outcome was rocks or gold and then they cycled back to Part B the choice here and went through that again and then after about uh you know a handful of trials they would go back into another condition where they were given a different pre-existing belief here so in our model this is built on a basin reinforcement learning model so the standard rescorla Wagner model this is the most basic version of model free reinforcement learning it says that you update your estimate of rewards by taking your initial estimate and then you increase that based on this reward prediction error which is the difference between the outcome that you actually got minus your pre-existing estimate and scale that by some learning rate that says well how much are you adjusting based on that new data now if you have a Bayesian version of this then that learning rate is itself derived from optimal statistical principles and so the the weight that you place on your prior beliefs versus the data is basically a reflection of how much uncertainty there is in each of these relative to one another so if you have very very big pre-existing beliefs that means your estimate variance here is quite high you're going to update more towards the data because you didn't really know much to start with now to this point this is a standard Basin reinforcement learning model this is the the Kalman filter from engineering but when we look at our Paradigm with ambiguous outcomes well now there are some points here which are actually not so clear right what does it mean to have a given outcome that's ambiguous if I told you you got 10 units of this Derby or should you count that as plus 10 should you count that as minus 10 should it be zero should you ignore it should it be somewhere in between where exactly if so and so we say you're going to impute that ambiguous outcome with basically your best guess your mean uh our expectation of that reward given the magnitude of it so if you think that this magnitude given you know you got A plus 10 if you think that tends to be more likely to be positive than negative then you're going to treat it as somewhere in the middle of minus 10 and plus 10 but skewed more towards the plus 10 side and you can calculate that more precisely given the basic Machinery which I just won't go into very much here the other thing that you need to do is to change the uncertainty about the outcome here as well because it's not only the signal noise that says how different each outcome is in a given trial from the true mean you also have some further uncertainty caused by the um the ambiguity from the coarsening of whether you whether it was positive or negative here as well and so you can see that that's a maximally uncertain when you're totally unsure 50 50 guess as to whether it was a positive or negative outcome here um and it happens to be scaled by the reward because you can think how if you've got an outcome of like zero or one you know that it's basically plus one or minus one you know that it's almost the same it doesn't really matter but if it's plus 100 or minus 100 now you're really really unsure and you should factor that in and I should mention this model is actually approximately based and we did what's called assumed density filtering which basically projects everything onto a gaussian space because it makes the math work out really nicely and that's a lot easier than doing it other ways so what did we actually find here well first the Bayesian model 50s learning curves fairly well so people were learning in the task and this was captured by you know any of these kinds of models that we would use here [Music] we also looked at the stated beliefs right remember that was when we asked them do you think that this outcome was rocks for gold and of course uh can you see my mouse cursor here cool so of course if there's gold this is a nice attention check we know that everybody said it was gold and it was rocks barring Some Noise you said it was rocks but in those dirty outcomes people basically said well if they were in that rich condition where they got the rumor of gold in this environment they had higher stated beliefs in gold and if they were in the poor condition then they had lower stated beliefs neutral oddly seemed to be pretty close to the rich condition actually and these little circles here represent the model predictions of a bayesin model where we fit condition specific prior beliefs here so the Basin model was able to capture these differences in stated beliefs across conditions as well now this is not model uh predictions here this is just the data itself and this is pretty neat if you look at these dotted lines here these dotted lines here reflect the true prevalence of gold in each uh trial here that is to say given the option you chose How likely was that to actually be gold and this is increasing with experience because you're just getting better at the task right you're you're actually learning this is the better mine to pick I'm going to pick that more often that's why this increases here what's cool is that these solid lines represent the stated beliefs that people had and in this neutral condition this Gray Line their stated beliefs track the actual true probabilities really closely that's to say if we didn't kind of push them in one direction or another their stated beliefs are pretty accurate compared to the True Values now the other neat thing is well we did see differences between these conditions so when we said well it's a bit Rich then they they are at a higher belief State here and when it's poor it was somewhat lower but in particular that obtains more at the start rather than the finish so it's almost as if they have different prior beliefs induced by this uh manipulation but with experience they're actually converging to the truth here so that's kind of neat right this is consistent with some idea of uh confirmation bias and optimism as being prior beliefs that are then uh influenced by the data as well and it turns out that if we fit that Bayesian model with different prior means for each condition you could actually capture those differences across conditions that is to say you end up with uh differences in those beliefs at the very beginning but then those end up washed out with the experience that you're getting because that experience is pretty uh comparable of that so the Bayesian model is capturing these dated belief Dynamics fairly well here it turns out the best fitting model does seem to vary somewhat across individuals but across the board the Bayesian version of the model fit better than a more traditional riskola Wagner reinforcement learning model that just skipped those ambiguous outcomes here comes here now can we look at differences across individuals right we saw that there are these pre uh these prior differences in beliefs when we very experimentally people's beliefs but what about individual trait differences and so we looked at optimism using this well-known life orientation test provides the lotr and this is pretty well known and commonly used in Clinical Psychology to capture optimism and it's been linked to a lot of uh well-known positive life and health outcomes so it's been linked to uh you know how healthy you are in terms of certain kinds of diseases and in terms of how you know happy you tend to be so you can see how this has a link between well and things like uncertain times I usually expect the best this is a very clear link uh in at least intuitively to how you're going to interpret these ambiguous outcomes and so we found in fact that if we take the average stated belief in gold on those ambiguous trials that is positively correlated with their optimism level that is to say optimists believe that these ambiguous outcomes tend to be positively rewarding here and it's not that there was any difference across them in terms of their objective accuracy that was pretty much uncorrelated only in terms of their subjective beliefs here so optimists and facts were attributing these ambiguous outcomes with more positive valence in effect so there's more that we're digging into still but in summary we showed this or download this task that measured learning and beliefs about these ambiguous outcomes in this context of valence ambiguity uh and we found that this observed confirmation bias seemed to be consistent with Bayesian mechanisms which is important for demonstrating that's adaptive in the sense that this data beliefs seem to be accurate they were connected closely to the true probabilities we also found that the Bayesian model could provide an adequate fit of this data and we're still trying to look into this form but it could be consistent with this idea that's been proposed of optimism as priors right so your your optimism determines your prior beliefs here which could then be uh minimized with the data that you're getting here or we're still looking into this but it provides some support for the idea that confirmation bias in these reinforcement learning type settings could actually be adapted and we provide a paradigm and a model that helps us to explore this idea so that's uh my talk and I'm happy to take any questions to the extent we have time for it


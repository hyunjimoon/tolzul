Video title: Claude Code's Globally Most Used Utilization Know-How Revealed | Sionic AI Engineer Ultrathink Pa...
    
Video URL: https://www.youtube.com/watch?v=0h6gfMqpx_0
    
Video language: English (United States)
    
--------------------------------

Welcome to the podcast 'Ordinary People,' which explores the extraordinary ways AI is changing people's lives. I am the host YouTuber 'Ordinary Businessman.' Today, we will be talking about 'Ending the Use of Cloud Code ' with Jinhyung Park, an engineer at 'Psionic AI,' which has achieved the world's highest usage of cloud code . Thank you for joining us, Jinhyung Park. Could you briefly introduce yourself? Nice to meet you. I am currently working in 'Ultrathink Engineering' at Psionic AI. These days, I am working on machine learning engineering or, mainly, backend engineering. I am creating a connection between the development and serving of AI agents and actual enterprise customers. You are an engineer at Psionic AI, so could you briefly introduce the company? 'Psionic AI,' which I am currently working at, is actually not easy for enterprise companies to adopt generative AI. This is because they need various ML teams or DevOps teams, and from that perspective, it is not easy to adopt them now. So from that perspective, we are now in the middle. We're continuously providing intermediate platforms to facilitate the adoption and utilization of AI. From that perspective, we 're helping enterprise clients easily adopt AI. What are the most common needs of enterprise companies ? Is the need for AI agents the most common? Yes, that's right. Ultimately , there are a variety of use cases that enterprises want to utilize AI for. Ultimately, from an enterprise perspective, I think we need to look at both the upside and the downside. First, the upside is, for example, if we have 20 or 30 years of company documents, we would like AI to learn from those documents and provide appropriate answers at the desired time without making mistakes. This is what basic AI companies want to introduce. From that perspective, when we say we will use it agentically, we want to organize various use cases well into code or functions and define and execute them according to the flow. In that sense, we often talk about 'agentic AI' or 'agent retrieval'. Now, the downside is, we have introduced AI, but we are worried that it will give us bad answers? Or that it will give us the wrong answers? Or that it will cause problems due to some unwanted actions . From this perspective, they worry a lot . For example, personal information may appear in the answer, and these things may seem trivial, but they can be critical issues for actual users. From that perspective, I think the point where enterprise companies have to take care of both the upside and the downside is the point where they have to worry the most. Last year, all companies put their lives on the line  for RAG and worked hard to build internal systems. This year, there seem to be a lot of attempts to introduce agent AI. You mentioned this before, but it would be great if you could briefly explain the difference between the two and how this trend shifted from RAG to agent AI. It would be great . Actually, the market's expectation for the introduction of generative AI is that the biggest need is to replace people or human resources with computers or AI. From that perspective, AI should be able to perform various use cases and various actions. From that perspective, if you are confined to a single, specific action, it is difficult to easily meet those expectations. For example, let's look at something like this today. If I ask the company to tell me about its annual sales, for example, if it's past RAG, I can simply store this in the database and retrieve it when needed. But for example, if a user asks, " What is the current annual sales or ROAS in light of today's stock situation?" , it can't simply be done with today's search. Now, those very blank parts need to be filled in well, and sometimes the AI ​​agent needs to be more active in calculating and making the user's abstract request more specific. From that perspective , I think the word "agentic" comes from the point of view of wanting to ask AI to do more diverse tasks and broaden the scope of what the AI ​​does. So, what is called RAG, basically, RAG is now closer to a buzzword, and basically, RAG is now search, right? Just like searching on Naver or Google or Spotify, we now search for our company's internal regulations. Then, the agent may or may not use the search tool, and AI will ultimately be the one to decide how to use the search function. From that perspective, the range of things AI can do has expanded significantly . RNG search is one of the tools that AI agents can use. These concepts are constantly evolving, and the pace of change is incredibly rapid, so I imagine users are having a hard time dealing with this. Your explanation was so good  that it was easy for me to understand. As we introduced earlier, today's topic is that you hold the title of world's No. 1 in Cloud Code token usage. Of course, this ranking has fluctuated, so you're no longer No. 1. You 've dropped to No. 3. You 're still ranked high, but you've been using it for a while. Many people may not be familiar with this concept, and this usage of 1. Could you briefly explain it? And when you introduced yourself earlier, you mentioned Ultrathink Engineering. I think it would be great if you could tell us more about that. Yes, that's good. First of all, if you say that you ranked first in usage, people often misunderstand that if you look at the record, it says that you spent 500 million won. There's about 400,000 dollars hidden, but when it was the highest , people misunderstand and ask if you paid 500 million won. Of course, I have several Max plans and am using them, and at that point, it was the usage of tokens that I used the most in a month. So, when I say token usage, it means that if I didn't subscribe to a token subscription and I didn't use an unlimited plan for the actual AI usage, if I had paid for the usage, it would have been 500 million won. So if you actually convert this, this is about 1.2 billion tokens . 1.5 billion? When that happens, it means that 1.5 billion tokens have been used. Those 1.5 billion tokens can mean various things, but if we think about what we call tokens, we can think of them as input, the context that I actually convey to the AI , output, the internal token that the AI ​​model thinks, reasons, and thinks about, and the final output, the result token. These three things are combined and called token talk. So, in the process, if you combine the input, output, and internal thinking of the AI, you can see that about 1.5 billion tokens have been consumed. The token usage is also enormous. I've been using a lot of cloud code, and in the end, the usability increases depending on how much you use it. I think that people who have used it a lot can gradually find ways to use it well . So today, I'm going to talk about some of Jinhyeong's know- how that he realized while using 1.5 billion tokens. Through that, we can plan for the future at both an individual and a corporate level. I think it would be great to talk about how to utilize cloud code and coding agent tools to not only increase productivity but also reduce costs. Okay, so let's start by sharing our screens. I brought the slides I used at the last Claude Meetup , and I'll expand on them by saying, "Tips on using Claude Code from Ultrathink Engineer." This is what I said. People are asking a lot about the usage itself, and as you said, the key is how to use it better. I 'm going to talk about it from that perspective. I think this is how we think about it.  So, ultimately, we had a paid subscription model for AI models last year, like $20 or $30, and now in October 2025, we 're talking about $ 200 or $300 . And Sam Altman recently mentioned that he 's going to create a plan that only those who subscribe to the Pro plan can purchase additional plans. From that perspective, I think there's a mismatch between the productivity provided by AI models and the current subscription plans. For example, from a very junior front-end developer's perspective, they can already cover the entire AI model itself, so now we're giving it to humans. The monthly salary is 3 million won. Our current minimum wage is 2.1 million won, so we can pay at least 2.1 million won, right? And in fact, when we look at articles like Open AI, they say they'll charge $30,000 for models developed by PhD-level researchers. So, on the one hand, I think , "Now is the cheapest time for AI models." But on the other hand, although I didn't mention this, it 's getting very expensive. In my case, I can't keep paying 500 million won, right? So, I think we need to distinguish between expensive and cheap options . Yes, you can think about it from that perspective. Let me talk  about what I'm mainly creating with AI. First, there's something called muvera-py. Recently, Google DeepMind published a paper on search. It's about a method that's about 50 times better than existing search methods, but it was misused. There was something called ColVal, but Muvera is a search technology that was supposed to be 50 times better, but it was 50 times more expensive. Now, they've made it about 1.5 times more expensive . And there's a paper on this algorithm. The implementation is in very basic C++, which is a very difficult language. Actually, most people use Python. So, I thought, what if we changed the implementation of this very difficult language, C++, into Python, which is widely used by people? I implemented it a little bit, and this implementation is now being used in Claude Opus 4 and then Gemini. I implemented this with two DeepThinks. At the time, GPT5 Pro was barely available, so I did a lot of coding. This is because I had to read the paper, understand it, and then code it. So, this is how I worked. First, I had to understand the paper. Now, I had to be a human in the loop to give feedback on whether the implementation was going well or not. Otherwise, I couldn't really give guidance. So, I had to first understand the paper. To understand the paper, I had to work with the best model. Now, we're using GPT5 Pro or Gemini DeepThink, these excellent models, to understand the paper together. We spent time reading together, and I understood it sufficiently, and now it's the first time for the AI ​​model. So, once that person has a sufficient understanding, we can move on to how to implement it. We need to discuss. This is what I'm going to create as a markdown file called 'tech spec'. The tech spec is, for example, like this paper, so to implement this, we need these requirements. For example, if we select five requirements, it's like a PM, or a product manager, selecting requirements. The best model selects this. And now, the coding CLI, Claude Code, or Codex, who can immediately see my code base, create a specific plan and get approval from the best AI. Is this okay to do? This iteration has to keep going. It has to keep going. In fact, the implementation I created is the answer. I created the tech spec with Gemini Pro and implemented it with the help of Claude Code. So, this was really popular at the time. It was really popular on Reddit and other places because this is a Google DeepMind paper. As soon as this came out, I made it in a sauna in two days. What I mean is, I'm filming on Fridays, and I like going to the sauna. But there aren't many saunas around Gangnam anymore. The reason I go to the sauna is because I have warm water. When I come out, I feel like my mind is really awakened. So, these days, I usually go to a sauna in Seolleung. Is there a sauna and a cafe there? Yes, it's a hotel, and there's a sauna and a cafe. So, I always use the sauna, and now I code while eating iced Americano or bread at the cafe. At that time, I always do creative work that 's not work -related on the weekends . And now, by doing this every Friday and Saturday, I always get a project selected, and with that, I can continue to do something new. I can do something new, or it can become famous. But in the case of Muvera-py, which I worked on at the time , I remember working together from dawn until Saturday afternoon , and I worked from dawn on Friday. It became very famous because it was a paper from DeepMind, so people really paid attention  . From that perspective, it was difficult to immediately apply the C++ implementation to my code, but this Python implementation was something I could use right away. So, the most representative person I was contacted at the time is now a search leader at Perplexity. Wang Bo was originally a leader in the embedding and RAG departments at Jina AI, but he recently moved. It just so happened that Jina is now here today. I heard that a famous search engine called Elasticsearch was being acquired, but anyway, a guy named Wang Bo came to Perplexity and asked if I wanted to work with him. I felt that way, and then, externally, it went viral on Twitter, and I received a lot of contacts. I really received a lot of contacts. So, as we continued to open source and release it, we started xAI. Andrew Zheng is a friend of the post-training team that created Grok. I talked to him, and now I'm at Microsoft, and I'm also talking to a guy from AI GBB. And when I posted this on Reddit, I started receiving contacts. So, I actually got a lot of contacts. It's been pouring in lately. And because I've been doing this, I feel like I've become a great genius engineer. People from MIT are contacting me, and I feel like I can go anywhere. But now I need to let go of my ego. Because, honestly, if I didn't have Fun Age 2.5 Pro, I wouldn't have been able to produce these results. So, it's always like, "The AI ​​takes the lead, and I learn from behind. And since I'm human, there are things the AI ​​can't see. So, I can say, "Isn't this wrong?" and go through that process. It's a huge help in creating results one by one. So, to be more specific, I think people are really interested in this coding CLI tool because Claude Code is so famous. I think there's a lot of interest. But as I've written here, what people usually think is, if you put a very abstract request like, "Make it like this," into Claude Code or a coding CLI agent, it'll work. But in reality, that's not the case at all . If we think about it, if we just sit down with a junior engineer, a college graduate, and say, "Hey, you've done development. He's done team projects at university," if we just ask him to create something like KakaoTalk, he  won't come up with it right away. Of course, he has to think about it too. KakaoTalk is probably the end goal. He'll have things he wants right now and things he needs to do in the future. We have to give him a context for all these various things. We have to give him more. Of course, since he's a junior developer, if you ask him to create KakaoTalk, he'll run away. Of course, the AI ​​won't run away. It'll pretend to do it and say it's done, but in reality, it won't work. From that perspective, for example, let's say, " Coding CI tool." They said they tried something but it didn't work well . It seems like this is the situation now. And what they're saying on one side is that there was already code that was running, but when they asked the coding CLI tool to do this, it didn't work well. In fact, that's inevitable. Because if you were to sit down a junior engine right away and ask them to read KakaoTalk's source code, it would be very difficult. It would also be difficult to implement this right away. From that perspective , this coding CLI is ultimately an AI agent, so we need to have discussions with this AI coding agent and work with it as if we were working with a person. Because if you think about our previous work in IT, there were many cases where we worked in a waterfall style. For example, if the requirements are clear and we implement these requirements, and then think about it in an agile way, we need to fail these requirements very quickly, and either I, a human, or an external QA, need to come in and continuously provide feedback on whether I'm doing well or not. This perspective is actually necessary when working with AI agents. So, the person providing the feedback could be another AI agent, a human, or a domain expert. There are so many different areas. From that perspective, we need to be strategic about this, not just praying for the tools in the coding market to do this . From that perspective, what I'm going to introduce a little more is that  we need to write good documentation. This may sound like a classic story, but documentation is incredibly important. Conversely, if you write this documentation well, you can implement it very well, no matter what AI model comes in. This documentation has two parts: one is the technical specifications, and the other is the plan. I want to emphasize the importance of this technical specifications. First , write this technical specifications. What is a technical specification? We need to clarify what we will implement and what we won't implement, and what our goal is through this implementation. In other words, it seems closer to "know yourself what you want to do. " For example, if we were to create KakaoTalk, it could be a messenger, a group chat, a simple text message, or an open chatroom. Assuming we're starting from scratch, let 's delve deeper into the details of creating KakaoTalk. KakaoTalk is basically a messenger, and a messenger has a sender and a receiver. So, the most basic step is to create a receiver, a sender, and the sender sends a message to the receiver. This is probably the process. Then, we can create three requirements: The sender can register , the receiver can add the sender as a friend, the sender can send messages to the receiver, and the receiver can read the sender's messages. So , we already have four requirements. This would be a more specific specification than simply asking for KakaoTalk. So, we've now created this. What you need to write in the tech spec is, " We'll implement these four requirements this time. " What we won't implement are things like, "We won't have an open chatroom because it's too big," or "Let's do group chats later," or "Let's do things like read receipts later ." You can do it like this . You need to document very well what you're going to do and what our goals are. Otherwise, each AI model, for example, might think very differently about creating KakaoTalk . Even within the same AI model, when I create a new session, what it thinks may be different. This is because AI models only produce output based on the context they accept in that moment . The actual learning that this AI model requires requires a lot of GPU resources, so we can't do it every day. From that perspective, we need to keep documenting it so that new people can continue working on it , like a handover document. These days, there's a bit of a specification-driven development approach  called SDD, right? You 're talking about that approach. It seems like Kirona and I think you consider the Speckit GitHub method , which has recently become a hot topic in the corporate world, very important . And with Vibe Coding becoming a hot topic these days, rather than simply telling people to do something, the method of always creating work instructions beforehand and proceeding according to the created work instructions is gaining popularity among both developers and non-developers. You seem to be saying that this is very important. Yes, that's right. Ultimately, I think the issues they're thinking about are very similar. It's not just about praying, it's about clearly defining what you want to do. But this is actually quite obvious. It's something that's obvious to people, so there's nothing special about it. You just need to document it well, manage versions well, store it well, and keep the documents and code in sync very well . This is very important. In fact, it's easy to say, but it's also very difficult. It's very difficult. I also find it  difficult. That 's why you have to write the specifications well from the beginning. Conversely, just because you've written the specifications well from the beginning doesn't mean you can just redo them. Things can vary and change depending on the situation. Because it can be done, it's right to try it out very quickly and fail quickly. This is the same thing I wrote. These technical specifications are the details of what needs to be implemented. The more specific these details are, the better. It's obvious. When I say specific, I mean down to the code level. That's why you have to talk to the best model. You have to talk to the best model, the most expensive model. In this case, when you spend a real token price of 1 million won or 10 million won, you have to use it very well. And you don't just have to do this with one model. You don't have to do it with the GPT5 program. You have to discuss it with other models of the same level, like Gemini Pro and DeepThink. In fact, the reason is  that there are various AI models, such as Gemini and GPT, and these models are ultimately different in nature. So, for example, Gemini has a more receptive characteristic, while GPT has a more receptive characteristic. Ultimately, the reason is that when training an AI model, how is it trained? What is the tendency to refine the AI ​​model? Also, the distribution of the datasets of these AI models are all different. For example, Claude is more adept at the latest Python, while GPT showed a lot of coding patterns from three to five years ago in Python. Therefore, since the knowledge and behavior of the AI ​​model can consult each other, I think I can proceed only after all the models have been approved. As you mentioned, you are talking about verifying a single task through multiple models . When trying to do that , how do you usually proceed ? Since the Claude code appeared, we have been working in parallel or in various ways. There are many ways to call MCP and such. It would be great if you could tell us how you usually proceed. Here are some points worth considering: I brought an example here. In the case of technical specifications, I believe that people can understand this clearly. So, you could use a terminal or VS Code to explain it. Personally, I use ChatGPT.com a lot for technical specifications. The reason is that I need to read the document myself so that I can intervene and give my opinion. For example, when a task force is formed at a company, there are a few initial meetings. For example, senior level employees, not just working-level employees, come in and have a lot of discussions. It's very similar to that. So, what I had was, I have an example. It might be difficult, but  I'll explain it simply. The text embedding inferencer, which is from Hugging Face, is quite famous. There's a code from Honeyfit. What does this code do? What does it do? Some of you may have heard of things like inbedding or Reranker when searching for allergies or other services. When using this, it's actually the best serving model, that is, inbedding and reranking models. This is actually used as a server, and it's one of the core servers. It's one of the rappers. So, if you look here, there are only about 50 contributors, and each of them is very famous. There are many people like Jina or Perplexity. These days, I enjoy adding new models to this repository as a personal hobby. This is because if you look at this repository, you can technically understand how the model is actually implemented. If I can quickly add new models, I can continue to gain popularity. Since it has the characteristic of killing two birds with one stone, I'm trying to continue implementing this. Recently, Jina AI, a very famous company, has released a model called Reranker. I won't explain this, but the ranker is known to be very good. It's well-known. Friend, so for example , what I did during the holidays was to add this new model used in Areju, called Jina Reranker V3, to Hugging Face's support . So how can I do that? This is extremely difficult even for non-developers, and it's difficult from a developer's perspective. To contribute to Hugging Face's repository, you first need to know Rust, and then you need to know machine learning. This is already a legacy code that's being used by many people and is being used globally. So, to add support, you need to understand the implementation and system structure. So, what should I do if I want to contribute to an existing code with an unfamiliar model and a difficult language ? Now, this is a very challenging task for me as well. Because I don't have a lot of experience, and I 'm not particularly good at this kind of thing. So, to implement this, I think the first thing I can try is this. So, first, there's this model. I don't know what it is, but when this model comes out, there's usually a paper. The paper is like a very detailed explanation of how the model is structured. Okay, so let's just put this explanation into GPT. This is GPT5 Pro. When I put it into GPT, it'll say something. I'll read it and study it. After studying it, it'll ask me to explain it, so I'll read it and continue the discussion. During the discussion, what I can do here is ask questions like this. I'll scroll down. If you scroll down, you'll see that I've asked all these questions and I'm just studying. I've studied , and the dialog box is really long. Yes, it's really long. I don't know how many times it's been, but I just wrote it like this. This company has this Heo In-pace, and I applied to Heo In-pace. So , if I were to write a technical specification, what would I do if I wanted to put in the code ? Basically, it would be a rough sketch. So, there are goals, there are non-goals, and there are certain things that need to be worked on. Requirements are sorted like requirement 1, 2, 3, 4, 5. Once they're sorted, I ask them to kindly create a markdown file for this. Okay, so if they write it kindly, it'll come out like this. But basically, when they do this, this GPT guy will have some knowledge. Since he's an agent, he'll probably search for the company, look at the code files, analyze them, and come to his own conclusions. But his conclusions and Gemini's conclusions might differ. Gemini has a very high level of understanding, and there 's a lot of this . So, I copied the information from here and put it here. So, I use GPT as an anchor, and this guy as the main worker. Now, I have a fun kid who provides feedback, a deep link. I give this result to this guy, and when he gives his opinion, I give him this opinion. He asks me again, and I give him this opinion. So , these two will inevitably clash.  Gemini's way of thinking is deep, and these two ways of thinking are two different things. If a conflict arises, and you say, "Oh, this can't be used as is," and the other person will have a different opinion , you need to coordinate the two people's thoughts. For example, one of the biggest ways to coordinate these two is with something like Zen MCP. For example, this involves having two MCP models discuss and fight, and then forcing them to reconcile after a maximum of 30 fights (you can set a value for this too). This is called a challenge, and there's an MCP called "JeCP," which is used in coding CLI. This method pits these two models against each other and determines the winner. In fact, I do this alone during tech space because I have to read and understand it and then raise my hand. So, for example, I do it like this.  I reflected the review at the time and suggested it. Now, this is a little off here, but here are the things I've written. Once the two people reach an agreement, I can then pass this on to the Cloud code or the coding CLI agent. I'm asking you whether you think this tech spec is correct or not . The reason I'm doing this is because, while these ChatGPT-based friends can ultimately make various function calls, the Coding CLI agent is the one with the highest understanding of the code I have. So, for example, let's take a look at the code I've done. Liz, if you look at it like this, there's a lot of this. I kept forking it because the session was disconnected, so I kept creating it. Now, this is how it's done. For example, I gave the GPT5 pro the initial tech spec and asked him to read it. He'll probably be touching some files here. He'll think about the file limitations and you can read the files better right now, so determine if there's a gap between the two. And he'll not only ask him to do this, but he'll also ask the Codex. This probably won't be able to see the past. Yes, the Codex doesn't have that function right now, so there's Rezum, but anyway, let's do this with the Codex and Gemini. Now, after looking at these, we ultimately put these individual results back into GPT 5 Pro and Gemini DeepSync. What do you think? And ultimately, there has to be a standard here. In the end, I'll use the results of GPT5 Pro, that is, the output of the spirit, as a standard. And this fun Deep Pink will be used as a supplement, as a feedback review. We have to role-play this so that it all comes together. Then, we gather the opinions of these friends, Gemini DeepSync's opinions, and ultimately give it to Claude GPT 5 Front. There are five people between these two, right? We repeat this opinion caution until all five people give the okay sign. Of course, there are six people, so it's like this. To implement this implementation, there's something called a tech spec council, and we keep repeating this until all six people agree. If a certain friend says something strange, I can step in and say, "I think your idea is wrong," and I can block you. Or, for example, a certain fun friend can give you more feedback directly. This is the process that needs to be done . In the middle, the coordinator can be an MCP friend, but since these technical specifications are so important, I'll do it. That 's why I'm talking about it like this. It's really long. It's really long. So , when discussing this with LLM models, in the case of Jinhyeong, you have to wait while you work. I'm curious about how you utilize that waiting time.  There seem to be two reasons. First, I have to improve my understanding. So, for those who are just starting out, time is running out just by looking at the documentation. Second, if this is a very demanding task, or a task with a high technical difficulty, I can't do anything else while I'm working. I have to understand if they're saying the right thing and give them feedback, so I tend to study that. But if it's not that and they're adding a simple feature, they delegate more, and I can work on other things during that time. So, for example, if the difficulty is low, I can work on three or four or more simultaneously. If the difficulty is high, I tend to focus on just one thing. I think it's a level of difficulty that requires a high level of immersion to understand. That's right . So, the misconception people have is that they just leave it to the kids and think they'll figure it out if they just sit back and do nothing. In reality, that's not true. Rather, I need to make an effort to maximize their abilities. So , for example, just because I use a lot of tokens doesn't mean I'm just going to go wild and play around. That's actually a point that people often misunderstand . You've explained it well . People might think that simply because they use a lot of tokens, they'll just ask questions here and there, toss those questions back here and there, and so on . Instead, you refine the answers you give, and then human intervention and coordination takes place, acting as a manager. Yes, that's right. That's how I do it. The final tech spec ending is this. If you look at it, there are a lot of different things going on. There are goals and non-goals, the current state is like this, and then the model is like this, architecturally and technically, and then there are requirements and the work that needs to be done in this way. For example, I think Here , I'm currently working on requirement 6.3, which is sub-task 3, which implements the detection logic. At this time, the code should be like this. It's almost like a blueprint that can be copied and used right away. So , there's also this. For example, in the case of Gemini, the output is usually not long.  But Claude's output is very long. So, I thought that Claude would be weaker in critical tasks, but instead, he's a very good writer. So , for example, Gemini Pro can capture the critical points, and Claude can write longer code. This is because Claude tends to write long code. In the case of Gemini, it feels like he just hits the nail on the head and runs away. That's why I'm telling you that it's very important to make good use of the characteristics of this model. So, now, we write the technical spec like this. If we write it like this, then, with this document, anyone can actually start this task. So, as I said at the beginning,  rather than just saying, "Hey, implement this," if we have this, we can do it. I also have the mindset that it will exist, and then I'll have an AI model. The next thing I have to do is write a very detailed to-do plan. In fact, tech specs alone are not enough. The reason is that tech specs are more like a document that explains what needs to be done, and it's different from what I'm going to do today. So, I always think of AI models as being very junior engines. They don't know anything, so I have to kindly explain it to them. That's why if I just give them tech specs right away, they 'll say , "Oh, I know what you told me, but I'm at a loss." That's why I need to tell them , "Just sit down and do this." Usually, when you do a to-do, you ask and discuss various models in the same way you wrote the tech specs earlier . But in the case of tech specs, I think a lot of people are involved. In the case of plans, if the tech specs are already solid, automation can be implemented from here . So, what I want to do with this plan is, Coding Sierra Agent. Its features include the ability to pinpoint code with great precision and see much more context and context. Therefore, from here on out, we don't use ChatGPT.com or anything like that. Instead, we place great importance on discussions between coding CLI agents. Since we already have a blueprint for what needs to be done and which files need to be touched in the technical specifications , you can think of it as a meeting between working-level professionals to discuss  the specifics . That's why these system professionals are involved. First, let's look at PLAN.md. Looking at plan.md, there are three versions, four versions , and what is being done here? If you look at it, these are implementation guidelines. What I created here is different from before. If the previous discussion was about technical issues, such as what needs to be done, in this case, we create something specific that says, "This is what you should do this time." So, in this case, as you can see from the many emojis, we use Claude Code Sonnet 4.5 as the main gun and the main model, and now we use Gemini CLI. Many of these friends provide feedback in between. For example, when working on Claude Code Sonnet 4.5, from this point on, agents that have started coding other things use MCP a lot to continuously provide feedback. For example, if I look at the milestones right now, there are 8 or 9. There are 9. Are these 9 milestones selected correctly? Do you agree with these milestones? If you perform the same thing that Claude Code CLI did, you can check whether the milestones created by Claude Code CLI are correct, in the correct order, and at the correct points. You continuously provide feedback. If you think they are not correct, clearly give feedback on why you think they are not correct and have them try again. This is repeated until both agree. This is just repeated. So this also takes about 3 hours. The tech spec I mentioned earlier took me about 2 days, and this took me a little over 3 hours. So I worked on this for about 4 days. So, what's happening here is that plan.md can be thought of as milestones . Milestones 1, 2, and 3 can be turned off when I turn on the session and turn on the cloud code and implement all of these milestones. It should be about this size. Of course, one milestone can be very large. In that case, you can see that there are sub-tasks. You can turn off these sub-tasks one by one. The decision on this is ultimately up to the coding agent. You look at it and adjust it well. This time, the 4.5 of the cow is a model that knows when to turn off the context. Therefore, it helps a little bit in setting these milestones. So, what I expect now is this. When this flat MD comes out, for example, I will only perform this task called detection logic with projector verification . I will turn off the session . I will commit and upload the code. Then, when it says "all done," a person comes in and if I can give feedback, I can give feedback. Or if I can create automated tests, this guy will create all the automated tests. So, now, I guess I've run it and it's done. When you say "done," I just look at it and confirm it. Whether to proceed or not, you need to keep updating this planner. If I complete milestone 1 and 1-1, I'll do all the work and mark it with an x. And this is this commit.  So, when doing this kind of work, the role of this Claude.md is extremely important. As you all know, this Claude.md is a system prompt that gives very strong instructions on how the current coding Sierra agent should work. So, for example, there's something like this. If you look at it, you absolutely must read the tech spec before doing any work. You have to read it very carefully. This alone will probably cost over 30,000 tokens. And based on this tech spec, what you have to do is to focus all your energy on implementing this plan. And you have to ask the tech spec about anything you don't know. Then, with the tech spec and the plan, any model given can be implemented. Of course, if the model is too weak, it won't work. So, for example, this. When I say "go," I mean, I look at plan.md and implement the last thing that's not implemented yet. And I write the test first. Only with the test can I quantitatively evaluate and determine whether I failed or passed. And write only the minimum code to implement this test. Because if you leave it to the AI ​​model, it will suddenly expand and make a lot of changes, and it will be difficult for people to give feedback. So, only very small changes will remain. Make only the minimum changes. If this is not enough, you can do this. Make a prompt like this. Then, you can force it to be rule-based and terminate the session if it exceeds 100 lines. There are many different strategies. So, this is what I do during the detailed stage. First, I run the test.  Well, this is now giving it to the compiler. I'll talk about this more. Run the compiler to give feedback, run the test, and then implement it. And continue to iterate until steps 1, 2, and 3 are all satisfied. Regarding the ad, you are in milestone 1. This is repeated only for detection logs with projector verification. It 's repeated, and the important thing here is to use something like my MCP to continuously receive feedback from other codes . So, I keep repeating this plan. I repeatedly implement it, and then I implement it, and then I implement it, and then I implement it, and it keeps going up. The Claude code itself also has a separate plan mode, which is completely separate from that . In fact, the plan mode is something I do myself. So, how do you think about it? This plan mode is like this. So, the techspec.md is a directive from management, the PLAN.md is what the supervisor told me to do today, and then the Claude code's plan.md is where I think about it myself. "Oh, I have this kind of thing. Should I read this first? Should I try it out and run it first?" That's what's on my mind. I think it's time to get to that point. So, I repeat this. And now, it's necessary to continuously update this plan. So For example, once you're done, you're using a very primitive method. Now, hit the V sign. Hit the V sign. When you're done, open a new session and say, "Do the next thing that's not marked with a V sign right now. Do the next thing. Do the next thing . And now the next person will read this, so if you say , "Write a note for him , here, plan.md," you'll write something like this. This is what you need to fix and move on, so you'll let him know. The reason why this is important is because of this . Then, he'll come to the next session and  work on this and move on . Do you usually update the MD file yourself? Or, after he's done with his work, you'll have him write an improvement plan like this himself. Instead, because version control is important, you have to commit with this plan. So, one commit includes one milestone or one subtask. That way, I can go back and forward. So, if you look at it, it's very well-integrated with the commit function of the machine. You have to use it well. One commit should only create one task and one function. This is actually a principle that comes up a lot in software engineering, but I think it applies even more when using things like plan.md well. So, have we progressed about 20% of what we've prepared? Yes, it seems like we've progressed, but it's too much to talk about today. We have a second part, so yes, there are some parts that go into quite a bit of depth, and I think you've discussed some very interesting topics. So, we're going to be able to explain the rest of the cloud code and the coding agent, and how we've used tokens a lot, and the know-how we've gained from that , in a more in-depth and easy-to-understand way than in the last seminar. We're running out of time, so it would be great if we could split this into two parts and cover the rest next time. Yes, that's great.


DISCLAIMER:


By using this tool to convert YouTube videos to Text, you acknowledge and agree to the following:


1. User Responsibility: You are responsible for ensuring that your use of this tool complies with all applicable copyright laws and YouTube's Terms of Use. This includes obtaining any necessary permissions from the original content creators before reproducing or distributing any content.


2. Content Ownership: The transcripts generated by this tool are based on publicly available content from YouTube. You do not own the rights to the original video content or its transcripts. All copyrights and ownership rights remain with the original content creators.


3. Attribution: This tool provides the URL of the original YouTube video for reference purposes. You are encouraged to include proper attribution when sharing the generated Text.


4. Limitations of Liability: We disclaim any liability for the misuse of the content generated through this tool. By using this tool, you agree to hold us harmless from any claims or disputes arising from your use of the content.